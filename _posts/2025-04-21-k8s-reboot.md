---
title: "Kubernetes 노드 전체를 안전하게 재부팅하는 방법"
date: 2025-04-21
tags: [k8s, kubernetes, reboot]
categories: [Howtos, Kubernetes]
---


마스터 노드와 워커 노드를 포함한 모든 Kubernetes 노드를 안전하게 재부팅하고, 재부팅 후 `kubectl` 명령이 정상적으로 작동하며 Kubernetes 서비스가 안정적으로 실행되도록 하려면 신중한 절차를 따라야 합니다. Kubernetes 클러스터는 고가용성(HA) 설정 여부, 노드의 역할, 그리고 클러스터 구성에 따라 재부팅 시 다양한 문제가 발생할 수 있습니다. 아래에서는 안전한 재부팅 절차와 재부팅 후 `kubectl` 명령이 작동하지 않는 문제를 해결하는 방법을 단계별로 설명하겠습니다.

---

### **1. 사전 준비**
재부팅 전에 클러스터 상태를 점검하고 중요한 데이터를 백업하여 문제를 최소화합니다.

#### **1.1 클러스터 상태 확인**
- **노드 상태 확인**:
```
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS   ROLES                  AGE   VERSION
k1     Ready    control-plane,master   28m   v1.29.15
k2     Ready    worker                 28m   v1.29.15
k3     Ready    worker                 28m   v1.29.15
k4     Ready    worker                 28m   v1.29.15
```
  - 모든 노드가 `Ready` 상태인지 확인합니다.
  - 노드의 역할(마스터/워커)을 확인합니다:
```
citec@k1:~/osh$ kubectl get nodes -o wide
NAME   STATUS   ROLES                  AGE   VERSION    INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME
k1     Ready    control-plane,master   28m   v1.29.15   172.16.2.149   <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
k2     Ready    worker                 28m   v1.29.15   172.16.2.52    <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
k3     Ready    worker                 28m   v1.29.15   172.16.2.223   <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
k4     Ready    worker                 28m   v1.29.15   172.16.2.161   <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27

citec@k1:~/osh$ kubectl describe nodes | grep -i "roles"
Roles:              control-plane,master
Roles:              worker
Roles:              worker
Roles:              worker
```

- **파드 상태 확인**:
```
citec@k1:~/osh$ kubectl get pods -A -o wide
NAMESPACE        NAME                                       READY   STATUS    RESTARTS   AGE     IP               NODE   NOMINATED NODE   READINESS GATES
kube-system      calico-kube-controllers-6b78c44475-5bt4m   1/1     Running   0          2m33s   10.244.194.129   k4     <none>           <none>
kube-system      calico-node-jdlpn                          1/1     Running   0          64s     172.16.2.161     k4     <none>           <none>
kube-system      calico-node-pxj8c                          1/1     Running   0          95s     172.16.2.149     k1     <none>           <none>
kube-system      calico-node-strt8                          1/1     Running   0          74s     172.16.2.52      k2     <none>           <none>
kube-system      calico-node-zlrv7                          1/1     Running   0          85s     172.16.2.223     k3     <none>           <none>
kube-system      coredns-5c55d7d65b-nqqr2                   1/1     Running   0          84s     10.244.195.129   k3     <none>           <none>
kube-system      coredns-5c55d7d65b-wv9xl                   1/1     Running   0          84s     10.244.99.1      k2     <none>           <none>
kube-system      etcd-k1                                    1/1     Running   2          3m13s   172.16.2.149     k1     <none>           <none>
kube-system      kube-apiserver-k1                          1/1     Running   18         3m13s   172.16.2.149     k1     <none>           <none>
kube-system      kube-controller-manager-k1                 1/1     Running   13         3m13s   172.16.2.149     k1     <none>           <none>
kube-system      kube-proxy-g42tp                           1/1     Running   0          2m54s   172.16.2.161     k4     <none>           <none>
kube-system      kube-proxy-hvhp8                           1/1     Running   0          2m58s   172.16.2.52      k2     <none>           <none>
kube-system      kube-proxy-qjh87                           1/1     Running   0          2m59s   172.16.2.149     k1     <none>           <none>
kube-system      kube-proxy-vx5ns                           1/1     Running   0          2m55s   172.16.2.223     k3     <none>           <none>
kube-system      kube-scheduler-k1                          1/1     Running   84         3m13s   172.16.2.149     k1     <none>           <none>
metallb-system   metallb-controller-5f9bb77dcd-tgg9c        1/1     Running   0          68s     10.244.194.132   k4     <none>           <none>
metallb-system   metallb-speaker-59qk9                      4/4     Running   0          68s     172.16.2.52      k2     <none>           <none>
metallb-system   metallb-speaker-k6q2l                      4/4     Running   0          67s     172.16.2.161     k4     <none>           <none>
metallb-system   metallb-speaker-mjt4s                      4/4     Running   0          68s     172.16.2.223     k3     <none>           <none>
metallb-system   metallb-speaker-wkgnk                      4/4     Running   0          68s     172.16.2.149     k1     <none>           <none>
```
  - 중요한 파드(예: `kube-apiserver`, `etcd`, `kube-scheduler`, `kube-controller-manager`, `coredns`)가 정상적으로 실행 중인지 확인합니다.

- **클러스터 고가용성(HA) 확인**:
  - 마스터 노드가 여러 개인지 확인합니다. HA 클러스터라면 마스터 노드를 순차적으로 재부팅해도 서비스 중단을 최소화할 수 있습니다.
  - `etcd` 클러스터 상태 확인(여기서는 k1 노드가 마스터 노드이다)
```
citec@k1:~/osh$ kubectl -n kube-system exec -it etcd-k1 -- etcdctl member list \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key
318d8f560168bc98, started, k1, https://172.16.2.149:2380, https://172.16.2.149:2379, false
```
  - 단일 마스터 노드라면 재부팅 시 클러스터 전체가 일시적으로 중단될 수 있습니다.

#### **1.2 백업**
- **etcd 데이터 백업**:
  `etcd`는 Kubernetes 클러스터의 상태를 저장하므로, 재부팅 전에 백업합니다.
```
citec@k1:~/osh$ kubectl -n kube-system exec -it etcd-k1 -- etcdctl snapshot save /tmp/etcd-snapshot.db \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key
{"level":"info","ts":"2025-04-21T00:23:45.723201Z","caller":"snapshot/v3_snapshot.go:65","msg":"created temporary db file","path":"/tmp/etcd-snapshot.db.part"}
{"level":"info","ts":"2025-04-21T00:23:45.724161Z","logger":"client","caller":"v3@v3.5.16/maintenance.go:212","msg":"opened snapshot stream; downloading"}
{"level":"info","ts":"2025-04-21T00:23:45.724263Z","caller":"snapshot/v3_snapshot.go:73","msg":"fetching snapshot","endpoint":"127.0.0.1:2379"}
{"level":"info","ts":"2025-04-21T00:23:45.819212Z","logger":"client","caller":"v3@v3.5.16/maintenance.go:220","msg":"completed snapshot read; closing"}
{"level":"info","ts":"2025-04-21T00:23:45.904592Z","caller":"snapshot/v3_snapshot.go:88","msg":"fetched snapshot","endpoint":"127.0.0.1:2379","size":"6.6 MB","took":"now"}
{"level":"info","ts":"2025-04-21T00:23:45.904745Z","caller":"snapshot/v3_snapshot.go:97","msg":"saved","path":"/tmp/etcd-snapshot.db"}
Snapshot saved at /tmp/etcd-snapshot.db

citec@k1:~/osh$ sudo crictl ps -a | grep etcd
WARN[0000] runtime connect using default endpoints: [unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock]. As the default settings are now deprecated, you should set the endpoint instead.
WARN[0000] image connect using default endpoints: [unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock]. As the default settings are now deprecated, you should set the endpoint instead.
7711677c54e86       a9e7e6b294baf       7 minutes ago       Running             etcd                      2                   fa79000c9f77f       etcd-k1
citec@k1:~/osh$ sudo find /run/containerd -name 'etcd-snapshot.db'
/run/containerd/io.containerd.runtime.v2.task/k8s.io/7711677c54e865d457771ae85063f9b6ba292b0e5aa8213ef000b320fd8317d0/rootfs/tmp/etcd-snapshot.db
citec@k1:~/osh$ sudo cp /run/containerd/io.containerd.runtime.v2.task/k8s.io/7711677c54e865d457771ae85063f9b6ba292b0e5aa8213ef000b320fd8317d0/rootfs/tmp/etcd-snapshot.db .
```
  - 백업 파일을 안전한 위치에 저장합니다.

- **중요 리소스 백업**:
  중요한 ConfigMap, Secret, Deployment 등을 백업합니다.
```
citec@k1:~/osh$ kubectl get all -A -o yaml > kubernetes-resources.yaml
citec@k1:~/osh$ kubectl get configmap,secret -A -o yaml > kubernetes-configs.yaml
citec@k1:~/osh$ ls -l kubernetes*.yaml
-rw-rw-r-- 1 citec citec 105117 Apr 21 09:29 kubernetes-configs.yaml
-rw-rw-r-- 1 citec citec 229928 Apr 21 09:28 kubernetes-resources.yaml
```

---

### **2. 노드 재부팅**
노드를 순차적으로 재부팅하여 클러스터의 안정성을 유지합니다. HA 클러스터라면 마스터 노드를 먼저 재부팅하고, 워커 노드를 나중에 재부팅합니다. 단일 마스터 클러스터라면 마스터 노드 재부팅 시 클러스터가 잠시 중단되므로, 워커 노드들을 순차적으로 재부팅한 후에 마스터 노드를 재부팅합니다. 본 문서에서는 단일 마스터 클러스터에 대해 설명합니다.

#### **2.1 워커 노드 재부팅**
워커 노드들의 순차적으로 아래의 순서대로 재부팅을 실행합니다. 각 노드에 대해 '재부팅 전 파드 배출', '노드 재부팅', '배출 해제'를 실시합니다.

1. **재부팅 전 파드 배출 (Drain)**
   - 재부팅하려는 노드에서 실행 중인 파드를 다른 노드로 안전하게 이동시킵니다.

   - 재부팅하려는 노드에 대해 파드 배출 명령을 수행(예시에서는 k4 노드부터 재부팅 수행):
```
citec@k1:~/osh$ kubectl drain k4 --ignore-daemonsets --delete-emptydir-data --force
node/k4 cordoned
Warning: ignoring DaemonSet-managed Pods: kube-system/calico-node-sx2s6, kube-system/kube-proxy-6bgsb, metallb-system/metallb-speaker-7rrcs
evicting pod kube-system/coredns-556f7949d8-8srzf
evicting pod kube-system/calico-kube-controllers-6b78c44475-mqf7b
pod/calico-kube-controllers-6b78c44475-mqf7b evicted
pod/coredns-556f7949d8-8srzf evicted
node/k4 drained
```
     - `ignore-daemonsets`: DaemonSet 파드는 드레인되지 않도록 설정.
     - `delete-emptydir-data`: EmptyDir 볼륨 데이터 삭제 허용.
     - `force`: 비관리 파드도 강제로 제거.

2. **워커 노드 재부팅**:
   - 파드를 배출한 워커 노드에 대해 재부팅 명령을 수행:
```
ssh k4 sudo reboot
```
   - 노드가 재부팅될 때까지 대기 (약 1~5분).
   - 재부팅 후 노드 상태 확인:
```
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS                        ROLES                  AGE   VERSION
k1     Ready                         control-plane,master   42m   v1.29.15
k2     Ready                         worker                 42m   v1.29.15
k3     Ready                         worker                 42m   v1.29.15
k4     NotReady,SchedulingDisabled   worker                 42m   v1.29.15  # <-- reboot

citec@k1:~/osh$ kubectl get nodes
NAME   STATUS                     ROLES                  AGE   VERSION
k1     Ready                      control-plane,master   40m   v1.29.15
k2     Ready                      worker                 39m   v1.29.15
k3     Ready                      worker                 39m   v1.29.15
k4     Ready,SchedulingDisabled   worker                 39m   v1.29.15  # <-- Ready 상태로 변경
```
     - 노드가 `Ready` 상태로 돌아올 때까지 기다립니다.

3. **노드 스케줄링 활성화**:
   - 재부팅된 노드에 대해 아래 명령 수행:
```
citec@k1:~/osh$ kubectl uncordon k4
node/k4 uncordoned
```
   - 확인(아래와 같이 k4 노드가 Ready 상태로 돌아온 후 다음 노드를 재부팅 수행):
```
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS   ROLES                  AGE   VERSION
k1     Ready    control-plane,master   44m   v1.29.15
k2     Ready    worker                 44m   v1.29.15
k3     Ready    worker                 44m   v1.29.15
k4     Ready    worker                 44m   v1.29.15
```

4. **파드 상태 점검**:
```
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS   ROLES                  AGE   VERSION
k1     Ready    control-plane,master   44m   v1.29.15
k2     Ready    worker                 44m   v1.29.15
k3     Ready    worker                 44m   v1.29.15
k4     Ready    worker                 44m   v1.29.15

citec@k1:~/osh$ kubectl get pods -A -o wide
NAMESPACE        NAME                                       READY   STATUS    RESTARTS        AGE   IP               NODE   NOMINATED NODE   READINESS GATES
kube-system      calico-kube-controllers-6b78c44475-8bfzf   1/1     Running   0               13m   10.244.194.133   k4     <none>           <none>
kube-system      calico-node-jdlpn                          1/1     Running   1 (9m26s ago)   25m   172.16.2.161     k4     <none>           <none>
kube-system      calico-node-pxj8c                          1/1     Running   0               25m   172.16.2.149     k1     <none>           <none>
kube-system      calico-node-strt8                          1/1     Running   1 (5m5s ago)    25m   172.16.2.52      k2     <none>           <none>
kube-system      calico-node-zlrv7                          1/1     Running   1 (2m17s ago)   25m   172.16.2.223     k3     <none>           <none>
kube-system      coredns-5c55d7d65b-2p6rp                   1/1     Running   0               14m   10.244.194.134   k4     <none>           <none>
kube-system      coredns-5c55d7d65b-5q2dp                   1/1     Running   0               14m   10.244.194.136   k4     <none>           <none>
kube-system      etcd-k1                                    1/1     Running   2               27m   172.16.2.149     k1     <none>           <none>
kube-system      kube-apiserver-k1                          1/1     Running   18              27m   172.16.2.149     k1     <none>           <none>
kube-system      kube-controller-manager-k1                 1/1     Running   13              27m   172.16.2.149     k1     <none>           <none>
kube-system      kube-proxy-g42tp                           1/1     Running   1 (9m26s ago)   26m   172.16.2.161     k4     <none>           <none>
kube-system      kube-proxy-hvhp8                           1/1     Running   1 (5m5s ago)    26m   172.16.2.52      k2     <none>           <none>
kube-system      kube-proxy-qjh87                           1/1     Running   0               27m   172.16.2.149     k1     <none>           <none>
kube-system      kube-proxy-vx5ns                           1/1     Running   1 (2m16s ago)   26m   172.16.2.223     k3     <none>           <none>
kube-system      kube-scheduler-k1                          1/1     Running   84              27m   172.16.2.149     k1     <none>           <none>
metallb-system   metallb-controller-5f9bb77dcd-5cqkx        1/1     Running   0               13m   10.244.194.135   k4     <none>           <none>
metallb-system   metallb-speaker-59qk9                      4/4     Running   4 (5m5s ago)    25m   172.16.2.52      k2     <none>           <none>
metallb-system   metallb-speaker-k6q2l                      4/4     Running   4 (9m26s ago)   25m   172.16.2.161     k4     <none>           <none>
metallb-system   metallb-speaker-mjt4s                      4/4     Running   4 (2m16s ago)   25m   172.16.2.223     k3     <none>           <none>
metallb-system   metallb-speaker-wkgnk                      4/4     Running   0               25m   172.16.2.149     k1     <none>           <none>
```
   - 모든 파드가 `Running` 상태인지 확인.

#### **2.2 마스터 노드 재부팅**
마스터 노드는 컨트롤 플레인 구성 요소를 실행하므로 더 신중히 재부팅해야 합니다. 본 문서에서는 단일 마스터 클러스터 구성에 대해서 설명합니다.

1. **재부팅 전 클러스터 상태 점검**
```
citec@k1:~/osh$ kubectl get pods -A
NAMESPACE        NAME                                       READY   STATUS    RESTARTS        AGE
kube-system      calico-kube-controllers-6b78c44475-8bfzf   1/1     Running   0               15m
kube-system      calico-node-jdlpn                          1/1     Running   1 (11m ago)     27m
kube-system      calico-node-pxj8c                          1/1     Running   0               27m
kube-system      calico-node-strt8                          1/1     Running   1 (7m6s ago)    27m
kube-system      calico-node-zlrv7                          1/1     Running   1 (4m18s ago)   27m
kube-system      coredns-5c55d7d65b-2p6rp                   1/1     Running   0               16m
kube-system      coredns-5c55d7d65b-5q2dp                   1/1     Running   0               16m
kube-system      etcd-k1                                    1/1     Running   2               29m
kube-system      kube-apiserver-k1                          1/1     Running   18              29m
kube-system      kube-controller-manager-k1                 1/1     Running   13              29m
kube-system      kube-proxy-g42tp                           1/1     Running   1 (11m ago)     28m
kube-system      kube-proxy-hvhp8                           1/1     Running   1 (7m6s ago)    29m
kube-system      kube-proxy-qjh87                           1/1     Running   0               29m
kube-system      kube-proxy-vx5ns                           1/1     Running   1 (4m17s ago)   28m
kube-system      kube-scheduler-k1                          1/1     Running   84              29m
metallb-system   metallb-controller-5f9bb77dcd-5cqkx        1/1     Running   0               15m
metallb-system   metallb-speaker-59qk9                      4/4     Running   4 (7m6s ago)    27m
metallb-system   metallb-speaker-k6q2l                      4/4     Running   4 (11m ago)     27m
metallb-system   metallb-speaker-mjt4s                      4/4     Running   4 (4m17s ago)   27m
metallb-system   metallb-speaker-wkgnk                      4/4     Running   0               27m
```

2. **재부팅 전 파드 배출**
   마스터 노드에 대한 파드 배출을 수행:
```
citec@k1:~/osh$ kubectl drain k1 --ignore-daemonsets --delete-emptydir-data --force
node/k1 cordoned
Warning: ignoring DaemonSet-managed Pods: kube-system/calico-node-jvssk, kube-system/kube-proxy-dtszk, metallb-system/metallb-speaker-cjzjv
node/k1 drained
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS                     ROLES                  AGE     VERSION
k1     Ready,SchedulingDisabled   control-plane,master   9m14s   v1.29.15
k2     Ready                      worker                 8m58s   v1.29.15
k3     Ready                      worker                 8m54s   v1.29.15
k4     Ready                      worker                 8m54s   v1.29.15
```

3. **재부팅**
```
citec@k1:~/osh$ sudo reboot
```

   재부팅 후 약 5~10분 대기 후 클러스터 상태 확인:
```
kubectl get nodes
kubectl get pods -A
```
   - `kube-apiserver`, `etcd` 등 컨트롤 플레인 파드가 정상적으로 실행 중인지 확인.

4. **마스터 노드 스케줄링 활성화**
```
kubectl uncordon k1
```

---

### **3. 재부팅 후 문제 해결**

재부팅 후 `kubectl` 명령이 작동하지 않거나 Kubernetes 서비스에 문제가 발생할 수 있습니다. 아래는 일반적인 문제와 해결 방법입니다.

#### **3.1 Forbidden 오류 발생**
- **문제**: `kubectl`이 `Error from server (Forbidden)` 오류 반환.
- **원인**:
  - 사용자가 관리자 권한을 부여받지 못해 발생.
  - Kubernetes 1.29 이상에서는 `admin.conf`가 "kubeadm:cluster-admins" 그룹을 사용하며, 이는 RBAC를 통해 관리됨. 반면, `super-admin.conf`는 "system:masters" 그룹을 포함하여 RBAC를 우회하는 비상용 관리자 권한을 제공. 본 문서의 설치에서 사용자의 경우, `admin.conf`를 사용 중이며, 이는 RBAC 바인딩에 의존하므로, 바인딩이 누락되면 "Forbidden" 오류가 발생. `super-admin.conf`는 `kubeadm init` 중 생성되며, 이는 "system:masters" 그룹을 포함하므로 관리자 권한을 자동으로 부여받음.
```
citec@k1:$ kubectl get pods -A
Error from server (Forbidden): pods is forbidden: User "kubernetes-admin" cannot list resource "pods" in API group "" at the cluster scope
citec@k1:$ kubectl get clusterrolebindings -o wide
Error from server (Forbidden): clusterrolebindings.rbac.authorization.k8s.io is forbidden: User "kubernetes-admin" cannot list resource "clusterrolebindings" in API 
group "rbac.authorization.k8s.io" at the cluster scope
```

- **해결 방법**:
  1. **임시 RBAC 비활성화**:
     `kube-apiserver.yaml` 파일에 `--authorization-mode=AlwaysAllow` 추가한 후 저장. `kube-apiserver`가 RBAC 비활성화된 상태로 재시작.
```
citec@k1:~$ sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=172.16.2.149
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --requestheader-allowed-names=front-proxy-client
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/16
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    - --authorization-mode=AlwaysAllow
```

  2. **cluster-admin 권한 부여**:
     `super-admin.conf` 파일을 사용해 현재 그룹 "kubeadm:cluster-admins"에 cluster-admin 권한을 부여.
```
citec@k1:~$ sudo KUBECONFIG=/etc/kubernetes/super-admin.conf kubectl get nodes
NAME   STATUS   ROLES    AGE    VERSION
k1     Ready    <none>   112s   v1.29.15

citec@k1:~$ sudo KUBECONFIG=/etc/kubernetes/admin.conf kubectl create clusterrolebinding admin-group-binding --clusterrole=cluster-admin --group=kubeadm:cluster-admins
clusterrolebinding.rbac.authorization.k8s.io/admin-group-binding created
```

  3. **RBAC 활성화**:
     `--authorization-mode=AlwaysAllow` 설정을 제거하여 RBAC을 활성화한 상태로 `kube-apiserver`를 재시작.
```
citec@k1:~$ sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml
```

#### **3.2 `kubectl` 명령이 작동하지 않는 경우**
- **문제**: `kubectl`이 `Unable to connect to the server` 또는 `connection refused` 오류 반환.
- **원인**:
  - `kube-apiserver`가 정상적으로 실행되지 않음.
  - `~/.kube/config` 파일의 API 서버 주소가 잘못됨.
  - 네트워크 문제 (예: Calico, Flannel).

- **해결 방법**:
  1. **API 서버 상태 확인**:
```
kubectl -n kube-system get pods -l component=kube-apiserver
```
     - `Running`이 아니면 로그 확인:
```
kubectl -n kube-system logs -l component=kube-apiserver
```

  2. **kubeconfig 확인**:
```
cat ~/.kube/config
```
     - `server` 필드의 주소가 마스터 노드의 올바른 IP와 포트(보통 6443)를 가리키는지 확인.
     - 필요 시 업데이트:
```
kubectl config set-cluster kubernetes --server=https://<MASTER_IP>:6443
```

  3. **네트워크 점검**:
```
kubectl -n kube-system get pods -l k8s-app=kube-dns
```
     - CoreDNS 파드가 실행 중인지 확인.
     - CNI 플러그인 확인 (예: Calico):
```
kubectl -n kube-system get pods -l k8s-app=calico-node
```

  4. **서비스 재시작**:
     - 마스터 노드에서 `kubelet` 재시작:
```
ssh <MASTER_NODE> sudo systemctl restart kubelet
ssh <MASTER_NODE> sudo systemctl status kubelet
```

#### **3.3 etcd 문제**
- **문제**: `etcd` 파드가 실행되지 않거나 클러스터 상태가 비정상.
- **해결 방법**:
  - `etcd` 로그 확인:
```
kubectl -n kube-system logs -l component=etcd
```
  - `etcd` 상태 점검:
```
kubectl -n kube-system exec -it etcd-<MASTER_NODE_NAME> -- etcdctl endpoint status
```
  - 문제가 지속되면 백업된 `etcd` 스냅샷 복구:
```
kubectl -n kube-system exec -it etcd-<MASTER_NODE_NAME> -- etcdctl snapshot restore /tmp/etcd-snapshot.db
```

#### **3.4 파드 재스케줄링 문제**
- **문제**: 워커 노드 재부팅 후 파드가 실행되지 않음.
- **해결 방법**:
  - 파드 상태 확인:
```
kubectl get pods -A -o wide
```
  - 드레인된 노드 확인 및 스케줄링 활성화:
```
kubectl uncordon <NODE_NAME>
```
  - 필요 시 파드 재배포:
```
kubectl delete pod <POD_NAME> -n <NAMESPACE>
```

---

### **4. 추가 안전 조치**
- **HA 클러스터 구축**: 단일 마스터 클러스터라면 HA 설정을 고려하여 마스터 노드를 최소 3개로 구성합니다. 이는 재부팅 시 서비스 중단을 방지합니다.
- **자동 복구 설정**: Kubernetes Operator 또는 `Node Problem Detector`를 사용하여 노드 장애를 자동 감지하고 복구하도록 설정.
- **모니터링**: Prometheus와 Grafana를 사용하여 클러스터 상태를 실시간 모니터링, 재부팅 후 문제를 빠르게 탐지.

---

### **결론**
안전한 Kubernetes 노드 재부팅을 위해:
1. 클러스터 상태를 점검하고 데이터를 백업합니다.
2. 노드를 `cordon` 및 `drain`하여 파드 스케줄링을 비활성화합니다.
3. 워커 노드와 마스터 노드를 순차적으로 재부팅합니다.
4. 재부팅 후 `kubectl` 및 클러스터 상태를 점검하고 문제를 해결합니다.

재부팅 후 `kubectl`이 작동하지 않는 문제를 방지하려면 `kube-apiserver`와 네트워크 상태를 우선 확인하고, 필요 시 `kubelet`을 재시작하거나 `kubeconfig`를 업데이트하세요. 추가 문제가 발생하면 다음 명령어의 출력과 오류 메시지를 공유해 주세요:
```
kubectl get nodes
kubectl get pods -A
kubectl -n kube-system logs -l component=kube-apiserver
```

원시 로그
```
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS   ROLES           AGE   VERSION
k1     Ready    control-plane   27h   v1.29.15
k2     Ready    <none>          27h   v1.29.15
k3     Ready    <none>          27h   v1.29.15
k4     Ready    <none>          27h   v1.29.15
citec@k1:~/osh$ kubectl get nodes -o wide
NAME   STATUS   ROLES           AGE   VERSION    INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME
k1     Ready    control-plane   27h   v1.29.15   172.16.2.149   <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
k2     Ready    <none>          27h   v1.29.15   172.16.2.52    <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
k3     Ready    <none>          27h   v1.29.15   172.16.2.223   <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
k4     Ready    <none>          27h   v1.29.15   172.16.2.161   <none>        Ubuntu 22.04.5 LTS   5.15.0-136-generic   containerd://1.7.27
citec@k1:~/osh$ kubectl describe nodes | grep -i "roles"
Roles:              control-plane
Roles:              <none>
Roles:              <none>
Roles:              <none>
citec@k1:~/osh$ kubectl get pods -A -o wide
NAMESPACE        NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE   NOMINATED NODE   READINESS GATES
ceph             ingress-nginx-ceph-controller-7ssh8        1/1     Running   0             24h   10.244.99.3      k2     <none>           <none>
ceph             ingress-nginx-ceph-controller-pnh5c        1/1     Running   0             24h   10.244.195.131   k3     <none>           <none>
ceph             ingress-nginx-ceph-controller-txszj        1/1     Running   0             24h   10.244.105.130   k1     <none>           <none>
ceph             ingress-nginx-ceph-controller-vfzwd        1/1     Running   0             24h   10.244.194.134   k4     <none>           <none>
kube-system      calico-kube-controllers-6b78c44475-7gm9j   1/1     Running   0             27h   10.244.194.130   k4     <none>           <none>
kube-system      calico-node-9knwk                          1/1     Running   0             27h   172.16.2.223     k3     <none>           <none>
kube-system      calico-node-ltwdm                          1/1     Running   0             27h   172.16.2.161     k4     <none>           <none>
kube-system      calico-node-qfqtq                          1/1     Running   0             27h   172.16.2.149     k1     <none>           <none>
kube-system      calico-node-z4tkv                          1/1     Running   0             27h   172.16.2.52      k2     <none>           <none>
kube-system      coredns-b87576b6c-55dr8                    1/1     Running   0             27h   10.244.195.129   k3     <none>           <none>
kube-system      coredns-b87576b6c-x2s4f                    1/1     Running   0             27h   10.244.99.1      k2     <none>           <none>
kube-system      etcd-k1                                    1/1     Running   84            27h   172.16.2.149     k1     <none>           <none>
kube-system      ingress-nginx-cluster-controller-4f7k9     1/1     Running   0             24h   172.16.2.223     k3     <none>           <none>
kube-system      ingress-nginx-cluster-controller-9bplr     1/1     Running   0             24h   172.16.2.149     k1     <none>           <none>
kube-system      ingress-nginx-cluster-controller-cxlzh     1/1     Running   0             24h   172.16.2.52      k2     <none>           <none>
kube-system      ingress-nginx-cluster-controller-gqb7r     1/1     Running   0             24h   172.16.2.161     k4     <none>           <none>
kube-system      kube-apiserver-k1                          1/1     Running   8             27h   172.16.2.149     k1     <none>           <none>
kube-system      kube-controller-manager-k1                 1/1     Running   8             27h   172.16.2.149     k1     <none>           <none>
kube-system      kube-proxy-8sw4c                           1/1     Running   0             27h   172.16.2.161     k4     <none>           <none>
kube-system      kube-proxy-lmffv                           1/1     Running   0             27h   172.16.2.52      k2     <none>           <none>
kube-system      kube-proxy-qr85k                           1/1     Running   0             27h   172.16.2.149     k1     <none>           <none>
kube-system      kube-proxy-wvcx2                           1/1     Running   0             27h   172.16.2.223     k3     <none>           <none>
kube-system      kube-scheduler-k1                          1/1     Running   79            27h   172.16.2.149     k1     <none>           <none>
metallb-system   metallb-controller-5f9bb77dcd-lbx7z        1/1     Running   0             27h   10.244.194.132   k4     <none>           <none>
metallb-system   metallb-speaker-69fvw                      4/4     Running   1 (23m ago)   27h   172.16.2.52      k2     <none>           <none>
metallb-system   metallb-speaker-lq49d                      4/4     Running   2 (22m ago)   27h   172.16.2.223     k3     <none>           <none>
metallb-system   metallb-speaker-qmhx5                      4/4     Running   0             27h   172.16.2.161     k4     <none>           <none>
metallb-system   metallb-speaker-vm7pz                      4/4     Running   0             27h   172.16.2.149     k1     <none>           <none>
openstack        ingress-nginx-openstack-controller-7v45t   1/1     Running   0             24h   10.244.194.133   k4     <none>           <none>
openstack        ingress-nginx-openstack-controller-cts8w   1/1     Running   0             24h   10.244.105.129   k1     <none>           <none>
openstack        ingress-nginx-openstack-controller-vj2kd   1/1     Running   0             24h   10.244.195.130   k3     <none>           <none>
openstack        ingress-nginx-openstack-controller-zdw66   1/1     Running   0             24h   10.244.99.2      k2     <none>           <none>
citec@k1:~/osh$ kubectl -n kube-system exec -it etcd-k1 -- etcdctl member list
error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "e0179539158515268684a8bac8ff7f8e034b30ed42bfa85ff15473446a8eb2b1": OCI runtime exec failed: exec failed: unable to start container process: apparmor failed to apply profile: write /proc/thread-self/attr/apparmor/exec: no such file or directory: unknown
citec@k1:~/osh$ kubectl -n kube-system exec -it etcd-k1 -- etcdctl snapshot save /tmp/etcd-snapshot.db
error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "526392b41917fa5e9c3d3430d9d6611c3e16b0fb7c0dccabd096d5f27e44b155": OCI runtime exec failed: exec failed: unable to start container process: apparmor failed to apply profile: write /proc/thread-self/attr/apparmor/exec: no such file or directory: unknown
citec@k1:~/osh$ kubectl cp kube-system/etcd-k1:/tmp/etcd-snapshot.db ./etcd-snapshot.db
error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "225c1caeccc435878ad19a8e55efbc9ea5846ee04b30dab9a3510de4c264fcf2": OCI runtime exec failed: exec failed: unable to start container process: apparmor failed to apply profile: write /proc/thread-self/attr/apparmor/exec: no such file or directory: unknown
citec@k1:~/osh$ kubectl get all -A -o yaml > kubernetes-resources.yaml
citec@k1:~/osh$ kubectl get configmap,secret -A -o yaml > kubernetes-configs.yaml
citec@k1:~/osh$ kubectl cordon k1
node/k1 cordoned
citec@k1:~/osh$ kubectl cordon k2
node/k2 cordoned
citec@k1:~/osh$ kubectl cordon k3
node/k3 cordoned
citec@k1:~/osh$ kubectl cordon k4
node/k4 cordoned
citec@k1:~/osh$ kubectl get nodes
NAME   STATUS                     ROLES           AGE   VERSION
k1     Ready,SchedulingDisabled   control-plane   27h   v1.29.15
k2     Ready,SchedulingDisabled   <none>          27h   v1.29.15
k3     Ready,SchedulingDisabled   <none>          27h   v1.29.15
k4     Ready,SchedulingDisabled   <none>          27h   v1.29.15
citec@k1:~/osh$ kubectl drain k1 --ignore-daemonsets --delete-emptydir-data --force
node/k1 already cordoned
Warning: ignoring DaemonSet-managed Pods: ceph/ingress-nginx-ceph-controller-txszj, kube-system/calico-node-qfqtq, kube-system/ingress-nginx-cluster-controller-9bplr, kube-system/kube-proxy-qr85k, metallb-system/metallb-speaker-vm7pz, openstack/ingress-nginx-openstack-controller-cts8w
node/k1 drained
citec@k1:~/osh$ kubectl drain k2 --ignore-daemonsets --delete-emptydir-data --force
node/k2 already cordoned
Warning: ignoring DaemonSet-managed Pods: ceph/ingress-nginx-ceph-controller-7ssh8, kube-system/calico-node-z4tkv, kube-system/ingress-nginx-cluster-controller-cxlzh, kube-system/kube-proxy-lmffv, metallb-system/metallb-speaker-69fvw, openstack/ingress-nginx-openstack-controller-zdw66
evicting pod kube-system/coredns-b87576b6c-x2s4f
pod/coredns-b87576b6c-x2s4f evicted
node/k2 drained
citec@k1:~/osh$ kubectl drain k3 --ignore-daemonsets --delete-emptydir-data --force
node/k3 already cordoned
Warning: ignoring DaemonSet-managed Pods: ceph/ingress-nginx-ceph-controller-pnh5c, kube-system/calico-node-9knwk, kube-system/ingress-nginx-cluster-controller-4f7k9, kube-system/kube-proxy-wvcx2, metallb-system/metallb-speaker-lq49d, openstack/ingress-nginx-openstack-controller-vj2kd
evicting pod kube-system/coredns-b87576b6c-55dr8
pod/coredns-b87576b6c-55dr8 evicted
node/k3 drained
citec@k1:~/osh$ kubectl drain k4 --ignore-daemonsets --delete-emptydir-data --force
node/k4 already cordoned
Warning: ignoring DaemonSet-managed Pods: ceph/ingress-nginx-ceph-controller-vfzwd, kube-system/calico-node-ltwdm, kube-system/ingress-nginx-cluster-controller-gqb7r, kube-system/kube-proxy-8sw4c, metallb-system/metallb-speaker-qmhx5, openstack/ingress-nginx-openstack-controller-7v45t
evicting pod metallb-system/metallb-controller-5f9bb77dcd-lbx7z
evicting pod kube-system/calico-kube-controllers-6b78c44475-7gm9j
pod/metallb-controller-5f9bb77dcd-lbx7z evicted
pod/calico-kube-controllers-6b78c44475-7gm9j evicted
node/k4 drained
```
