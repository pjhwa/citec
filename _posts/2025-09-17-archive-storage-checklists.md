---
title: "archive storage checklist (draft)"
date: 2025-09-17
tags: [storage, archive, ceph, cloud, checklist]
categories: [Howtos, Storage]
---

## 구성

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|---------------|----------|------|
| 버킷 이름의 유효성 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: name 필드가 3~63자 영문/숫자/하이픈 조합임<br>취약: name 필드가 빈 값 또는 허용되지 않는 문자 포함임 | 버킷 이름이 유효하지 않으면 API 호출 시 오류 발생으로 데이터 접근 지연이나 실패가 발생하며, 장기적으로 버킷 관리 혼란을 초래함 | 버킷 재생성 시 유효한 이름으로 설정하고, 기존 버킷 삭제 후 재생성함 | * 확인방법: showbucket 명령어로 name 필드 출력 확인<br>* References<br>- Ceph Object Gateway Bucket Naming Conventions: https://docs.ceph.com/en/latest/radosgw/s3/bucketops/#create-bucket (버킷 이름 규칙 설명, S3 호환으로 SCP Archive Storage에도 적용됨) |
| 버킷 태그 설정 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: tags 필드가 비어있지 않고 key-value 쌍으로 구성됨<br>취약: tags 필드가 없거나 빈 배열임 | 태그가 없으면 비용 추적과 리소스 분류가 어려워 운영 비용 과다 청구나 감사 시 문제 발생함 | 버킷 생성 또는 수정 시 tags 파라미터에 적절한 key-value 추가함 | * 설정방법: createbucket 시 --tags '{"key":"value"}' 옵션 사용<br>* References<br>- S3 Bucket Tagging Best Practices: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-tagging.html (태그 관리 가이드, Ceph/S3 호환) |
| 버킷 상태 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: state 필드가 ACTIVE임<br>취약: state 필드가 INACTIVE 또는 ERROR임 | 상태가 비정상 시 데이터 접근 불가로 아카이빙/복구 작업 실패와 데이터 손실 위험이 있음 | 상태 이상 시 MSP에 문의하여 상태 복구 요청함 | * 확인방법: showbucket 명령어로 state 필드 출력<br>* References<br>- Ceph RGW Bucket Lifecycle: https://docs.ceph.com/en/quincy/radosgw/lifecycle/ (버킷 상태 관리 설명) |
| 아카이빙 소스 버킷 이름 설정 확인 | scpcli archivestorage archiving policy show --archiving_policy_id <policy_id> --bucket_id <bucket_id> | 정상: archiving_source_bucket_name 필드가 유효한 Object Storage 버킷 이름임<br>취약: archiving_source_bucket_name 필드가 빈 값임 | 소스 버킷 이름이 없으면 아카이빙 정책 실행 시 소스 데이터 인식 실패로 아카이빙 누락 발생함 | 정책 생성/수정 시 유효한 소스 버킷 이름 지정함 | * 설정방법: createarchivingpolicy 시 --archiving_source_bucket_name <name> 옵션 사용<br>* References<br>- Archive Storage Archiving Policy Guide: https://docs.ceph.com/en/latest/radosgw/s3/lifecycle/ (라이프사이클 정책 소스 설정) |
| 아카이빙 정책의 object_lifecycle 값 확인 | scpcli archivestorage archiving policy show --archiving_policy_id <policy_id> --bucket_id <bucket_id> | 정상: object_lifecycle 값이 1 이상의 정수임<br>취약: object_lifecycle 값이 0 이하임 | lifecycle 값이 부적절하면 오브젝트가 너무 일찍 또는 늦게 아카이빙되어 비용 증가나 데이터 접근 지연 발생함 | 정책 수정 시 적절한 일수(예: 30)로 object_lifecycle 설정함 | * 설정방법: setarchivingpolicy 시 --object_lifecycle <days> 옵션 사용<br>* References<br>- S3 Lifecycle Configuration: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html (라이프사이클 일수 베스트 프랙티스) |
| 아카이빙 정책의 object_path 설정 확인 | scpcli archivestorage archiving policy show --archiving_policy_id <policy_id> --bucket_id <bucket_id> | 정상: object_path가 / 또는 특정 경로로 설정됨<br>취약: object_path가 빈 값임 | path가 없으면 전체 오브젝트가 대상이 되어 불필요한 아카이빙으로 성능 저하와 비용 증가함 | 정책 생성 시 필요한 경로만 지정하여 object_path 설정함 | * 설정방법: createarchivingpolicy 시 --object_path <path> 옵션 사용<br>* References<br>- Ceph RGW Prefix Filtering: https://docs.ceph.com/en/reef/radosgw/s3/#prefix (경로 필터링 설명) |
| 버킷 암호화 활성화 확인 | scpcli archivestorage bucket encryption show --bucket_id <bucket_id> | 정상: enabled 필드가 True임<br>취약: enabled 필드가 False임 | 암호화 비활성화 시 데이터 유출 위험이 증가하며, 규정 준수 위반으로 벌금 발생 가능함 | 버킷 수정 시 암호화 활성화로 enabled=True 설정함 | * 설정방법: setbucketencryption 시 --enabled True 옵션 사용<br>* References<br>- Ceph Server-Side Encryption: https://docs.ceph.com/en/latest/radosgw/s3/#server-side-encryption (SSE 설정 가이드) |
| 아카이빙 정책 목록 존재 확인 | scpcli archivestorage archiving policy list --bucket_id <bucket_id> | 정상: 목록에 1개 이상 정책 출력됨<br>취약: 목록이 빈 배열임 | 정책이 없으면 자동 아카이빙이 수행되지 않아 Object Storage 용량 초과와 비용 증가함 | 버킷에 적절한 아카이빙 정책 생성함 | * 확인방법: listarchivingpolicies 명령어 실행 후 id 필드 확인<br>* References<br>- S3 Lifecycle Policies: https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-configuration-examples.html (정책 목록 관리) |
| 복구 대상 버킷 이름 설정 확인 | scpcli archivestorage recovery history show --bucket_id <bucket_id> --id <history_id> | 정상: recovery_target_bucket_name 필드가 유효한 이름임<br>취약: recovery_target_bucket_name 필드가 없음 | 대상 버킷이 지정되지 않으면 복구 작업 실패로 데이터 복원 지연 발생함 | 복구 요청 시 유효한 대상 버킷 이름 지정함 | * 설정방법: recoverobjects 시 --recovery_target_bucket_name <name> 옵션 사용<br>* References<br>- Archive Restore Targets: https://docs.ceph.com/en/quincy/radosgw/s3/#restore-objects (복구 대상 설정) |
| 오브젝트 복구 overwrite 설정 확인 | scpcli archivestorage recovery history show --bucket_id <bucket_id> --id <history_id> | 정상: overwrite가 True로 설정됨 (중복 시 처리)<br>취약: overwrite가 False임 | overwrite 비활성화 시 기존 파일 덮어쓰기 실패로 데이터 불일치와 복구 오류 발생함 | 복구 시 overwrite=True로 설정하여 기존 데이터 덮어쓰기 허용함 | * 설정방법: recoverobjects 시 --overwrite True 옵션 사용<br>* References<br>- S3 Restore Overwrite: https://docs.aws.amazon.com/AmazonS3/latest/API/API_RestoreObject.html (복구 옵션 설명) |
| recovery_infos 배열 형식 확인 | scpcli archivestorage recovery history show --bucket_id <bucket_id> --id <history_id> | 정상: recovery_infos가 JSON 배열 형식임<br>취약: recovery_infos가 빈 배열 또는 잘못된 형식임 | infos 형식이 잘못되면 특정 오브젝트 복구 실패로 부분 데이터 손실 발생함 | 복구 요청 시 올바른 JSON 형식으로 recovery_infos 지정함 | * 설정방법: recoverobjects 시 --recovery_infos '[{"object_type":"FILE","source_object_path":"/"}]' 사용<br>* References<br>- Ceph Object Restore JSON: https://docs.ceph.com/en/latest/radosgw/s3/#restore-object (JSON 파라미터 가이드) |
| 버킷 사용량 모니터링 기준 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: usage 값이 예상 범위 내 (예: 0~TB 단위)<br>취약: usage가 급증하거나 비정상임 | 사용량 초과 시 추가 비용 발생과 아카이빙 지연으로 서비스 중단 위험이 있음 | 정기적으로 usage 확인 후 정책 조정함 | * 확인방법: showbucket 명령어로 usage 필드 출력<br>* References<br>- S3 Storage Monitoring: https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html (사용량 모니터링 베스트 프랙티스) |
| 아카이빙 정책 ID 유효성 확인 | scpcli archivestorage archiving policy show --archiving_policy_id <policy_id> --bucket_id <bucket_id> | 정상: id 필드가 SCH- 형식으로 유효함<br>취약: id 필드가 존재하지 않음 | 정책 ID 무효 시 정책 적용 실패로 아카이빙 누락과 데이터 관리 오류 발생함 | 유효한 정책 ID로 재지정함 | * 확인방법: showarchivingpolicy 명령어 실행<br>* References<br>- Ceph Policy IDs: https://docs.ceph.com/en/reef/radosgw/lifecycle/#lifecycle-policy (정책 ID 관리) |
| 버킷 오브젝트 경로 설정 확인 | scpcli archivestorage bucket object list --bucket_id <bucket_id> --object_path <path> | 정상: object_path가 지정된 경로 출력됨<br>취약: object_path가 무시됨 | 경로 설정 오류 시 불필요한 오브젝트 목록 조회로 성능 저하 발생함 | list 시 적절한 object_path 지정함 | * 설정방법: listbucketobjects 시 --object_path <path> 옵션 사용<br>* References<br>- S3 Prefix Queries: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html (경로 쿼리 설명) |
| 아카이빙 이력 상태 확인 | scpcli archivestorage archiving history show --bucket_id <bucket_id> --id <history_id> | 정상: state 필드가 SUCCESS임<br>취약: state 필드가 FAILED임 | 이력 상태 실패 시 아카이빙 데이터 불완전으로 복구 시 데이터 손실 발생함 | 실패 이력 취소 후 재실행함 | * 확인방법: showarchivinghistory 명령어로 state 필드 확인<br>* References<br>- Ceph Archiving Status: https://docs.ceph.com/en/latest/radosgw/s3/#lifecycle-transition (전환 상태 관리) |
| 복구 이력 진행률 확인 | scpcli archivestorage recovery history show --bucket_id <bucket_id> --id <history_id> | 정상: recovery_rate가 100%임<br>취약: recovery_rate가 0% 또는 저조함 | 진행률 저조 시 복구 지연으로 비즈니스 연속성 위협받음 | 진행률 모니터링 후 취소/재시도함 | * 확인방법: showrecoveryhistory 명령어로 recovery_rate 필드 출력<br>* References<br>- S3 Restore Progress: https://docs.aws.amazon.com/AmazonS3/latest/API/API_RestoreObject.html#API_RestoreObject_ResponseSyntax (진행률 추적) |
| 버킷 오브젝트 타입 확인 | scpcli archivestorage bucket object list --bucket_id <bucket_id> --object_type FILE | 정상: object_type이 FILE 또는 DIR로 출력됨<br>취약: object_type이 UNKNOWN임 | 타입 오류 시 오브젝트 처리 실패로 삭제/복구 작업 오류 발생함 | list 시 object_type 필터 적용함 | * 설정방법: listbucketobjects 시 --object_type <type> 옵션 사용<br>* References<br>- Ceph Object Types: https://docs.ceph.com/en/quincy/radosgw/s3/#object-metadata (오브젝트 메타데이터) |
| 아카이빙 정책 수정 가능성 확인 | scpcli archivestorage archiving policy set --archiving_policy_id <policy_id> --bucket_id <bucket_id> --object_lifecycle <new_value> | 정상: 명령 실행 후 에러 없음<br>취약: 명령 실행 시 에러 발생 | 정책 수정 불가 시 유연한 lifecycle 조정 어려워 비용 최적화 실패함 | 정책 수정 명령으로 object_lifecycle 업데이트함 | * 확인방법: setarchivingpolicy 명령어 테스트 실행<br>* References<br>- S3 Policy Updates: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt-update.html (정책 수정 가이드) |
| 버킷 삭제 전 오브젝트 확인 | scpcli archivestorage bucket object list --bucket_id <bucket_id> --limit 1 | 정상: 목록에 오브젝트 존재 시 삭제 전 확인됨<br>취약: 삭제 시 오브젝트 잔여 확인 안됨 | 삭제 시 잔여 오브젝트로 데이터 손실이나 비용 누적 발생함 | 삭제 전 listbucketobjects로 오브젝트 확인 후 삭제함 | * 확인방법: listbucketobjects 명령어로 paths 확인<br>* References<br>- S3 Bucket Deletion Safety: https://docs.aws.amazon.com/AmazonS3/latest/userguide/delete-bucket.html (삭제 전 확인) |
| 아카이빙 취소 가능성 확인 | scpcli archivestorage archiving history cancel --bucket_id <bucket_id> --id <history_id> | 정상: 명령 실행 후 상태 변경됨<br>취약: 취소 시 에러 발생 | 취소 불가 시 실패 아카이빙 지속으로 리소스 낭비 발생함 | 진행 중 이력 취소 명령 실행함 | * 확인방법: cancelarchiving 명령어 테스트<br>* References<br>- Ceph Operation Cancellation: https://docs.ceph.com/en/latest/radosgw/s3/#abort-multipart-upload (작업 취소 유사) |
| 복구 취소 가능성 확인 | scpcli archivestorage recovery history cancel --bucket_id <bucket_id> --id <history_id> | 정상: 명령 실행 성공<br>취약: 취소 실패 | 복구 취소 불가 시 불필요한 복구 비용과 시간 낭비함 | cancelrecovery 명령으로 취소함 | * 확인방법: cancelrecovery 명령어 실행<br>* References<br>- S3 Restore Abort: https://docs.aws.amazon.com/AmazonS3/latest/API/API_AbortMultipartUpload.html (복구 취소 유사) |
| 버킷 목록 limit 설정 확인 | scpcli archivestorage bucket list --limit 20 | 정상: limit 값이 1000 이하로 제한됨<br>취약: limit이 과도하게 큼 | limit 과다 시 API 응답 지연으로 운영 효율 저하함 | list 시 적절한 limit (예: 20) 지정함 | * 설정방법: listbuckets 시 --limit <value> 옵션 사용<br>* References<br>- S3 List Limits: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListBuckets.html (목록 제한 베스트 프랙티스) |
| 아카이빙 이력 검색 기간 확인 | scpcli archivestorage archiving history list --start_at_from <from> --start_at_to <to> --bucket_id <bucket_id> | 정상: 기간 내 이력 출력됨<br>취약: 기간 설정 오류로 빈 결과 | 검색 기간 잘못 시 이력 추적 어려워 문제 진단 지연함 | listarchivinghistories 시 적절한 from/to 지정함 | * 확인방법: listarchivinghistories 명령어로 start_at 확인<br>* References<br>- Ceph History Queries: https://docs.ceph.com/en/reef/radosgw/s3/#list-buckets (기간 쿼리) |
| 복구 이력 offset 설정 확인 | scpcli archivestorage recovery history list --offset 0 --bucket_id <bucket_id> | 정상: offset이 0부터 순차적임<br>취약: offset 무시됨 | offset 오류 시 중복/누락 이력으로 모니터링 불완전함 | listrecoveryhistories 시 --offset <value> 사용함 | * 설정방법: listrecoveryhistories 시 --offset <value> 옵션<br>* References<br>- S3 Pagination: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html#API_ListObjectsV2_ResponseElements (오프셋 페이징) |
| 오브젝트 삭제 경로 확인 | scpcli archivestorage bucket object delete --bucket_id <bucket_id> --paths <path> | 정상: paths 배열이 유효함<br>취약: paths 빈 배열 | 삭제 경로 오류 시 잔여 오브젝트로 용량 초과 발생함 | deletebucketobjects 시 올바른 paths 지정함 | * 확인방법: deletebucketobjects 명령어 테스트<br>* References<br>- Ceph Object Deletion: https://docs.ceph.com/en/latest/radosgw/s3/#delete-object (삭제 경로 가이드) |
| 마커 기반 오브젝트 목록 확인 | scpcli archivestorage bucket object list --bucket_id <bucket_id> --marker <marker> | 정상: marker 이후 오브젝트 출력됨<br>취약: marker 무효 | 마커 오류 시 전체 목록 재조회로 성능 저하함 | listbucketobjects 시 --marker <value> 사용함 | * 설정방법: listbucketobjects 시 --marker <file> 옵션<br>* References<br>- S3 Continuation Markers: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html (마커 페이징) |
| 아카이빙 소스 경로 확인 | scpcli archivestorage archiving history show --bucket_id <bucket_id> --id <history_id> | 정상: source_object_path가 / 또는 지정 경로임<br>취약: source_object_path 빈 값 | 소스 경로 없음 시 아카이빙 대상 누락으로 데이터 불일치함 | showarchivinghistory로 path 확인 후 정책 조정함 | * 확인방법: showarchivinghistory 명령어로 source_object_path 필드<br>* References<br>- Archive Source Paths: https://docs.ceph.com/en/quincy/radosgw/s3/#transition-actions (소스 경로 전환) |

## 결함 및 오류

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|---------------|----------|------|
| 아카이빙 이력 실패 상태 확인 | scpcli archivestorage archiving history list --start_at_from 2025-09-01T00:00:00+09:00 --start_at_to 2025-09-17T23:59:59+09:00 --bucket_id <bucket_id> --state FAILED --limit 10 --offset 0 | 정상: 목록에 FAILED 상태 이력 없음<br>취약: 목록에 FAILED 상태 이력 1개 이상 출력됨 | 아카이빙 이력이 실패 상태로 남아있으면 아카이빙된 오브젝트가 불완전하게 처리되어 데이터 무결성 손상과 후속 복구 작업 시 오류가 발생하며, 장기적으로 저장 용량 낭비와 재작업 비용 증가를 초래함 | 실패 이력을 취소하거나 재실행하여 상태를 SUCCESS로 변경하고, 원인 분석 후 정책 재설정함 | * 확인방법: listarchivinghistories 명령어로 state 필드 확인<br>* References<br>- Ceph RGW Troubleshooting: https://docs.ceph.com/en/latest/radosgw/troubleshooting/ (RGW 데몬 통신 오류 및 상태 확인 가이드, 실패 이력 진단 방법 설명) |
| 복구 이력 실패 상태 확인 | scpcli archivestorage recovery history list --start_at_from 2025-09-01T00:00:00+09:00 --start_at_to 2025-09-17T23:59:59+09:00 --bucket_id <bucket_id> --state FAILED --limit 10 --offset 0 | 정상: 목록에 FAILED 상태 이력 없음<br>취약: 목록에 FAILED 상태 이력 1개 이상 출력됨 | 복구 이력 실패 시 복원된 오브젝트가 누락되어 데이터 복구 불완전으로 비즈니스 연속성 위협과 데이터 손실 리스크가 증가하며, 반복 실패로 복구 시간 지연과 추가 비용 발생함 | 실패 이력 취소 후 recovery_infos를 재검토하여 복구 작업 재시도함 | * 확인방법: listrecoveryhistories 명령어로 state 필드 확인<br>* References<br>- Red Hat Ceph Troubleshooting Multisite: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/4/html/troubleshooting_guide/troubleshooting-a-multisite-ceph-object-gateway (복구 실패 상태 처리 및 재시도 베스트 프랙티스) |
| 아카이빙 진행률 미완료 확인 | scpcli archivestorage archiving history show --bucket_id <bucket_id> --id <history_id> | 정상: archiving_rate 필드가 100임<br>취약: archiving_rate 필드가 100 미만임 | 아카이빙 진행률이 미완료 상태로 멈추면 부분 아카이빙으로 인해 소스 오브젝트와 아카이브 데이터 불일치 발생, 후속 정책 적용 시 중복 처리나 누락 오류가 발생하며 시스템 리소스 낭비를 초래함 | 진행 중 이력을 취소하고 재아카이빙 실행하여 100% 완료 보장함 | * 확인방법: showarchivinghistory 명령어로 archiving_rate 필드 출력<br>* References<br>- Ceph Object Gateway Error Codes: https://www.ibm.com/docs/en/storage-ceph/8.0.0?topic=gateway-error-code-definitions-ceph-object (진행률 오류 코드 및 취소 방법 설명) |
| 복구 진행률 미완료 확인 | scpcli archivestorage recovery history show --bucket_id <bucket_id> --id <history_id> | 정상: recovery_rate 필드가 100임<br>취약: recovery_rate 필드가 100 미만임 | 복구 진행률 미완료 시 복원 오브젝트가 불완전하게 생성되어 애플리케이션에서 데이터 접근 실패가 발생하며, 장기적으로 복구 지연과 데이터 무결성 문제로 운영 중단 위험이 있음 | 복구 이력 취소 후 overwrite 옵션을 재설정하여 재복구 시도함 | * 확인방법: showrecoveryhistory 명령어로 recovery_rate 필드 출력<br>* References<br>- SUSE Ceph Troubleshooting Object Gateway: https://documentation.suse.com/ses/7.1/html/ses-all/bp-troubleshooting-objectgateway.html (진행률 모니터링 및 취소 베스트 프랙티스) |
| 버킷 상태 오류 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: state 필드가 ACTIVE임<br>취약: state 필드가 ERROR 또는 INACTIVE임 | 버킷 상태가 오류로 전환되면 모든 아카이빙 및 복구 작업이 중단되어 데이터 접근 불가와 작업 큐 지연이 발생하며, 클러스터 불안정으로 인해 전체 스토리지 서비스 영향이 확대됨 | MSP에 상태 복구 요청 후 정책 재적용으로 ACTIVE 상태 복원함 | * 확인방법: showbucket 명령어로 state 필드 확인<br>* References<br>- Ceph Health Checks: https://docs.ceph.com/en/reef/rados/operations/health-checks/ (버킷 상태 오류 진단 및 복구 가이드) |
| 아카이빙 정책 ID 무효 확인 | scpcli archivestorage archiving policy show --archiving_policy_id <policy_id> --bucket_id <bucket_id> | 정상: id 필드가 SCH- 형식으로 유효함<br>취약: id 필드가 존재하지 않거나 형식 오류임 | 정책 ID 무효 시 정책 조회 및 적용 실패로 아카이빙 스케줄링 오류가 발생하며, 오브젝트 전환이 누락되어 용량 초과와 비용 증가를 초래함 | 유효한 정책 ID로 재생성하거나 setarchivingpolicy로 수정함 | * 확인방법: showarchivingpolicy 명령어 실행 시 id 필드 확인<br>* References<br>- Ceph RGW Lifecycle Policy Errors: https://docs.ceph.com/en/latest/radosgw/lifecycle/ (정책 ID 형식 오류 및 재설정 방법) |
| 아카이빙 소스 버킷 이름 오류 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: archiving_source_bucket_name 필드가 유효한 Object Storage 버킷 이름임<br>취약: archiving_source_bucket_name 필드가 빈 값 또는 무효 형식임 | 소스 버킷 이름 오류 시 아카이빙 소스 인식 실패로 데이터 전환 불가, 정책 실행 중 예외 발생과 로그 오염으로 문제 진단 지연이 발생함 | 소스 버킷 이름을 재지정하고 createarchivingpolicy로 정책 재생성함 | * 확인방법: showbucket 명령어로 archiving_source_bucket_name 필드 출력<br>* References<br>- Ceph Multi-Site Troubleshooting: https://www.ibm.com/docs/en/storage-ceph/8.0.0?topic=troubleshooting-multi-site-ceph-object-gateway (소스 설정 오류 처리) |
| object_lifecycle 값 이상 확인 | scpcli archivestorage archiving policy show --archiving_policy_id <policy_id> --bucket_id <bucket_id> | 정상: object_lifecycle 값이 1 이상의 유효 정수임<br>취약: object_lifecycle 값이 0 이하 또는 비숫자임 | lifecycle 값 이상 시 아카이빙 타이밍 오류로 오브젝트가 조기/지연 아카이빙되어 접근 지연이나 용량 과부하가 발생하며, 정책 실행 로그에 반복 오류 메시지 생성됨 | setarchivingpolicy 명령으로 적절한 일수 값(예: 30)으로 수정함 | * 확인방법: showarchivingpolicy 명령어로 object_lifecycle 필드 확인<br>* References<br>- Ceph Erasure Code Errors: https://docs.ceph.com/en/reef/rados/operations/erasure-code/ (라이프사이클 값 검증 베스트 프랙티스) |
| 암호화 활성화 오류 확인 | scpcli archivestorage bucket encryption show --bucket_id <bucket_id> | 정상: enabled 필드가 True임<br>취약: enabled 필드가 False임 | 암호화 비활성화 오류 시 데이터 암호화 실패로 보안 취약점이 노출되어 규정 위반과 데이터 유출 리스크가 증가하며, 복구 시 암호화 키 불일치 오류 발생함 | setbucketencryption 명령으로 enabled=True 설정함 | * 확인방법: showbucketencryption 명령어로 enabled 필드 출력<br>* References<br>- Ceph Server-Side Encryption Troubleshooting: https://docs.ceph.com/en/latest/radosgw/s3/#server-side-encryption (암호화 오류 코드 및 활성화 가이드) |
| 오브젝트 목록 조회 오류 확인 | scpcli archivestorage bucket object list --bucket_id <bucket_id> --limit 1 | 정상: 목록에 오브젝트 출력됨<br>취약: 에러 메시지 출력 또는 빈 목록(예상 오브젝트 존재 시) | 오브젝트 목록 조회 실패 시 관리 작업 중단으로 삭제/모니터링 불가, RGW 통신 오류로 클러스터 연결 문제 확대됨 | bucket_id 재확인 후 listbucketobjects 재실행, MSP에 통신 로그 요청함 | * 확인방법: listbucketobjects 명령어 실행 결과 확인<br>* References<br>- Ceph RGW Common Errors: https://docs.ceph.com/en/latest/radosgw/troubleshooting/ (조회 API 오류 진단) |
| 오브젝트 삭제 작업 실패 확인 | scpcli archivestorage bucket object delete --bucket_id <bucket_id> --paths '["test/"]' (테스트 후 실제 paths 사용) | 정상: 명령 성공(응답 없음)<br>취약: 에러 메시지 출력(예: paths 무효) | 삭제 실패 시 잔여 오브젝트로 용량 누적과 비용 증가, 후속 아카이빙 시 중복 오류 발생함 | paths 배열 형식 재검토 후 deletebucketobjects 재실행함 | * 확인방법: deletebucketobjects 명령어 에러 확인<br>* References<br>- Red Hat Ceph Delete Object Errors: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/5/html/troubleshooting_guide/troubleshooting-a-multisite-ceph-object-gateway (삭제 경로 오류 처리) |
| 아카이빙 취소 실패 확인 | scpcli archivestorage archiving history cancel --bucket_id <bucket_id> --id <history_id> | 정상: 명령 성공<br>취약: 에러 메시지 출력(예: 이력 ID 무효) | 취소 실패 시 실패 아카이빙이 지속되어 리소스 낭비와 큐 지연, 후속 작업 충돌 발생함 | history_id 재확인 후 cancelarchiving 재시도함 | * 확인방법: cancelarchiving 명령어 결과 확인<br>* References<br>- Ceph Operation Cancellation: https://docs.ceph.com/en/latest/radosgw/s3/#abort-multipart-upload (취소 작업 오류 유사 가이드) |
| 복구 취소 실패 확인 | scpcli archivestorage recovery history cancel --bucket_id <bucket_id> --id <history_id> | 정상: 명령 성공<br>취약: 에러 메시지 출력 | 복구 취소 실패 시 불필요한 복구가 계속되어 비용 과다와 타겟 버킷 오염 발생함 | recovery_id 검증 후 cancelrecovery 재실행함 | * 확인방법: cancelrecovery 명령어 에러 확인<br>* References<br>- SUSE Ceph Restore Abort: https://documentation.suse.com/ses/7.1/html/ses-all/bp-troubleshooting-objectgateway.html (복구 취소 오류) |
| 버킷 사용량 불일치 오류 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: usage 값이 예상 범위(오브젝트 합계와 일치)임<br>취약: usage 값이 0 또는 비정상 급증임 | 사용량 불일치 시 청구 오류와 용량 모니터링 실패로 초과 비용 발생, 아카이빙 데이터 무결성 문제로 이어짐 | usage 로그 분석 후 MSP에 용량 동기화 요청함 | * 확인방법: showbucket 명령어로 usage 필드와 오브젝트 list 비교<br>* References<br>- Ceph OSD Troubleshooting: https://docs.ceph.com/en/octopus/rados/troubleshooting/troubleshooting-osd/ (용량 계산 오류 진단) |
| object_path 형식 오류 확인 | scpcli archivestorage archiving policy list --bucket_id <bucket_id> | 정상: object_path가 / 또는 유효 경로 형식임<br>취약: object_path가 빈 값 또는 특수 문자 포함임 | path 형식 오류 시 정책 적용 범위 오류로 불필요한 아카이빙 또는 누락 발생, 로그에 반복 경로 파싱 에러 생성됨 | 정책 수정 시 유효 path 지정함 | * 확인방법: listarchivingpolicies 명령어로 object_path 필드 확인<br>* References<br>- Ceph Prefix Filtering Errors: https://docs.ceph.com/en/reef/radosgw/s3/#prefix (경로 형식 오류 처리) |
| tags 파싱 오류 확인 | scpcli archivestorage bucket show --bucket_id <bucket_id> | 정상: tags 필드가 유효 JSON 배열임<br>취약: tags 필드가 파싱 에러 또는 빈 값임 | 태그 파싱 실패 시 비용 추적 불가와 리소스 분류 오류, 감사 시 준수 위반 발생함 | tags 재설정으로 유효 key-value 쌍 적용함 | * 확인방법: showbucket 명령어로 tags 필드 출력 확인<br>* References<br>- Ceph Object Metadata Errors: https://docs.ceph.com/en/quincy/radosgw/s3/#object-metadata (태그 파싱 트러블슈팅) |
| 마커 무효 오류 확인 | scpcli archivestorage bucket object list --bucket_id <bucket_id> --marker <invalid_marker> | 정상: 유효 마커 시 다음 페이지 출력<br>취약: 무효 마커로 에러 출력 | 마커 무효 시 페이징 실패로 대량 오브젝트 관리 불가, 전체 목록 재조회로 성능 저하 발생함 | 마커 값을 object_name에서 추출하여 재지정함 | * 확인방법: listbucketobjects 명령어 에러 확인<br>* References<br>- Ceph List Objects Pagination: https://docs.ceph.com/en/latest/radosgw/s3/#list-objects (마커 오류 가이드) |
| limit 값 초과 오류 확인 | scpcli archivestorage bucket list --limit 1001 | 정상: limit 1000 이하 시 정상 출력<br>취약: limit 1000 초과 시 에러 출력 | limit 초과 시 API 호출 실패로 버킷 관리 지연, 대량 작업 시 중단과 재시도 부하 증가함 | limit을 1000 이하로 제한하여 실행함 | * 확인방법: listbuckets 명령어 결과 확인<br>* References<br>- Ceph API Limits: https://docs.ceph.com/en/reef/radosgw/s3/#list-buckets (쿼리 제한 오류) |
| offset 값 오류 확인 | scpcli archivestorage archiving history list --start_at_from 2025-09-01T00:00:00+09:00 --start_at_to 2025-09-17T23:59:59+09:00 --bucket_id <bucket_id> --offset -1 | 정상: offset 0 이상 시 정상 페이징<br>취약: offset 음수 또는 초과 시 에러 출력 | offset 오류 시 이력 검색 누락으로 문제 추적 실패, 로그 분석 지연과 장애 재발 리스크 증가함 | offset을 0부터 순차 적용함 | * 확인방법: listarchivinghistories 명령어 에러 확인<br>* References<br>- Ceph Pagination Errors: https://docs.ceph.com/en/latest/radosgw/s3/#list-objects-v2 (오프셋 트러블슈팅) |
| 타임스탬프 형식 오류 확인 | scpcli archivestorage archiving history list --start_at_from invalid_date --start_at_to 2025-09-17T23:59:59+09:00 --bucket_id <bucket_id> | 정상: ISO 형식 타임스탬프 출력<br>취약: 형식 오류 시 에러 출력 | 타임스탬프 무효 시 이력 검색 실패로 기간 내 오류 누락, 모니터링 공백과 장애 탐지 지연 발생함 | from/to 값을 ISO 8601 형식으로 재입력함 | * 확인방법: listarchivinghistories 명령어 에러 확인<br>* References<br>- Ceph Time Queries: https://docs.ceph.com/en/reef/radosgw/s3/#date-time (타임스탬프 형식 오류) |
| overwrite 설정 오류 확인 | scpcli archivestorage bucket object recover --bucket_id <bucket_id> --recovery_target_bucket_name <target> --recovery_infos '[{"object_type":"FILE","source_object_path":"/"}]' --overwrite False (테스트) | 정상: overwrite True 시 성공<br>취약: False 시 중복 에러 출력 | overwrite False 시 기존 오브젝트 충돌로 복구 실패, 데이터 불일치와 반복 재시도 오류 발생함 | overwrite=True로 설정하여 덮어쓰기 허용함 | * 확인방법: recoverobjects 명령어 에러 확인<br>* References<br>- Ceph Restore Overwrite: https://docs.ceph.com/en/latest/radosgw/s3/#restore-object (overwrite 옵션 오류) |
| recovery_infos JSON 형식 오류 확인 | scpcli archivestorage bucket object recover --bucket_id <bucket_id> --recovery_target_bucket_name <target> --recovery_infos invalid_json --overwrite True | 정상: 유효 JSON 배열 출력<br>취약: 형식 오류 시 파싱 에러 출력 | infos JSON 무효 시 복구 대상 지정 실패로 부분 복구 불가, 작업 로그 오염과 데이터 손실 리스크 증가함 | recovery_infos를 '[{"object_type":"FILE","source_object_path":"/"}]' 형식으로 수정함 | * 확인방법: recoverobjects 명령어 에러 확인<br>* References<br>- Ceph JSON Parameter Errors: https://docs.ceph.com/en/latest/radosgw/s3/#restore-object (JSON 형식 트러블슈팅) |
| 아카이빙 소스 경로 불일치 확인 | scpcli archivestorage archiving history show --bucket_id <bucket_id> --id <history_id> | 정상: source_object_path가 정책 object_path와 일치함<br>취약: source_object_path 불일치임 | 소스 경로 불일치 시 아카이빙 대상 오류로 잘못된 데이터 전환, 무결성 손상과 복구 시 버전 충돌 발생함 | 정책 object_path 재설정 후 재아카이빙함 | * 확인방법: showarchivinghistory와 showarchivingpolicy 비교<br>* References<br>- Ceph Transition Actions: https://docs.ceph.com/en/latest/radosgw/lifecycle/#transition-actions (경로 불일치 오류) |
| 총 오브젝트 수 vs 아카이빙 수 불일치 확인 | scpcli archivestorage archiving history show --bucket_id <bucket_id> --id <history_id> | 정상: archiving_object_count가 total_object_count와 예상 범위 내임<br>취약: archiving_object_count가 total_object_count 미만 또는 초과임 | 오브젝트 수 불일치 시 아카이빙 누락 또는 중복으로 데이터 무결성 문제, 후속 모니터링 오류와 용량 계산 부정확함 | 이력 재검토 후 정책 필터 재적용함 | * 확인방법: showarchivinghistory 명령어로 count 필드 비교<br>* References<br>- Ceph Object Count Errors: https://docs.ceph.com/en/quincy/radosgw/s3/#object-count (카운트 불일치 진단) |
| 이력 ID 무효 확인 | scpcli archivestorage archiving history show --bucket_id <bucket_id> --id invalid_id | 정상: 유효 ID 시 상세 출력<br>취약: 무효 ID로 에러 출력 | 이력 ID 무효 시 상태 조회 실패로 문제 추적 불가, 장애 재발과 운영 지연 발생함 | listarchivinghistories로 유효 ID 추출 후 재조회함 | * 확인방법: showarchivinghistory 명령어 에러 확인<br>* References<br>- Ceph ID Validation: https://docs.ceph.com/en/reef/radosgw/s3/#list-buckets (ID 형식 오류) |
| 버킷 ID 무효 확인 | scpcli archivestorage bucket show --bucket_id invalid_id | 정상: 유효 ID 시 상세 출력<br>취약: 무효 ID로 에러 출력 | 버킷 ID 무효 시 모든 작업 중단으로 서비스 접근 불가, API 호출 실패 반복과 로그 과부하 발생함 | listbuckets로 유효 ID 확인 후 재입력함 | * 확인방법: showbucket 명령어 에러 확인<br>* References<br>- Ceph Bucket ID Errors: https://docs.ceph.com/en/latest/radosgw/s3/#bucketops (버킷 ID 트러블슈팅) |
| 아카이빙 정책 목록 비어있음 오류 | scpcli archivestorage archiving policy list --bucket_id <bucket_id> | 정상: 목록에 정책 1개 이상 출력됨<br>취약: 목록 빈 배열임 | 정책 목록 비어있음 시 자동 아카이빙 미실행으로 용량 초과 오류, 수동 작업 증가와 비용 상승 발생함 | createarchivingpolicy로 정책 생성함 | * 확인방법: listarchivingpolicies 명령어 결과 확인<br>* References<br>- Ceph Lifecycle Policies: https://docs.ceph.com/en/latest/radosgw/lifecycle/ (정책 목록 오류 및 생성 가이드) |

## 가용성

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|---------------|----------|------|
| 버킷 상태 지속성 확인 | SCP 콘솔에서 버킷 상세 정보 조회 | 정상: state 필드가 지속적으로 ACTIVE로 표시됨<br>취약: state 필드가 간헐적으로 INACTIVE로 전환됨 | 버킷 상태가 불안정하면 아카이빙 및 복구 작업이 중단되어 데이터 접근 지연이 발생하고, Ceph 클러스터의 모니터 쿼럼 문제로 인해 전체 서비스 가용성이 저하되며, 클라이언트 연결 실패가 빈번해져 비즈니스 연속성 위협이 커짐 | MSP에 클러스터 모니터 상태 복구 요청 후, 버킷 재활성화 절차 수행함 | * 확인방법: SCP 콘솔 버킷 목록에서 state 필드 실시간 모니터링<br>* 설정방법: Ceph 모니터 다운 시 자동 failover 설정 확인<br>* References<br>- Ceph Architecture - High Availability Monitors: https://docs.ceph.com/en/reef/architecture (모니터 쿼럼으로 가용성 유지 설명, 최소 3개 모니터 권고로 쿼럼 안정성 확보) |
| 아카이빙 정책 적용 빈도 확인 | SCP 콘솔 아카이빙 정책 목록 및 이력 검토 | 정상: 정책 적용 이력이 매일 또는 주기적으로 성공적으로 기록됨<br>취약: 정책 적용 이력이 7일 이상 누락됨 | 정책 적용이 지연되면 Object Storage 오브젝트가 아카이브되지 않아 용량 초과로 인한 서비스 중단이 발생하고, Ceph RGW의 라이프사이클 전환이 실패하여 데이터 무결성 문제가 발생하며, 장기적으로 클러스터 부하 증가로 가용성 저하가 초래됨 | 아카이빙 정책 스케줄을 매일 실행으로 조정하고, 정책 상태를 주기적으로 검증함 | * 확인방법: 콘솔에서 listarchivingpolicies 및 listarchivinghistories 유사 기능 사용<br>* References<br>- Ceph RGW Service - High Availability: https://docs.ceph.com/en/reef/cephadm/services/rgw/ (RGW HA 엔드포인트로 정책 실행 안정성 확보, ingress 서비스 최소 구성 권고) |
| 복구 이력 성공률 확인 | SCP 콘솔 복구 이력 목록 검토 | 정상: 최근 30일 복구 이력 중 성공 상태 비율 95% 이상임<br>취약: 성공 상태 비율 95% 미만임 | 복구 성공률이 낮으면 데이터 복원 지연으로 인해 다운타임이 연장되고, Ceph OSD의 redundancy 실패 시 데이터 손실 위험이 증가하며, 반복 복구 시도로 클러스터 리소스 고갈이 발생하여 전체 가용성이 취약해짐 | 복구 프로세스 최적화로 recovery_infos를 세분화하고, overwrite 옵션을 표준화함 | * 확인방법: 콘솔 recovery history list에서 state 필드 집계<br>* References<br>- Intro to Ceph - Redundancy Requirements: https://docs.ceph.com/en/reef/start (최소 3개 OSD로 redundancy 확보, 고가용성 위해 필수) |
| 버킷 사용량 임계값 모니터링 | SCP 콘솔 버킷 사용량 차트 확인 | 정상: usage가 할당 용량의 80% 미만 유지됨<br>취약: usage가 80% 초과임 | 사용량 초과 시 아카이빙 지연으로 클러스터 스토리지 풀 고갈이 발생하고, Ceph CRUSH 맵 재배치 실패로 노드 다운 시 데이터 접근 불가 상태가 지속되어 가용성 SLA 위반이 발생함 | 사용량 알림 임계값을 70%로 낮추고, 자동 아카이빙 정책 강화함 | * 확인방법: showbucket 유사 기능으로 usage 필드 추적<br>* References<br>- Hardware Recommendations - Daemon Separation: https://docs.ceph.com/en/reef/start/hardware-recommendations/ (전용 호스트로 데몬 분리, 용량 관리로 가용성 향상) |
| 암호화 설정 안정성 확인 | SCP 콘솔 버킷 암호화 상태 조회 | 정상: enabled 필드가 True로 지속 활성화됨<br>취약: enabled 필드가 False로 전환됨 | 암호화 비활성화 시 데이터 무결성 오류로 복구 실패가 발생하고, Ceph 서버사이드 암호화 키 손실 시 전체 버킷 접근 불가로 가용성이 급감하며, 규정 준수 위반으로 서비스 중단이 장기화됨 | 암호화 키 백업을 주기적으로 수행하고, enabled 상태를 강제 유지함 | * 확인방법: showbucketencryption 유사 기능 모니터링<br>* References<br>- Management Gateway - HA Enhancements: https://docs.ceph.com/en/latest/cephadm/services/mgmt-gateway/ (nginx HA로 관리 애플리케이션 가용성 확보) |
| 아카이빙 소스 버킷 연동 확인 | SCP 콘솔 버킷 상세 및 정책 연동 상태 검토 | 정상: archiving_source_bucket_name이 유효하고 연결됨<br>취약: 소스 버킷 이름이 무효 또는 연결 끊김 | 소스 연동 실패 시 아카이빙 데이터 불일치로 복구 시 버전 충돌이 발생하고, Ceph 멀티사이트 싱크 오류로 지역 간 데이터 동기화 지연이 발생하여 가용성 저하가 초래됨 | 소스 버킷을 다중 연결로 구성하고, 연동 테스트 주기적으로 실행함 | * 확인방법: showbucket에서 archiving_source_bucket_name 필드 확인<br>* References<br>- User Management - HA Permissions: https://docs.ceph.com/en/reef/rados/operations/user-management/ (HA를 위한 블록리스트 권한, 가용성 유지) |
| object_lifecycle 값 최적화 확인 | SCP 콘솔 아카이빙 정책 상세 조회 | 정상: object_lifecycle 값이 30일 이상으로 설정됨<br>취약: object_lifecycle 값이 30일 미만임 | lifecycle 값이 짧으면 빈번한 아카이빙으로 클러스터 부하가 증가하고, Ceph OSD 재배치 지연 시 가용성 저하가 발생하며, 정책 실행 큐 오버플로로 작업 중단이 빈번해짐 | lifecycle 값을 데이터 보존 기간에 맞게 60일로 조정함 | * 확인방법: showarchivingpolicy에서 object_lifecycle 필드 확인<br>* References<br>- Storage Cluster Quick Start - Multiple Monitors: https://docs.ceph.com/en/octopus/install/ceph-deploy/quick-ceph-deploy (다중 모니터로 HA, 최소 3개 권고) |
| 복구 대상 버킷 다중화 확인 | SCP 콘솔 복구 이력 및 타겟 설정 검토 | 정상: recovery_target_bucket_name이 2개 이상의 리전으로 분산됨<br>취약: 단일 리전 타겟만 사용됨 | 단일 타겟 시 지역 장애로 복구 불가 상태가 발생하고, Ceph 멀티사이트 복제 실패 시 데이터 접근 지연이 장기화되어 가용성 SLA를 위반함 | 타겟 버킷을 멀티 리전으로 설정하고, failover 정책 적용함 | * 확인방법: listrecoveryhistories에서 recovery_target_bucket_name 집계<br>* References<br>- Ceph Dashboard - HA Mechanism: https://docs.ceph.com/en/latest/mgr/dashboard/ (매니저 HA로 서비스 자동 재시작, 가용성 향상) |
| 아카이빙 이력 취소 빈도 확인 | SCP 콘솔 아카이빙 이력 목록 및 취소 기록 검토 | 정상: 취소 이력이 월 1회 미만임<br>취약: 취소 이력이 월 1회 초과임 | 빈번한 취소 시 아카이빙 프로세스 불안정으로 큐 지연이 발생하고, Ceph RGW 작업 충돌로 가용성 저하가 초래되며, 리소스 낭비로 클러스터 성능 저하가 발생함 | 취소 원인 분석 후 정책을 안정화하여 취소 빈도 최소화함 | * 확인방법: listarchivinghistories에서 cancel 상태 필터링<br>* References<br>- User Management - Best Practices: https://docs.ceph.com/en/octopus/rados/operations/user-management/ (타입/이름 사용 권고, HA 권한 관리) |
| 오브젝트 경로 접근성 확인 | SCP 콘솔 오브젝트 목록 조회 | 정상: object_path가 지정 경로로 안정 출력됨<br>취약: 경로 접근 시 오류 발생 | 경로 접근 실패 시 관리 작업 중단으로 삭제/복구 불가 상태가 발생하고, Ceph prefix 필터링 오류로 대량 오브젝트 검색 지연이 발생하여 가용성 영향이 확대됨 | 경로를 계층화하여 관리하고, 접근 로그 모니터링함 | * 확인방법: listbucketobjects 유사 기능으로 object_path 테스트<br>* References<br>- Health Checks - Monitor Availability: https://docs.ceph.com/en/reef/rados/operations/health-checks/ (모니터 다운 시 클라이언트 영향 최소화) |
| 버킷 태그 중복성 확인 | SCP 콘솔 버킷 태그 목록 검토 | 정상: tags가 고유 key-value로 구성됨<br>취약: tags 중복 또는 누락임 | 태그 중복 시 비용 추적 오류로 리소스 할당 지연이 발생하고, Ceph 메타데이터 불일치로 버킷 관리 실패가 발생하여 가용성 저하가 초래됨 | 태그를 표준화하고, 자동 할당 스크립트 적용함 | * 확인방법: showbucket에서 tags 필드 검증<br>* References<br>- Ceph Object Storage Multisite Replication: https://ceph.io/en/news/blog/2025/rgw-multisite-replication_part1/ (멀티사이트 복제로 geo-redundancy 확보) |
| 복구 진행률 안정성 확인 | SCP 콘솔 복구 상세 이력 조회 | 정상: recovery_rate가 100%로 안정 유지됨<br>취약: recovery_rate 변동성 큼 | 진행률 불안정 시 복구 지연으로 다운타임 연장이 발생하고, Ceph OSD 재배치 실패로 데이터 불완전 복원이 발생하여 가용성 취약점이 노출됨 | 진행률 모니터링 알림을 설정하고, stalled 시 취소 후 재시도함 | * 확인방법: showrecoveryhistory에서 recovery_rate 필드 추적<br>* References<br>- Ceph's Role in High Availability: https://www.alibabacloud.com/tech-news/a/ceph/4or7sz12m3a-cephs-role-in-high-availability-strategies (자동 데이터 재분배로 failover 지원) |
| 아카이빙 소스 경로 일관성 확인 | SCP 콘솔 정책 및 이력 비교 | 정상: source_object_path가 정책 object_path와 일치함<br>취약: 경로 불일치 발생 | 경로 불일치 시 아카이빙 누락으로 데이터 무결성 손상이 발생하고, Ceph 전환 액션 실패로 가용성 저하가 발생하며, 복구 시 버전 충돌이 빈번해짐 | 소스 경로를 정책과 동기화하고, 검증 스크립트 실행함 | * 확인방법: showarchivinghistory와 showarchivingpolicy 비교<br>* References<br>- New to PVE Ceph HA: https://forum.proxmox.com/threads/new-to-pve-trying-to-figure-out-redundant-ha-storage-with-ceph-or-is-there-some-better-way.148452/ (단일 디스크 실패 시 VM 이동으로 HA) |
| 버킷 오브젝트 타입 다양성 확인 | SCP 콘솔 오브젝트 목록 타입 집계 | 정상: object_type이 FILE/DIR로 균형 분포됨<br>취약: 단일 타입 과다임 | 타입 불균형 시 처리 오류로 오브젝트 관리 실패가 발생하고, Ceph 메타데이터 오류로 가용성 저하가 초래되며, 대량 작업 시 클러스터 부하 증가함 | 타입 필터를 적용한 관리 정책 도입함 | * 확인방법: listbucketobjects에서 object_type 필드 분석<br>* References<br>- High Availability for Ceph Storage: https://serverfault.com/questions/989863/high-availability-for-ceph-storage (최소 3 MON으로 쿼럼 HA) |
| 정책 수정 이력 추적 확인 | SCP 콘솔 정책 변경 로그 검토 | 정상: 수정 이력이 30일 내 5회 미만임<br>취약: 수정 이력 과다임 | 빈번한 수정 시 정책 불안정으로 실행 지연이 발생하고, Ceph 라이프사이클 업데이트 실패로 가용성 저하가 발생하며, 롤백 필요 시 다운타임 증가함 | 변경 관리 프로세스를 강화하고, 수정 전 테스트 환경 사용함 | * 확인방법: setarchivingpolicy 유사 로그 확인<br>* References<br>- Intro to Ceph - OSD Redundancy: https://docs.ceph.com/en/reef/start (최소 3 OSD로 redundancy) |
| 복구 overwrite 옵션 표준화 확인 | SCP 콘솔 복구 설정 검토 | 정상: overwrite가 True로 일관됨<br>취약: 옵션 혼재임 | 옵션 불일치 시 충돌 오류로 복구 실패가 발생하고, Ceph 오브젝트 덮어쓰기 지연으로 가용성 저하가 초래되며, 데이터 불일치 리스크 증가함 | 모든 복구 작업에 overwrite True를 기본 적용함 | * 확인방법: recoverobjects 유사 설정 확인<br>* References<br>- Ceph Storage - Scalability Redundancy: https://www.lightbitslabs.com/blog/ceph-storage/ (CRUSH 알고리즘으로 redundancy) |
| 아카이빙 총 오브젝트 수 검증 | SCP 콘솔 이력 상세 조회 | 정상: total_object_count와 archiving_object_count 차이 5% 이내임<br>취약: 차이 5% 초과임 | 카운트 불일치 시 아카이빙 누락으로 데이터 손실 위험이 발생하고, Ceph 오브젝트 카운트 오류로 가용성 저하가 초래되며, 모니터링 공백 발생함 | 카운트 검증을 자동화하고, 불일치 시 재아카이빙 실행함 | * 확인방법: showarchivinghistory에서 count 필드 비교<br>* References<br>- Configuring Multi-Site Fault-Tolerant: https://docs.redhat.com/en/documentation/red_hat_amq_broker/7.10/html/configuring_amq_broker/configuring-fault-tolerant-system-configuring (CRUSH 버킷으로 fault tolerance) |
| 버킷 목록 조회 안정성 확인 | SCP 콘솔 버킷 목록 새로고침 | 정상: 목록이 5초 내 로드됨<br>취약: 로드 시간 5초 초과임 | 조회 지연 시 관리 작업 중단으로 가용성 영향이 발생하고, Ceph API 호출 실패로 클러스터 연결 문제 확대됨 | 목록 캐싱을 활성화하고, limit을 50으로 제한함 | * 확인방법: listbuckets 유사 기능 성능 측정<br>* References<br>- Ceph Object Gateway Considerations: https://www.ibm.com/docs/en/storage-ceph/7.1.0?topic=recommendations-ceph-object-gateway-considerations (멀티사이트 failover로 DR) |
| recovery_infos 형식 일관성 확인 | SCP 콘솔 복구 정보 검토 | 정상: recovery_infos가 JSON 배열 형식으로 유효함<br>취약: 형식 오류 발생 | 형식 오류 시 복구 대상 지정 실패로 부분 복구 불가가 발생하고, Ceph JSON 파싱 오류로 가용성 저하가 초래되며, 작업 로그 오염됨 | infos 형식을 표준 템플릿으로 관리함 | * 확인방법: recoverobjects 유사 파라미터 검증<br>* References<br>- Ceph Replication Consistency: https://openmetal.io/resources/blog/ceph-replication-and-consistency-model-explained/ (복제로 fault tolerance) |
| 아카이빙 상태 모니터링 알림 확인 | SCP 콘솔 알림 설정 검토 | 정상: state 변경 시 알림 활성화됨<br>취약: 알림 비활성화임 | 알림 부재 시 상태 이상 탐지 지연으로 다운타임 연장이 발생하고, Ceph 헬스 체크 실패로 가용성 저하가 초래됨 | state 필드에 대한 실시간 알림 규칙 추가함 | * 확인방법: 콘솔 알림 로그 확인<br>* References<br>- Architecture - Ceph Unified System: https://docs.ceph.com/en/reef/architecture (통합 시스템으로 reliable 가용성) |
| 버킷 삭제 전 확인 프로세스 확인 | SCP 콘솔 삭제 작업 로그 검토 | 정상: 삭제 전 오브젝트 목록 확인 기록 있음<br>취약: 확인 기록 누락임 | 확인 누락 시 잔여 오브젝트로 용량 누적이 발생하고, Ceph 버킷 삭제 실패로 가용성 저하가 초래되며, 비용 과다 청구됨 | 삭제 워크플로에 list 확인 단계를 의무화함 | * 확인방법: deletebucket 유사 로그 분석<br>* References<br>- RGW Service - HA Endpoint: https://docs.ceph.com/en/reef/cephadm/services/rgw/ (ingress로 HA 엔드포인트) |
| 오브젝트 수정일 동기화 확인 | SCP 콘솔 오브젝트 메타데이터 조회 | 정상: modified_at이 실시간 업데이트됨<br>취약: modified_at 지연됨 | 동기화 지연 시 버전 관리 오류로 복구 불일치가 발생하고, Ceph 메타데이터 싱크 실패로 가용성 저하가 초래됨 | 메타데이터 동기화 주기를 단축함 | * 확인방법: listbucketobjects에서 modified_at 필드 확인<br>* References<br>- Health Checks - Cluster Quorum: https://docs.ceph.com/en/reef/rados/operations/health-checks/ (다수 모니터로 쿼럼 유지) |
| 정책 object_path 범위 최적화 확인 | SCP 콘솔 정책 상세 경로 검토 | 정상: object_path가 /로 전체 커버됨<br>취약: 제한적 경로만 지정됨 | 범위 제한 시 부분 아카이빙으로 용량 불균형이 발생하고, Ceph prefix 오류로 가용성 저하가 초래되며, 데이터 접근 지연됨 | path를 전체 루트로 확장하고, 세분화 관리함 | * 확인방법: listarchivingpolicies에서 object_path 필드 확인<br>* References<br>- Storage Cluster - Multiple Ceph Monitors: https://docs.ceph.com/en/octopus/install/ceph-deploy/quick-ceph-deploy (다중 모니터로 HA) |
| 복구 사용량 추적 확인 | SCP 콘솔 복구 이력 usage 필드 검토 | 정상: usage가 예상 범위 내임<br>취약: usage 급증임 | 사용량 급증 시 타겟 버킷 오버플로로 복구 중단이 발생하고, Ceph 용량 재할당 실패로 가용성 저하가 초래됨 | usage 모니터링을 강화하고, 임계 알림 설정함 | * 확인방법: showrecoveryhistory에서 usage 필드 분석<br>* References<br>- Ceph Dashboard - Built-in HA: https://docs.ceph.com/en/latest/mgr/dashboard/ (자동 재시작으로 HA) |
| 아카이빙 end_at 일시 정확성 확인 | SCP 콘솔 이력 종료 시간 검토 | 정상: end_at이 start_at + 예상 시간 이내임<br>취약: end_at 지연됨 | 종료 지연 시 큐 쌓임으로 신규 작업 지연이 발생하고, Ceph 작업 스케줄러 과부하로 가용성 저하가 초래됨 | 이력 타임아웃을 설정하고, 지연 시 취소함 | * 확인방법: listarchivinghistories에서 end_at/start_at 비교<br>* References<br>- User Management - Ceph Users: https://docs.ceph.com/en/octopus/rados/operations/user-management/ (RGW 사용자와 분리, HA 권한) |

## 성능 및 용량

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|---------------|----------|------|
| 버킷 사용량 모니터링 | SCP 콘솔에서 버킷 상세 정보 조회 | 정상: usage가 할당 용량의 80% 미만 유지됨<br>취약: usage가 80% 초과임 | 사용량 초과 시 아카이빙 지연으로 클러스터 스토리지 풀 고갈이 발생하고, Ceph CRUSH 맵 재배치 실패로 노드 다운 시 데이터 접근 불가 상태가 지속되어 성능 저하와 용량 부족으로 서비스 중단이 발생하며, 추가 비용 증가와 청구 오류가 초래됨 | 사용량 알림 임계값을 70%로 낮추고, 자동 아카이빙 정책을 강화하여 용량을 최적화함 | * 확인방법: SCP 콘솔 버킷 목록에서 usage 필드 실시간 차트 확인<br>* References<br>- Hardware Recommendations - Ceph Documentation: https://docs.ceph.com/en/reef/start/hardware-recommendations/ (SSD 사용으로 랜덤 액세스 시간 감소와 처리량 증가, 용량 관리 최적화 설명, SSD 권고로 성능 향상) |
| 아카이빙 진행률 최적화 | SCP 콘솔 아카이빙 이력 상세 조회 | 정상: archiving_rate가 100%로 1시간 내 완료됨<br>취약: archiving_rate가 100% 미만으로 1시간 초과임 | 진행률 지연 시 부분 아카이빙으로 소스 오브젝트와 아카이브 데이터 불일치가 발생하고, Ceph RGW 작업 큐 오버플로로 후속 아카이빙 지연이 발생하며, 클러스터 CPU/IO 부하 증가로 전체 성능 저하와 용량 재할당 지연이 초래됨 | 아카이빙 스케줄을 비피크 타임으로 조정하고, object_lifecycle 값을 30일 이상으로 설정하여 빈번한 작업을 줄임 | * 확인방법: 콘솔 아카이빙 history show에서 archiving_rate 필드 추적<br>* References<br>- Ceph Object Gateway Config Reference: https://docs.ceph.com/en/reef/radosgw/config-ref/ (객체 저장 공간 즉시 할당으로 용량 효율성 확보, 삭제/덮어쓰기 후 공간 정리 설명) |
| 복구 처리 시간 확인 | SCP 콘솔 복구 이력 상세 조회 | 정상: recovery_rate가 100%로 2시간 내 완료됨<br>취약: recovery_rate가 100% 미만으로 2시간 초과임 | 복구 지연 시 데이터 복원 불완전으로 애플리케이션 다운타임이 연장되고, Ceph OSD 재배치 실패로 용량 불균형이 발생하며, 반복 복구 시도로 네트워크 대역폭 고갈과 성능 저하가 초래됨 | recovery_infos를 세분화하여 배치 크기를 100개 이하로 제한하고, overwrite를 True로 설정하여 충돌을 최소화함 | * 확인방법: 콘솔 recovery history show에서 recovery_rate 필드 모니터링<br>* References<br>- BlueStore Configuration Reference: https://docs.ceph.com/en/reef/rados/configuration/bluestore-config-ref/ (빠른 디바이스에 block.db 배치로 성능 향상, 혼합 디바이스 용량 최적화 설명) |
| 오브젝트 크기 분포 균형 | SCP 콘솔 오브젝트 목록 조회 | 정상: 평균 object_size가 1MB 이상으로 균형됨<br>취약: 평균 object_size가 1MB 미만임 | 작은 오브젝트 과다 시 메타데이터 오버헤드가 증가하고, Ceph RGW 쿼리 지연으로 목록 조회 성능 저하가 발생하며, 용량 효율성 저하로 스토리지 풀 고갈이 빨라짐 | 오브젝트 업로드를 배치 처리로 통합하여 평균 크기를 5MB 이상으로 유지함 | * 확인방법: 콘솔 bucket object list에서 object_size 필드 평균 계산<br>* References<br>- Erasure code: https://docs.ceph.com/en/reef/rados/operations/erasure-code/ (다중 풀 지원으로 성능/보호 전략 최적화, erasure coding으로 용량 절약 설명) |
| 아카이빙 정책 lifecycle 값 적절성 | SCP 콘솔 아카이빙 정책 상세 조회 | 정상: object_lifecycle 값이 30일 이상임<br>취약: object_lifecycle 값이 30일 미만임 | lifecycle 짧음 시 빈번한 아카이빙으로 IO 부하가 증가하고, Ceph OSD 재배치 지연으로 성능 저하가 발생하며, 용량 전환 중 중복 저장으로 효율성 저하가 초래됨 | lifecycle 값을 데이터 보존 기간에 맞게 60일로 조정하고, 정책을 분할 적용함 | * 확인방법: 콘솔 archiving policy show에서 object_lifecycle 필드 확인<br>* References<br>- Pools: https://docs.ceph.com/en/squid/rados/operations/pools/ (복제 풀 vs erasure 풀 용량 비교, replicated 풀 성능 우선 설명) |
| 암호화 오버헤드 모니터링 | SCP 콘솔 버킷 암호화 상태 및 사용량 조회 | 정상: enabled True 시 usage 증가율 5% 이내임<br>취약: enabled True 시 usage 증가율 5% 초과임 | 암호화 오버헤드 과다 시 복호화 지연으로 복구 성능 저하가 발생하고, Ceph 서버사이드 암호화 키 처리로 CPU 부하 증가하며, 용량 효율성 저하로 추가 스토리지 필요가 초래됨 | 암호화 키를 하드웨어 가속으로 처리하고, enabled 상태를 주기적으로 검증함 | * 확인방법: 콘솔 bucket encryption show와 usage 비교<br>* References<br>- Intro to Ceph: https://docs.ceph.com/en/reef/start (최소 OSD 수로 용량 redundancy 확보, 성능 영향 최소화 설명) |
| 오브젝트 목록 조회 limit 설정 | SCP 콘솔 오브젝트 목록 조회 테스트 | 정상: limit 값이 1000 이하로 설정됨<br>취약: limit 값이 1000 초과임 | limit 과다 시 API 응답 지연으로 관리 성능 저하가 발생하고, Ceph RGW 메모리 고갈로 쿼리 실패가 빈번하며, 대량 조회 중 용량 스냅샷 오버헤드가 증가함 | limit을 500으로 제한하고, 마커 기반 페이징을 적용함 | * 확인방법: 콘솔 bucket object list에서 limit 파라미터 확인<br>* References<br>- Multi-Site: https://docs.ceph.com/en/quincy/radosgw/multisite/ (멀티사이트 구성으로 용량 분산, 최소 2 클러스터 권고) |
| 아카이빙 이력 검색 offset 최적화 | SCP 콘솔 아카이빙 이력 목록 조회 | 정상: offset 값이 1000 미만으로 유지됨<br>취약: offset 값이 1000 초과임 | offset 과다 시 검색 지연으로 모니터링 성능 저하가 발생하고, Ceph 로그 쿼리 부하 증가로 용량 로그 저장 과부하가 초래되며, 이력 분석 지연으로 용량 예측 오류 발생함 | offset을 0부터 순차 적용하고, 기간 필터를 강화함 | * 확인방법: 콘솔 archiving history list에서 offset 파라미터 테스트<br>* References<br>- Erasure coding enhancements: https://docs.ceph.com/en/latest/dev/osd_internals/erasure_coding/enhancements/ (작은 랜덤 액세스 성능 개선, erasure coding 최적화 설명) |
| 버킷 사용량 증가 추세 분석 | SCP 콘솔 버킷 사용량 차트 조회 | 정상: 주간 usage 증가율 10% 미만임<br>취약: 주간 usage 증가율 10% 초과임 | 증가 추세 급등 시 용량 초과 예측 실패로 아카이빙 지연이 발생하고, Ceph 풀 확장 지연으로 성능 병목이 초래되며, 청구 비용 급증과 용량 재할당 중단이 발생함 | 증가 추세 알림을 설정하고, 자동 용량 확장 정책 적용함 | * 확인방법: 콘솔 버킷 대시보드에서 usage 트렌드 그래프 분석<br>* References<br>- Ceph Dashboard: https://docs.ceph.com/en/latest/mgr/dashboard/ (RGW 성능 카운터 표시, 용량 모니터링 기능 설명) |
| 아카이빙 오브젝트 수 효율성 | SCP 콘솔 아카이빙 이력 상세 조회 | 정상: archiving_object_count / total_object_count 비율 90% 이상임<br>취약: 비율 90% 미만임 | 효율성 저하 시 누락 아카이빙으로 용량 중복 저장이 발생하고, Ceph 전환 실패로 성능 저하가 초래되며, 후속 복구 시 추가 IO 부하 증가함 | 정책 object_path를 세밀하게 조정하고, 필터를 강화함 | * 확인방법: 콘솔 archiving history show에서 count 필드 비율 계산<br>* References<br>- Architecture: https://docs.ceph.com/en/reef/architecture (통합 스토리지 시스템으로 용량 효율성, 오브젝트/블록/파일 지원 설명) |
| 복구 overwrite 성능 영향 | SCP 콘솔 복구 이력 조회 | 정상: overwrite True 시 recovery_rate 95% 이상임<br>취약: overwrite True 시 recovery_rate 95% 미만임 | overwrite 비효율 시 충돌 처리 지연으로 복구 성능 저하가 발생하고, Ceph 오브젝트 덮어쓰기 오버헤드로 용량 재할당 지연이 초래되며, 데이터 불일치로 재작업 증가함 | overwrite를 기본 True로 설정하고, 타겟 버킷 용량을 20% 여유로 유지함 | * 확인방법: 콘솔 recovery history show에서 recovery_rate와 overwrite 비교<br>* References<br>- Best Practices of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/best-practices-of-ceph-storage-cluster-tuning-2b22689b5f8a (BlueStore 우선 사용으로 성능 튜닝, jumbo MTU 네트워크 격리 설명) |
| 소스 오브젝트 경로 복잡도 | SCP 콘솔 아카이빙 정책 및 이력 검토 | 정상: source_object_path 깊이가 5레벨 이내임<br>취약: 깊이가 5레벨 초과임 | 경로 복잡 시 검색 지연으로 아카이빙 성능 저하가 발생하고, Ceph prefix 필터링 오버헤드로 용량 메타데이터 증가가 초래되며, 목록 조회 시 타임아웃 발생함 | 경로를 평탄화하고, object_path를 루트로 제한함 | * 확인방법: 콘솔 archiving history show에서 source_object_path 길이 분석<br>* References<br>- [SOLVED] Ceph configuration - best practices: https://forum.proxmox.com/threads/ceph-configuration-best-practices.143965/ (OSD 메모리 8GiB 이상 설정으로 성능 안정화, 재시작 최소화 설명) |
| 버킷 태그 개수 제한 | SCP 콘솔 버킷 태그 목록 조회 | 정상: tags 개수가 10개 이내임<br>취약: tags 개수가 10개 초과임 | 태그 과다 시 메타데이터 처리 지연으로 버킷 관리 성능 저하가 발생하고, Ceph 메타데이터 저장 용량 증가로 효율성 저하가 초래되며, 쿼리 시 CPU 부하 증가함 | 태그를 핵심 항목으로 제한하고, 자동 태깅 스크립트 적용함 | * 확인방법: 콘솔 bucket show에서 tags 배열 길이 확인<br>* References<br>- Application best practices for distributed file systems: https://docs.ceph.com/en/reef/cephfs/app-best-practices/ (분산 파일 시스템 성능 차이 설명, 로컬 vs 분산 최적화 팁) |
| 복구 대상 버킷 용량 여유 | SCP 콘솔 복구 타겟 버킷 사용량 조회 | 정상: recovery_target_bucket_name usage가 70% 미만임<br>취약: usage가 70% 초과임 | 타겟 용량 부족 시 복구 중단으로 성능 지연이 발생하고, Ceph 풀 오버플로로 재배치 실패가 초래되며, 용량 확장 지연으로 다운타임 증가함 | 타겟 버킷을 50% 여유로 유지하고, 자동 스케일링 정책 적용함 | * 확인방법: 콘솔 bucket show에서 타겟 usage 확인<br>* References<br>- Chapter 2. Red Hat Ceph Storage considerations: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/5/html/installation_guide/red-hat-ceph-storage-considerations-and-recommendations (MTU 일관성으로 네트워크 성능 최적화, end-to-end 통신 설명) |
| 아카이빙 삭제 작업 빈도 | SCP 콘솔 오브젝트 삭제 이력 검토 | 정상: 월 삭제 작업이 100회 미만임<br>취약: 월 삭제 작업이 100회 초과임 | 삭제 빈도 과다 시 메타데이터 정리 지연으로 성능 저하가 발생하고, Ceph 공간 반환 실패로 용량 누적이 초래되며, GC 오버헤드로 IO 부하 증가함 | 삭제를 배치 처리하고, 주기적 정리 스케줄 적용함 | * 확인방법: 콘솔 bucket object delete 로그 집계<br>* References<br>- 10 essential Ceph commands: https://blog.softiron.com/engineering/10-essential-ceph-commands-for-managing-any-cluster-at-any-scale/ (클러스터 관리 명령으로 용량 모니터링, df 명령 설명) |
| 복구 취소 작업 영향 | SCP 콘솔 복구 이력 취소 기록 검토 | 정상: 취소 이력이 월 5회 미만임<br>취약: 취소 이력이 월 5회 초과임 | 취소 빈도 높음 시 리소스 낭비로 성능 저하가 발생하고, Ceph 작업 큐 지연으로 용량 재할당 중단이 초래되며, 후속 복구 지연 증가함 | 취소 원인 분석 후 recovery_infos 최적화로 빈도 줄임 | * 확인방법: 콘솔 recovery history list에서 cancel 상태 필터링<br>* References<br>- Ceph Storage: https://www.lightbitslabs.com/blog/ceph-storage/ (커모디티 하드웨어 스케일링으로 용량 확대, 노드 수천 개 지원 설명) |
| 오브젝트 마커 페이징 사용 | SCP 콘솔 대량 오브젝트 목록 조회 테스트 | 정상: marker 사용 시 응답 시간 5초 이내임<br>취약: marker 미사용 시 응답 시간 5초 초과임 | 마커 미사용 시 대량 조회 지연으로 성능 저하가 발생하고, Ceph 메모리 고갈로 용량 스냅샷 실패가 초래되며, 관리 작업 중단 발생함 | 마커를 의무 적용하고, limit 1000으로 제한함 | * 확인방법: 콘솔 bucket object list에서 marker 파라미터 성능 측정<br>* References<br>- What are the key considerations: https://www.quora.com/What-are-the-key-considerations-and-best-practices-for-implementing-Ceph-storage-in-a-distributed-environment-and-how-can-organizations-optimize-performance-and-reliability-with-Ceph (캐시 티어링으로 핫/콜드 데이터 마이그레이션, 성능 최적화 설명) |
| 아카이빙 object_type 필터 효율 | SCP 콘솔 아카이빙 정책 타입 설정 검토 | 정상: object_type 필터 사용 시 처리 시간 20% 단축임<br>취약: 필터 미사용 시 처리 시간 20% 초과임 | 필터 미사용 시 불필요 처리로 성능 저하가 발생하고, Ceph 타입별 IO 불균형으로 용량 효율성 저하가 초래되며, 대량 작업 지연 증가함 | object_type을 FILE로 제한하고, DIR는 별도 정책 적용함 | * 확인방법: 콘솔 archiving policy list에서 object_type 필드 확인<br>* References<br>- How to Tune Ceph for Block Storage Performance: https://openmetal.io/resources/blog/how-to-tune-ceph-for-block-storage-performance/ (운영 전문성 기반 튜닝, 산업 베스트 프랙티스 설명) |
| 버킷 오브젝트 수정 빈도 | SCP 콘솔 오브젝트 메타데이터 조회 | 정상: modified_at 최근 30일 내 50% 이내임<br>취약: 50% 초과임 | 수정 빈도 과다 시 메타데이터 업데이트 지연으로 성능 저하가 발생하고, Ceph 버전 관리 오버헤드로 용량 증가가 초래되며, 아카이빙 트리거 오류 발생함 | 수정 작업을 최소화하고, 불변 오브젝트 정책 적용함 | * 확인방법: 콘솔 bucket object list에서 modified_at 분포 분석<br>* References<br>- Maximising Data Efficiency with Ceph Storage: https://uneos.au/maximising-data-efficiency-with-ceph-storage-a-comprehensive-guide/ (구현/구성/관리 베스트 프랙티스, 데이터 효율성 설명) |
| 복구 usage 증가율 | SCP 콘솔 복구 이력 usage 필드 검토 | 정상: recovery usage 증가율 주간 5% 미만임<br>취약: 5% 초과임 | 증가 과다 시 타겟 버킷 오버플로로 복구 성능 저하가 발생하고, Ceph 용량 재할당 지연으로 전체 풀 불균형이 초래되며, 비용 과다 청구 발생함 | usage 추적 알림 설정하고, 복구 배치 크기 조정함 | * 확인방법: 콘솔 showrecoveryhistory에서 usage 트렌드 확인<br>* References<br>- Ceph Object Gateway Config Reference: https://docs.ceph.com/en/reef/radosgw/config-ref/ (삭제/덮어쓰기 후 공간 정리로 용량 관리, 즉시 할당 설명) |
| 아카이빙 정책 수 제한 | SCP 콘솔 아카이빙 정책 목록 조회 | 정상: 정책 수가 버킷당 5개 이내임<br>취약: 5개 초과임 | 정책 과다 시 실행 큐 지연으로 아카이빙 성능 저하가 발생하고, Ceph 라이프사이클 관리 오버헤드로 용량 메타데이터 증가가 초래되며, 충돌 오류 빈번함 | 정책을 통합하고, 최대 3개로 제한함 | * 확인방법: 콘솔 listarchivingpolicies에서 id 개수 집계<br>* References<br>- Pools: https://docs.ceph.com/en/squid/rados/operations/pools/ (replicated 풀 용량 vs 성능 트레이드오프, erasure 풀 권고) |
| 이력 보관 기간 최적화 | SCP 콘솔 이력 목록 설정 검토 | 정상: 이력 보관 기간 90일 이내임<br>취약: 90일 초과임 | 보관 과다 시 로그 용량 증가로 검색 성능 저하가 발생하고, Ceph 저장소 고갈로 용량 부족이 초래되며, 분석 도구 과부하 발생함 | 보관 기간을 60일로 단축하고, 오래된 이력 아카이빙함 | * 확인방법: 콘솔 archiving history list에서 start_at 필터 적용<br>* References<br>- Erasure code: https://docs.ceph.com/en/reef/rados/operations/erasure-code/ (다중 풀 전략으로 용량/성능 균형, RGW 지원 설명) |
| 버킷 삭제 후 용량 회수 | SCP 콘솔 삭제 후 버킷 사용량 확인 | 정상: 삭제 후 usage 10% 이내로 회수됨<br>취약: 10% 초과 잔여임 | 회수 지연 시 잔여 용량 누적으로 성능 저하가 발생하고, Ceph 공간 반환 실패로 풀 고갈이 초래되며, 비용 누적 청구 발생함 | 삭제 후 GC 주기를 단축하고, 수동 회수 트리거 적용함 | * 확인방법: 콘솔 bucket show에서 삭제 전후 usage 비교<br>* References<br>- Multi-Site: https://docs.ceph.com/en/quincy/radosgw/multisite/ (멀티사이트 용량 동기화, 최소 2 인스턴스 권고) |
| 복구 source_object_path 길이 | SCP 콘솔 복구 이력 경로 검토 | 정상: source_object_path 길이가 256자 이내임<br>취약: 256자 초과임 | 경로 길이 과다 시 복구 지연으로 성능 저하가 발생하고, Ceph 경로 파싱 오버헤드로 용량 메타데이터 증가가 초래되며, 타임아웃 오류 빈번함 | 경로를 단축하고, 계층 구조 최적화함 | * 확인방법: 콘솔 showrecoveryhistory에서 source_object_path 길이 측정<br>* References<br>- BlueStore Configuration Reference: https://docs.ceph.com/en/reef/rados/configuration/bluestore-config-ref/ (block.db 빠른 디바이스 배치로 IO 성능 향상) |
| 아카이빙 total_object_count 추적 | SCP 콘솔 아카이빙 이력 count 필드 조회 | 정상: total_object_count 주간 변동 20% 미만임<br>취약: 20% 초과임 | count 변동 과다 시 예측 실패로 용량 계획 오류가 발생하고, Ceph 카운트 동기화 지연으로 성능 저하가 초래되며, 아카이빙 누락 증가함 | count 모니터링 대시보드 설정하고, 변동 알림 적용함 | * 확인방법: 콘솔 showarchivinghistory에서 total_object_count 트렌드 분석<br>* References<br>- Ceph Dashboard: https://docs.ceph.com/en/latest/mgr/dashboard/ (RGW 사용자 및 성능 카운터 관리, 용량 추적 기능) |

## 운영

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|---------------|----------|------|
| 로그 레벨 설정 최적화 | SCP 콘솔에서 로그 설정 조회 | 정상: debug 로그 레벨이 INFO 이상으로 설정됨<br>취약: debug 로그 레벨이 DEBUG 이하임 | 로그 레벨이 과도하게 상세하면 로그 볼륨이 폭증하여 스토리지 용량을 빠르게 소모하고, Ceph RGW 로그 처리 지연으로 운영 모니터링이 어려워지며, 로그 분석 도구 과부하로 인시던트 탐지 지연이 발생하여 장애 대응 시간이 길어짐 | 로그 레벨을 WARN으로 조정하고, 필요 시 세션별로 동적으로 변경함 | * 확인방법: SCP 콘솔 로그 대시보드에서 레벨 필터 적용<br>* 설정방법: ceph config set global debug_rgw 1/1로 조정<br>* References<br>- Logging and Debugging - Ceph Documentation: https://docs.ceph.com/en/latest/rados/troubleshooting/log-and-debug/ (Ceph 컴포넌트 디버그 로그 레벨 런타임 조정 설명, 운영 중 로그 관리 베스트 프랙티스) |
| 로그 로테이션 주기 확인 | SCP 콘솔 로그 파일 목록 및 크기 검토 | 정상: 로그 파일 크기가 100MB 미만으로 유지됨<br>취약: 로그 파일 크기가 100MB 초과임 | 로테이션 주기가 길면 로그 파일이 과도하게 커져 디스크 공간을 점유하고, Ceph OSD 로그 누적으로 클러스터 성능 저하가 발생하며, 로그 검색 지연으로 운영 인시던트 진단이 늦어져 다운타임이 연장됨 | 로테이션 주기를 매일로 설정하고, 압축 및 오래된 로그 자동 삭제함 | * 확인방법: 콘솔 로그 저장소에서 파일 크기 집계<br>* 설정방법: ceph-mgr 로그 로테이션 스크립트 스케줄링<br>* References<br>- Monitoring Services - Ceph Documentation: https://docs.ceph.com/en/reef/cephadm/services/monitoring/ (중앙화된 로그 관리로 Loki & Promtail 사용, 로테이션 베스트 프랙티스 설명) |
| 모니터링 알림 임계값 설정 | SCP 콘솔 알림 규칙 목록 조회 | 정상: 알림 임계값이 80% 용량/5% 실패율로 설정됨<br>취약: 알림 임계값이 90% 초과임 | 임계값이 높으면 용량 초과나 실패를 사전에 탐지하지 못해 갑작스러운 클러스터 다운이 발생하고, Ceph 모니터 알림 누락으로 운영 팀 대응 지연이 초래되며, 장애 확산으로 서비스 가용성이 저하됨 | 알림 임계값을 70% 용량/3% 실패율로 낮추고, 다중 채널(이메일/Slack) 알림 활성화함 | * 확인방법: 콘솔 모니터링 대시보드에서 규칙 검토<br>* 설정방법: ceph health alert 설정 스크립트 실행<br>* References<br>- Chapter 3. Monitoring a Ceph storage cluster - Red Hat: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/7/html/administration_guide/monitoring-a-ceph-storage-cluster (클러스터 헬스 모니터링 및 알림 설정 가이드, 임계값 베스트 프랙티스) |
| 정기 헬스 체크 실행 주기 | SCP 콘솔 헬스 체크 로그 검토 | 정상: 헬스 체크가 매시간 실행됨<br>취약: 헬스 체크 실행 간격이 6시간 초과임 | 헬스 체크 주기가 길면 클러스터 이상을 늦게 발견하여 OSD 실패가 누적되고, Ceph 모니터 쿼럼 손실로 데이터 접근 지연이 발생하며, 운영 중 장애 예방이 어려워 다운타임 증가함 | 헬스 체크를 매 30분으로 스케줄링하고, 자동 보고서 생성함 | * 확인방법: 콘솔 헬스 대시보드에서 실행 로그 확인<br>* 설정방법: ceph health -s 스크립트 cronjob 등록<br>* References<br>- Chapter 3. Monitoring - Red Hat Ceph Storage: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/3/html/administration_guide/monitoring (OSD/MON 데몬 상태 모니터링, 정기 헬스 체크 권고) |
| 패치 적용 이력 추적 | SCP 콘솔 패치 관리 로그 조회 | 정상: 최근 30일 내 패치 적용 1회 이상임<br>취약: 90일 내 패치 적용 없음 | 패치 미적용 시 알려진 취약점이 노출되어 보안 침해가 발생하고, Ceph 버그 누적으로 운영 안정성이 저하되며, 성능 패치 누락으로 용량 관리 오류가 초래됨 | 패치 적용을 월 1회로 스케줄링하고, 롤백 계획 수립함 | * 확인방법: 콘솔 패치 히스토리에서 적용 날짜 확인<br>* 설정방법: ceph orch upgrade 명령으로 자동 패치<br>* References<br>- Best Practices of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/best-practices-of-ceph-storage-cluster-tuning-57318cb5e6d9 (클러스터 튜닝 및 패치 관리 베스트 프랙티스, 정기 업데이트 권고) |
| EOS 버전 확인 | SCP 콘솔 클러스터 버전 정보 조회 | 정상: Ceph 버전이 지원 기간 내(예: 2025년 이후 EOS)임<br>취약: EOS 버전 사용 중임 | EOS 버전 사용 시 보안 패치 미지원으로 취약점이 지속되고, Ceph 업그레이드 지연으로 운영 호환성 문제가 발생하며, 벤더 지원 중단으로 장애 대응이 어려워짐 | EOS 전 버전으로 업그레이드하고, 호환성 테스트 수행함 | * 확인방법: 콘솔 버전 대시보드에서 EOS 상태 확인<br>* 설정방법: ceph version 확인 후 ceph orch upgrade 실행<br>* References<br>- IBM Storage Ceph Concepts and Architecture Guide: https://www.redbooks.ibm.com/redpapers/pdfs/redp5721.pdf (클러스터 구성 백업 및 EOS 관리 가이드, git 기반 버전 관리 설명) |
| 백업 스케줄 확인 | SCP 콘솔 백업 정책 목록 검토 | 정상: 백업이 매일 실행됨<br>취약: 백업 간격이 7일 초과임 | 백업 주기가 길면 데이터 손실 범위가 확대되고, Ceph 구성 백업 누락으로 복구 지연이 발생하며, 운영 중 재해 시 RTO(복구 시간 목표) 초과로 비즈니스 영향 증가함 | 백업을 매일로 설정하고, 오프사이트 저장소 연동함 | * 확인방법: 콘솔 백업 스케줄러에서 주기 확인<br>* 설정방법: ceph orch apply backup 스크립트 cronjob<br>* References<br>- IBM Storage Ceph Concepts and Architecture Guide: https://www.redbooks.ibm.com/redpieces/pdfs/redp5721.pdf (클러스터 구성 백업 베스트 프랙티스, git 사용 권고) |
| 복구 테스트 주기 | SCP 콘솔 복구 테스트 로그 검토 | 정상: 복구 테스트가 분기 1회 이상임<br>취약: 6개월 내 테스트 없음 | 복구 테스트 미실시 시 실제 재해 시 복구 실패가 발생하고, Ceph 백업 무결성 확인 누락으로 데이터 손실이 초래되며, 운영 팀 훈련 부족으로 RPO(복구 지점 목표) 미달성함 | 복구 테스트를 월 1회로 확대하고, 시뮬레이션 환경 구축함 | * 확인방법: 콘솔 복구 히스토리에서 테스트 플래그 확인<br>* 설정방법: ceph orch run recovery_test 스크립트 스케줄링<br>* References<br>- A Guide to OpenStack and Ceph Monitoring: https://trilio.io/openstack-training/openstack-and-ceph/ (Ceph 모니터링 및 복구 테스트 베스트 프랙티스, 안정적 배포 가이드) |
| 인시던트 로그 분석 주기 | SCP 콘솔 인시던트 보고서 검토 | 정상: 인시던트 분석이 매월 수행됨<br>취약: 3개월 내 분석 없음 | 분석 주기 지연 시 재발 장애가 발생하고, Ceph 로그 패턴 미인식으로 근본 원인 미해결이 초래되며, 운영 효율성 저하와 다운타임 누적 증가함 | 분석을 주 1회로 강화하고, RCA(Root Cause Analysis) 도구 도입함 | * 확인방법: 콘솔 인시던트 대시보드에서 분석 날짜 확인<br>* 설정방법: ceph log analyze 스크립트 자동화<br>* References<br>- Logging and Debugging - Ceph Documentation: https://docs.ceph.com/en/latest/rados/troubleshooting/log-and-debug/ (로그 디버깅 및 인시던트 분석 가이드, 런타임 로그 조정) |
| 용량 예측 보고서 생성 | SCP 콘솔 용량 트렌드 차트 분석 | 정상: 월간 용량 예측 보고서 생성됨<br>취약: 3개월 내 보고서 없음 | 예측 미실시 시 용량 초과로 아카이빙 중단이 발생하고, Ceph 풀 확장 지연으로 성능 저하가 초래되며, 비용 초과 청구와 운영 계획 오류 발생함 | 예측 모델을 도입하고, 월 1회 보고서 자동 생성함 | * 확인방법: 콘솔 용량 대시보드에서 트렌드 그래프 검토<br>* 설정방법: ceph osd df 트리거 스크립트 cronjob<br>* References<br>- Monitoring Services - Ceph Documentation: https://docs.ceph.com/en/reef/cephadm/services/monitoring/ (중앙 로그 및 용량 모니터링, 예측 베스트 프랙티스) |
| 사용자 액세스 감사 로그 | SCP 콘솔 액세스 로그 목록 조회 | 정상: 액세스 로그가 90일 보관됨<br>취약: 보관 기간 30일 미만임 | 감사 로그 짧음 시 보안 사건 추적이 어려워지고, Ceph RGW 액세스 패턴 분석 누락으로 무단 접근 탐지 지연이 발생하며, 규정 준수 위반으로 벌금 부과됨 | 보관 기간을 180일로 연장하고, 이상 징후 알림 설정함 | * 확인방법: 콘솔 감사 로그 저장소에서 기간 확인<br>* 설정방법: ceph config set global rgw_log_retention 180<br>* References<br>- Chapter 3. Monitoring a Ceph storage cluster - Red Hat: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/7/html/administration_guide/monitoring-a-ceph-storage-cluster (액세스 모니터링 및 감사 로그 관리 가이드) |
| 네트워크 지연 모니터링 | SCP 콘솔 네트워크 메트릭스 조회 | 정상: 평균 지연이 50ms 미만임<br>취약: 평균 지연 50ms 초과임 | 지연 증가 시 아카이빙 전송 속도 저하로 작업 지연이 발생하고, Ceph 멀티사이트 싱크 실패로 데이터 불일치가 초래되며, 운영 중 네트워크 병목으로 성능 저하 확산됨 | 지연 알림을 30ms로 설정하고, 네트워크 최적화(예: MTU 조정) 수행함 | * 확인방법: 콘솔 네트워크 대시보드에서 지연 차트 확인<br>* 설정방법: ceph orch host ls로 네트워크 인터페이스 검토<br>* References<br>- Best Practices of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/best-practices-of-ceph-storage-cluster-tuning-57318cb5e6d9 (네트워크 튜닝 및 지연 모니터링 베스트 프랙티스) |
| 데이터 무결성 검증 주기 | SCP 콘솔 무결성 체크 로그 검토 | 정상: 무결성 검증이 주 1회 실행됨<br>취약: 1개월 내 검증 없음 | 검증 미실시 시 데이터 손상 누적이 발생하고, Ceph erasure code 오류 미발견으로 복구 실패가 초래되며, 운영 중 데이터 신뢰성 저하로 애플리케이션 오류 증가함 | 검증을 매일로 확대하고, 자동 스크럽 스케줄링함 | * 확인방법: 콘솔 헬스 체크에서 무결성 결과 확인<br>* 설정방법: ceph deep-scrub 스크립트 cronjob<br>* References<br>- Chapter 3. Monitoring - Red Hat Ceph Storage: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/3/html/administration_guide/monitoring (데이터 무결성 스크럽 및 검증 가이드) |
| 재해 복구 드릴 실행 | SCP 콘솔 DR 테스트 보고서 검토 | 정상: DR 드릴이 반기 1회 이상임<br>취약: 1년 내 드릴 없음 | 드릴 미실시 시 실제 재해 시 복구 프로세스 실패가 발생하고, Ceph 백업 복원 지연으로 RTO 초과가 초래되며, 운영 팀 준비 부족으로 비즈니스 중단 장기화됨 | 드릴을 분기 1회로 강화하고, 시나리오 기반 시뮬레이션함 | * 확인방법: 콘솔 DR 히스토리에서 실행 날짜 확인<br>* 설정방법: ceph orch run dr_drill 스크립트 스케줄링<br>* References<br>- Maximising Data Efficiency with Ceph Storage: https://uneos.au/maximising-data-efficiency-with-ceph-storage-a-comprehensive-guide/ (DR 및 재해 복구 베스트 프랙티스, 클러스터 헬스 관리 설명) |
| 비용 최적화 리뷰 주기 | SCP 콘솔 비용 보고서 분석 | 정상: 비용 리뷰가 월 1회임<br>취약: 3개월 내 리뷰 없음 | 리뷰 지연 시 불필요 비용 누적이 발생하고, Ceph 용량 과다 할당으로 예산 초과가 초래되며, 운영 최적화 미실시로 효율성 저하와 청구 오류 발생함 | 리뷰를 주 1회로 확대하고, 태그 기반 비용 분류 도입함 | * 확인방법: 콘솔 비용 대시보드에서 트렌드 검토<br>* 설정방법: ceph osd usage 트리거 비용 스크립트<br>* References<br>- Automation of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/automation-of-ceph-storage-cluster-tuning-273073e8e5ad (자동화 튜닝으로 비용 최적화, 스케일러블 인프라 설명) |
| 문서화 업데이트 주기 | SCP 콘솔 문서 저장소 검토 | 정상: 운영 문서가 분기 1회 업데이트됨<br>취약: 6개월 내 업데이트 없음 | 문서화 미업데이트 시 운영 지침 불일치로 오류가 발생하고, Ceph 구성 변경 추적으로 팀 간 혼란이 초래되며, 온보딩 지연과 지식 손실 발생함 | 업데이트를 월 1회로 설정하고, 버전 컨트롤(git) 적용함 | * 확인방법: 콘솔 문서 히스토리에서 수정 날짜 확인<br>* 설정방법: ceph config dump 문서 동기화 스크립트<br>* References<br>- IBM Storage Ceph Concepts and Architecture Guide: https://www.redbooks.ibm.com/redpapers/pdfs/redp5721.pdf (클러스터 문서화 및 git 백업 베스트 프랙티스) |
| 벤더 지원 티켓 관리 | SCP 콘솔 티켓 히스토리 조회 | 정상: 미해결 티켓이 5개 미만임<br>취약: 미해결 티켓 10개 초과임 | 티켓 관리 미흡 시 장애 해결 지연이 발생하고, Ceph 벤더 이슈 누적으로 운영 안정성 저하가 초래되며, SLA 위반으로 계약 불이익 발생함 | 티켓 우선순위화하고, 주 1회 리뷰 미팅 실시함 | * 확인방법: 콘솔 지원 포털에서 상태 필터 확인<br>* 설정방법: ceph health detail 티켓 트리거 스크립트<br>* References<br>- A Guide to OpenStack and Ceph Monitoring: https://trilio.io/openstack-training/openstack-and-ceph/ (벤더 지원 및 티켓 관리 베스트 프랙티스, 안정적 운영 가이드) |
| 자동화 스크립트 테스트 | SCP 콘솔 스크립트 실행 로그 검토 | 정상: 스크립트 테스트가 월 1회임<br>취약: 3개월 내 테스트 없음 | 테스트 미실시 시 스크립트 오류로 운영 자동화 실패가 발생하고, Ceph 작업 중단으로 수동 개입 증가가 초래되며, 효율성 저하와 오류 누적 발생함 | 테스트를 주 1회로 확대하고, 단위 테스트 프레임워크 도입함 | * 확인방법: 콘솔 자동화 로그에서 테스트 결과 확인<br>* 설정방법: ceph orch script test 스크립트 cronjob<br>* References<br>- Automation of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/automation-of-ceph-storage-cluster-tuning-273073e8e5ad (자동화 스크립트 튜닝 및 테스트 베스트 프랙티스) |
| 클러스터 업그레이드 계획 | SCP 콘솔 업그레이드 로드맵 검토 | 정상: 업그레이드 계획이 반기 1회 업데이트됨<br>취약: 1년 내 계획 없음 | 계획 미수립 시 업그레이드 지연으로 보안 취약점이 지속되고, Ceph 버전 불일치로 호환성 문제가 초래되며, 운영 중 기능 누락과 성능 저하 발생함 | 계획을 분기 1회 검토하고, 롤아웃 테스트 환경 구축함 | * 확인방법: 콘솔 업그레이드 대시보드에서 로드맵 확인<br>* 설정방법: ceph orch upgrade plan 스크립트 실행<br>* References<br>- Best Practices of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/best-practices-of-ceph-storage-cluster-tuning-57318cb5e6d9 (클러스터 업그레이드 및 계획 베스트 프랙티스) |
| 보안 패치 적용 주기 | SCP 콘솔 보안 패치 로그 조회 | 정상: 보안 패치가 월 1회 적용됨<br>취약: 3개월 내 적용 없음 | 패치 미적용 시 알려진 CVE 취약점이 노출되어 침해 위험이 증가하고, Ceph RGW 보안 홀이 운영 중 악용되어 데이터 유출이 초래되며, 규정 준수 위반으로 감사 실패함 | 패치 적용을 주 1회로 강화하고, 자동 스캔 도구 연동함 | * 확인방법: 콘솔 보안 대시보드에서 적용 이력 확인<br>* 설정방법: ceph orch apply security_patch 스크립트<br>* References<br>- Logging and Debugging - Ceph Documentation: https://docs.ceph.com/en/latest/rados/troubleshooting/log-and-debug/ (보안 로그 및 패치 디버깅 가이드) |
| 운영 보고서 생성 주기 | SCP 콘솔 보고서 아카이브 검토 | 정상: 운영 보고서가 주 1회 생성됨<br>취약: 월 1회 미만임 | 보고서 지연 시 성과 추적이 어려워지고, Ceph 메트릭스 미분석으로 최적화 기회 상실이 초래되며, 경영진 보고 지연으로 의사결정 오류 발생함 | 보고서를 자동 생성하고, KPI 대시보드 연동함 | * 확인방법: 콘솔 보고서 저장소에서 생성 날짜 확인<br>* 설정방법: ceph mgr module report 스크립트 cronjob<br>* References<br>- Ceph Dashboard: https://docs.ceph.com/en/latest/mgr/dashboard/ (운영 보고서 및 메트릭스 생성 가이드, 대시보드 기능 설명) |
| 성능 메트릭스 수집 | SCP 콘솔 메트릭스 로그 검토 | 정상: 메트릭스 수집 간격이 5분임<br>취약: 15분 초과임 | 수집 지연 시 성능 이상 탐지가 늦어지고, Ceph OSD 메트릭스 누락으로 튜닝 지연이 초래되며, 운영 중 병목 미인식으로 다운타임 증가함 | 수집 간격을 1분으로 단축하고, Promtail 연동함 | * 확인방법: 콘솔 메트릭스 대시보드에서 간격 확인<br>* 설정방법: ceph mgr prometheus module 활성화<br>* References<br>- Monitoring Services - Ceph Documentation: https://docs.ceph.com/en/reef/cephadm/services/monitoring/ (메트릭스 수집 및 Promtail 베스트 프랙티스) |
| OSD 실패 예측 알림 | SCP 콘솔 OSD 헬스 로그 분석 | 정상: SMART 메트릭스 알림이 활성화됨<br>취약: 예측 알림 비활성화임 | 예측 미설정 시 OSD 실패가 갑작스럽게 발생하고, Ceph 데이터 재배치 지연으로 용량 불균형이 초래되며, 운영 중 클러스터 불안정성 증가함 | SMART 모니터링을 강화하고, 실패 임계 알림 설정함 | * 확인방법: 콘솔 OSD 대시보드에서 SMART 상태 확인<br>* 설정방법: ceph osd smartctl 스크립트 cronjob<br>* References<br>- Best Practices of Ceph Storage Cluster Tuning: https://medium.com/@eren.c.uysal/best-practices-of-ceph-storage-cluster-tuning-57318cb5e6d9 (OSD 실패 예측 및 SMART 메트릭스 모니터링 가이드) |
| 모니터 쿼럼 안정성 확인 | SCP 콘솔 모니터 상태 조회 | 정상: 모니터 수가 3개 이상 유지됨<br>취약: 모니터 수가 2개 미만임 | 쿼럼 불안정 시 클러스터 상태 동기화 실패가 발생하고, Ceph 맵 업데이트 지연으로 데이터 접근 오류가 초래되며, 운영 중 가용성 저하와 장애 확산됨 | 모니터를 5개로 확대하고, 자동 failover 설정함 | * 확인방법: 콘솔 모니터 대시보드에서 수 확인<br>* 설정방법: ceph mon add 명령으로 추가<br>* References<br>- Chapter 3. Monitoring a Ceph storage cluster - Red Hat: https://docs.redhat.com/en/documentation/red_hat_ceph_storage/7/html/administration_guide/monitoring-a-ceph-storage-cluster (모니터 쿼럼 및 안정성 관리 베스트 프랙티스) |
| RGW 로그 분석 주기 | SCP 콘솔 RGW 로그 파일 검토 | 정상: RGW 로그 분석이 주 1회임<br>취약: 월 1회 미만임 | 분석 지연 시 RGW 오류 패턴 미인식으로 아카이빙 실패가 누적되고, Ceph API 호출 지연으로 운영 효율성 저하가 초래되며, 사용자 쿼리 오류 증가함 | 분석을 매일로 설정하고, Loki 쿼리 도구 사용함 | * 확인방법: 콘솔 RGW 로그 저장소에서 분석 날짜 확인<br>* 설정방법: ceph log rotate 및 analyze 스크립트<br>* References<br>- Monitoring Services - Ceph Documentation: https://docs.ceph.com/en/reef/cephadm/services/monitoring/ (RGW 로그 중앙화 및 분석 가이드, Loki 통합 설명) |
