---
title: "SKE Checklists"
date: 2025-09-03
tags: [ske, kubernetes, checklist]
categories: [Howtos, Kubernetes]
---

## 구성

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|----------------|----------|------|
| 클러스터 버전 확인 | kubectl version --short | 정상: SKE 클러스터 버전이 최신 안정 버전 (예: 1.28.x)임<br>취약: SKE 클러스터 버전이 오래된 버전 (예: 1.24.x 이하)임 | 오래된 Kubernetes 버전 사용 시 알려진 보안 취약점 노출되어 클러스터 침투 가능성 증가하며, 새로운 기능 미지원으로 운영 효율성 저하됨 | SKE 콘솔 또는 kubectl을 통해 클러스터를 최신 버전으로 업그레이드하여 보안 패치 적용하고 기능 업데이트함 | * 설정방법<br>SCP 콘솔에서 클러스터 업그레이드 선택 후 최신 버전 적용<br>* References<br>- Kubernetes Version and Version Skew Support Policy: https://kubernetes.io/docs/setup/release/version-skew-policy/ |
| RBAC 활성화 여부 | kubectl get clusterrolebindings | 정상: RBAC가 활성화되어 있으며 기본 역할 바인딩이 최소화됨<br>취약: RBAC가 비활성화되거나 과도한 권한 부여됨 | RBAC 미활성화 시 모든 사용자나 서비스가 클러스터 전체에 무제한 접근 가능하여 보안 침해 발생 위험이 높아짐 | SKE 클러스터 생성 시 RBAC를 기본으로 활성화하고, 최소 권한 원칙에 따라 역할과 바인딩 설정함 | * 설정방법<br>kubectl create clusterrolebinding ...<br>* References<br>- Using RBAC Authorization: https://kubernetes.io/docs/reference/access-authn-authz/rbac/ |
| Pod Security Admission 활성화 | kubectl get podsecuritypolicies | 정상: Pod Security Admission이 Strict 모드로 설정됨<br>취약: Pod Security Admission이 비활성화되거나 Privileged 모드임 | 취약한 Pod Security 설정 시 컨테이너가 호스트 시스템에 접근하여 보안 취약점 악용 가능하며, 악성 코드 실행 위험이 증가함 | SKE 클러스터에서 Pod Security Admission을 활성화하고 Baseline 또는 Restricted 정책 적용함 | * 설정방법<br>kubectl label --overwrite ns <namespace> pod-security.kubernetes.io/enforce=restricted<br>* References<br>- Pod Security Admission: https://kubernetes.io/docs/concepts/security/pod-security-admission/ |
| 네트워크 정책 설정 | kubectl get networkpolicies -A | 정상: 모든 네임스페이스에 기본 Deny 네트워크 정책 적용됨<br>취약: 네트워크 정책이 없거나 허용 범위가 과도함 | 네트워크 정책 미설정 시 Pod 간 무제한 통신으로 내부 공격 확산 가능하며, 데이터 유출 위험이 높아짐 | SKE에서 Calico 또는 유사 네트워킹 플러그인을 사용해 기본 Deny 정책과 필요한 Allow 규칙 정의함 | * 설정방법<br>kubectl apply -f networkpolicy.yaml<br>* References<br>- Network Policies: https://kubernetes.io/docs/concepts/services-networking/network-policies/ |
| 리소스 쿼터 설정 | kubectl get resourcequotas -A | 정상: 각 네임스페이스에 CPU/Memory 쿼터 설정됨<br>취약: 리소스 쿼터가 없거나 무제한임 | 리소스 쿼터 미설정 시 단일 워크로드가 클러스터 자원 독점하여 다른 애플리케이션 가용성 저하되고 비용 증가함 | SKE 클러스터 네임스페이스별로 ResourceQuota 객체 생성하여 리소스 상한 설정함 | * 설정방법<br>kubectl create resourcequota myquota --hard=cpu=1,memory=1Gi<br>* References<br>- Manage Resource Quotas: https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/ |
| 리밋 레인지 설정 | kubectl get limitranges -A | 정상: 각 네임스페이스에 Pod/Container 리밋 레인지 적용됨<br>취약: 리밋 레인지가 없음 | 리밋 레인지 미설정 시 Pod가 과도한 리소스 요청하여 클러스터 불안정화되며, 노드 다운 가능성 증가함 | SKE에서 LimitRange 객체를 네임스페이스에 적용하여 기본 리소스 제한 설정함 | * 설정방법<br>kubectl create limitrange mylimits --min=cpu=100m --default=cpu=500m<br>* References<br>- Limit Ranges: https://kubernetes.io/docs/concepts/policy/limit-range/ |
| 시크릿 관리 | kubectl get secrets -A | 정상: 시크릿이 암호화되어 저장되고 최소 접근 권한임<br>취약: 시크릿이 평문으로 저장되거나 과도한 접근임 | 시크릿 취약 시 민감 정보(키, 비밀번호) 유출되어 인증 우회나 데이터 탈취 발생 가능함 | SKE에서 etcd 암호화 활성화하고 RBAC로 시크릿 접근 제한함 | * 설정방법<br>kubectl create secret generic mysecret --from-literal=key=value<br>* References<br>- Secrets: https://kubernetes.io/docs/concepts/configuration/secret/ |
| 서비스 어카운트 토큰 | kubectl get serviceaccounts -A | 정상: 자동 마운트 비활성화 (automountServiceAccountToken=false)<br>취약: 자동 마운트 활성화됨 | 자동 마운트 시 Pod가 불필요한 클러스터 접근 권한 획득하여 보안 침해 위험이 높아짐 | SKE Pod 스펙에서 automountServiceAccountToken을 false로 설정함 | * 설정방법<br>Pod YAML: automountServiceAccountToken: false<br>* References<br>- Service Accounts: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/ |
| 인그레스 컨트롤러 설정 | kubectl get ingressclasses | 정상: 공식 IngressClass (예: nginx) 사용됨<br>취약: IngressClass가 없거나 커스텀임 | 취약한 Ingress 설정 시 외부 트래픽이 필터링되지 않아 DDoS나 injection 공격 노출됨 | SKE에서 SCP 제공 Ingress 컨트롤러 설치하고 TLS/Rate Limiting 설정함 | * 설정방법<br>kubectl apply -f ingress-nginx.yaml<br>* References<br>- Ingress: https://kubernetes.io/docs/concepts/services-networking/ingress/ |
| 로드 밸런서 설정 | kubectl get services -A \| grep LoadBalancer | 정상: LB가 최소 권한과 보안 그룹 적용됨<br>취약: LB가 공개되거나 보안 미적용임 | 공개 LB 시 외부 공격 표면 증가하여 무단 접근이나 데이터 유출 발생 가능함 | SCP LB에서 보안 그룹과 SSL 오프로드 설정함 | * 설정방법<br>SCP 콘솔에서 LB 보안 그룹 추가<br>* References<br>- Service: https://kubernetes.io/docs/concepts/services-networking/service/ |
| 방화벽 규칙 | SCP 콘솔에서 Firewall Rules 확인 | 정상: 최소 포트만 허용 (예: 80,443)<br>취약: 불필요 포트 개방됨 | 과도한 포트 개방 시 취약 서비스 노출되어 침투 공격 위험이 높아짐 | SCP Firewall에서 필요 포트만 허용하고 소스 IP 제한함 | * 설정방법<br>SCP 콘솔 Firewall Rule 생성<br>* References<br>- Network Policies in Kubernetes: https://kubernetes.io/docs/concepts/services-networking/network-policies/ |
| 노드풀 구성 | kubectl get nodes | 정상: 노드풀이 autoscaling 활성화됨<br>취약: 고정 노드 수로 구성됨 | 고정 노드 시 트래픽 증가 시 스케일링 실패로 서비스 다운 발생함 | SKE 클러스터에서 Cluster Autoscaler 활성화함 | * 설정방법<br>SCP 콘솔 Node Pool Autoscaling On<br>* References<br>- Cluster Autoscaler: https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler |
| 어드미션 컨트롤러 | kubectl describe clusterrole admin | 정상: NamespaceLifecycle, LimitRanger 등 활성화됨<br>취약: 필수 컨트롤러 비활성화됨 | 미활성화 시 유효하지 않은 객체 생성되어 클러스터 불안정화됨 | SKE API 서버에서 --enable-admission-plugins 설정함 | * 설정방법<br>API Server Flag: --enable-admission-plugins=NamespaceLifecycle,LimitRanger<br>* References<br>- Admission Controllers: https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/ |
| etcd 암호화 | kubectl get etcd | 정상: etcd 데이터가 암호화됨<br>취약: 평문 저장됨 | 평문 etcd 시 데이터 유출 시 클러스터 전체 제어 상실 가능함 | SKE에서 EncryptionConfig 파일로 etcd 암호화 활성화함 | * 설정방법<br>EncryptionConfig YAML 적용<br>* References<br>- Encrypting Secret Data at Rest: https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/ |
| API 서버 인증 | kubectl get apiserver | 정상: 클라이언트 인증서와 토큰 인증 활성화됨<br>취약: 익명 접근 허용됨 | 익명 접근 시 무단 API 호출로 클러스터 조작 가능함 | SKE에서 --anonymous-auth=false 설정함 | * 설정방법<br>API Server Flag: --anonymous-auth=false<br>* References<br>- Authentication: https://kubernetes.io/docs/reference/access-authn-authz/authentication/ |
| Kubelet 보안 설정 | kubectl get kubeletconfigs | 정상: --anonymous-auth=false, --authorization-mode=Webhook<br>취약: 기본 설정임 | 취약 Kubelet 시 노드 수준 공격으로 클러스터 침투 가능함 | SKE 노드에서 Kubelet Config 파일 수정함 | * 설정방법<br>Kubelet Flag: --anonymous-auth=false<br>* References<br>- Kubelet Authentication/Authorization: https://kubernetes.io/docs/reference/access-authn-authz/kubelet-authn-authz/ |
| 컨테이너 런타임 | kubectl get nodes -o jsonpath='{.items[*].status.nodeInfo.containerRuntimeVersion}' | 정상: containerd 또는 CRI-O 사용됨<br>취약: Docker 사용됨 | Docker 사용 시 알려진 취약점으로 컨테이너 탈출 위험이 있음 | SKE에서 containerd로 전환함 | * 설정방법<br>SCP 콘솔 CRI 선택<br>* References<br>- Container Runtimes: https://kubernetes.io/docs/setup/production-environment/container-runtimes/ |
| 네임스페이스 격리 | kubectl get namespaces | 정상: 애플리케이션별 네임스페이스 분리됨<br>취약: default 네임스페이스 과도 사용임 | 격리 미설정 시 애플리케이션 간 간섭으로 장애 확산됨 | SKE에서 네임스페이스 생성하고 리소스 분배함 | * 설정방법<br>kubectl create namespace myns<br>* References<br>- Namespaces: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/ |
| 헬름 차트 보안 | helm ls -A | 정상: 공식 차트 사용 및 값 검증됨<br>취약: 비공식 차트 사용임 | 비공식 차트 시 악성 코드 포함 가능하며 보안 취약점 노출됨 | SKE에서 Helm Tiller 비사용하고 값 파일 보안 설정함 | * 설정방법<br>helm install --values secure-values.yaml<br>* References<br>- Helm Security: https://helm.sh/docs/topics/security/ |
| 모니터링 에이전트 | kubectl get deployments -n monitoring | 정상: Prometheus 또는 유사 모니터링 설치됨<br>취약: 모니터링 미설정임 | 모니터링 없음 시 이상 징후 미탐지로 장애 지연 대응됨 | SKE에 Prometheus Operator 설치함 | * 설정방법<br>kubectl apply -f prometheus.yaml<br>* References<br>- Monitoring Kubernetes: https://kubernetes.io/docs/tasks/debug/debug-cluster/ |
| 로깅 설정 | kubectl get deployments -n logging | 정상: Fluentd 또는 ELK 스택 설치됨<br>취약: 로깅 미설정임 | 로깅 없음 시 감사 로그 누락으로 보안 사건 추적 불가함 | SKE에 EFK 스택 배포함 | * 설정방법<br>kubectl apply -f fluentd.yaml<br>* References<br>- Logging Architecture: https://kubernetes.io/docs/concepts/cluster-administration/logging/ |
| 백업 정책 | kubectl get cronjobs -A | 정상: Velero 또는 유사 백업 툴 설치됨<br>취약: 백업 미설정임 | 백업 없음 시 데이터 손실 시 복구 불가하며 비즈니스 중단됨 | SKE에 Velero 설치하고 스케줄 백업 설정함 | * 설정방법<br>velero install<br>* References<br>- Velero Documentation: https://velero.io/docs/ |
| 오토스케일링 | kubectl get hpa -A | 정상: HorizontalPodAutoscaler 설정됨<br>취약: 수동 스케일링임 | 수동 시 트래픽 변동 대응 실패로 성능 저하됨 | SKE Deployment에 HPA 적용함 | * 설정방법<br>kubectl autoscale deployment mydep --cpu-percent=50<br>* References<br>- Horizontal Pod Autoscaler: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ |
| 클러스터 엔드포인트 | kubectl cluster-info | 정상: 엔드포인트가 HTTPS만 사용됨<br>취약: HTTP 노출됨 | HTTP 사용 시 트래픽 스니핑으로 인증 정보 유출됨 | SKE API 서버를 HTTPS로만 설정함 | * 설정방법<br>API Server Flag: --secure-port=6443<br>* References<br>- Securing a Cluster: https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/ |
| 커스텀 어드미션 웹훅 | kubectl get validatingwebhookconfigurations | 정상: 보안 웹훅 (예: OPA) 설치됨<br>취약: 웹훅 미설정임 | 미설정 시 정책 위반 객체 생성되어 보안 약화됨 | SKE에 Open Policy Agent 설치함 | * 설정방법<br>kubectl apply -f opa.yaml<br>* References<br>- Admission Webhooks: https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/ |

## 결함 및 오류

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|----------------|----------|------|
| API 서버 오류 로그 확인 | kubectl logs -n kube-system -l component=kube-apiserver --tail=100 \| grep -i error | 정상: 최근 로그에 오류 메시지가 없음<br>취약: 오류 메시지(예: "Error serving request")가 다수 발생함 | API 서버 오류 발생 시 클러스터 전체 제어가 불가능해지며, 모든 API 호출이 실패하여 워크로드 배포와 관리가 중단됨 | API 서버 로그를 분석하여 원인(예: 인증 실패, 리소스 부족)을 파악하고, 해당 문제를 해결한 후 서버를 재시작함 | * 설정방법<br>kubectl describe pod -n kube-system -l component=kube-apiserver로 상세 확인 후 재배포<br>* References<br>- kube-apiserver: https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/ |
| Kubelet 오류 로그 확인 | kubectl logs -n kube-system -l component=kubelet --tail=100 \| grep -i error | 정상: 최근 로그에 오류 메시지가 없음<br>취약: 오류 메시지(예: "Failed to start container")가 다수 발생함 | Kubelet 오류 시 노드에서 Pod가 실행되지 않아 서비스 중단이 발생하며, 클러스터 가용성이 저하됨 | Kubelet 설정 파일을 검토하고, 노드 리소스나 컨테이너 런타임을 재구성한 후 Kubelet을 재시작함 | * 설정방법<br>systemctl restart kubelet (노드에서 실행)<br>* References<br>- Kubelet: https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/ |
| Pod 크래시 로그 확인 | kubectl logs <pod-name> -c <container-name> --previous | 정상: 크래시 로그가 없거나 해결된 상태임<br>취약: 크래시 로그에 반복적인 오류(예: OOMKilled)가 있음 | Pod 크래시 시 애플리케이션이 반복적으로 종료되어 서비스 불안정성이 증가하며, 사용자 요청이 실패함 | Pod 스펙에서 리소스 요청/제한을 조정하고, 애플리케이션 코드를 디버깅하여 크래시 원인을 제거함 | * 설정방법<br>kubectl edit pod <pod-name>으로 리소스 수정<br>* References<br>- Debugging Pods: https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/ |
| 네트워크 연결 오류 확인 | kubectl logs -n kube-system -l k8s-app=calico-node \| grep -i error | 정상: 네트워크 로그에 연결 오류가 없음<br>취약: 연결 오류(예: "Failed to connect to peer")가 발생함 | 네트워크 오류 시 Pod 간 통신이 실패하여 마이크로 서비스가 동작하지 않으며, 전체 시스템 장애가 확산됨 | CNI 플러그인(예: Calico)을 재설치하거나 네트워크 정책을 재검토하여 연결 문제를 해결함 | * 설정방법<br>kubectl apply -f calico.yaml로 재배포<br>* References<br>- Network Plugins: https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/ |
| 인증 오류 로그 확인 | kubectl logs -n kube-system -l component=kube-apiserver \| grep -i "authentication failed" | 정상: 인증 오류 로그가 없음<br>취약: 인증 실패 로그가 반복적으로 발생함 | 인증 오류 시 무단 접근 시도가 증가하며, 클러스터 보안이 취약해져 데이터 유출 위험이 있음 | RBAC 설정을 강화하고, 인증서나 토큰을 갱신하여 인증 메커니즘을 재구성함 | * 설정방법<br>kubectl apply -f rbac.yaml로 역할 바인딩 수정<br>* References<br>- Authentication: https://kubernetes.io/docs/reference/access-authn-authz/authentication/ |
| 리소스 부족 오류 확인 | kubectl get events -A \| grep -i OOMKilled | 정상: OOMKilled 이벤트가 없음<br>취약: OOMKilled 이벤트가 빈번함 | 리소스 부족 시 컨테이너가 강제 종료되어 애플리케이션 가용성이 저하되며, 성능 저하가 발생함 | 노드 리소스를 증설하거나 Pod의 리소스 쿼터를 설정하여 자원 할당을 최적화함 | * 설정방법<br>kubectl create resourcequota <quota-name> --hard=memory=10Gi<br>* References<br>- Resource Management: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/ |
| 이미지 풀 오류 확인 | kubectl describe pod <pod-name> \| grep -i "Failed to pull image" | 정상: 이미지 풀 이벤트가 없음<br>취약: 이미지 풀 실패 이벤트가 있음 | 이미지 풀 오류 시 Pod가 시작되지 않아 배포가 지연되며, 서비스 롤아웃이 실패함 | 이미지 레지스트리 접근 권한을 확인하고, 네트워크 연결을 재설정하여 이미지를 재풀함 | * 설정방법<br>kubectl apply -f image-pull-secret.yaml<br>* References<br>- Images: https://kubernetes.io/docs/concepts/containers/images/ |
| 볼륨 마운트 오류 확인 | kubectl describe pod <pod-name> \| grep -i "FailedMount" | 정상: FailedMount 이벤트가 없음<br>취약: FailedMount 이벤트가 발생함 | 볼륨 마운트 오류 시 데이터 접근이 불가능해지며, Stateful 애플리케이션이 동작하지 않음 | PV/PVC 설정을 검토하고, 스토리지 프로비저너를 재구성하여 마운트 문제를 해결함 | * 설정방법<br>kubectl edit pvc <pvc-name>으로 수정<br>* References<br>- Persistent Volumes: https://kubernetes.io/docs/concepts/storage/persistent-volumes/ |
| DNS 해석 오류 확인 | kubectl logs -n kube-system -l k8s-app=coredns \| grep -i error | 정상: CoreDNS 로그에 오류가 없음<br>취약: DNS 쿼리 실패 오류가 있음 | DNS 오류 시 서비스 디스커버리가 실패하여 Pod 간 통신이 불가능해지며, 네트워크 장애가 발생함 | CoreDNS ConfigMap을 수정하고, Pod를 재시작하여 DNS 설정을 최적화함 | * 설정방법<br>kubectl edit configmap coredns -n kube-system<br>* References<br>- DNS for Services and Pods: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/ |
| Ingress 오류 로그 확인 | kubectl logs -n ingress-nginx -l app=ingress-nginx \| grep -i error | 정상: Ingress 로그에 오류가 없음<br>취약: 라우팅 오류(예: "upstream timed out")가 발생함 | Ingress 오류 시 외부 트래픽이 차단되어 서비스 접근이 불가능해지며, 사용자 경험이 저하됨 | Ingress 규칙을 재검토하고, 백엔드 서비스를 확인하여 라우팅을 재구성함 | * 설정방법<br>kubectl edit ingress <ingress-name><br>* References<br>- Ingress Controllers: https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/ |
| Service 엔드포인트 오류 확인 | kubectl get endpoints -A \| grep -v "1/1" | 정상: 모든 엔드포인트가 Ready 상태임<br>취약: 엔드포인트가 NotReady 상태임 | 엔드포인트 오류 시 서비스 로드 밸런싱이 실패하여 트래픽 분산이 안 되며, 성능 저하가 발생함 | Pod Readiness Probe를 조정하고, 서비스 셀렉터를 확인하여 엔드포인트를 재생성함 | * 설정방법<br>kubectl edit service <service-name><br>* References<br>- Services: https://kubernetes.io/docs/concepts/services-networking/service/ |
| ConfigMap 로드 오류 확인 | kubectl describe pod <pod-name> \| grep -i "Failed to load configmap" | 정상: ConfigMap 로드 이벤트가 없음<br>취약: 로드 실패 이벤트가 있음 | ConfigMap 오류 시 애플리케이션 설정이 적용되지 않아 동작 이상이 발생하며, 구성 오류가 확산됨 | ConfigMap 내용을 검증하고, 볼륨 마운트 경로를 수정하여 재배포함 | * 설정방법<br>kubectl apply -f configmap.yaml<br>* References<br>- ConfigMaps: https://kubernetes.io/docs/concepts/configuration/configmap/ |
| Deployment 롤아웃 실패 확인 | kubectl rollout status deployment <dep-name> | 정상: 롤아웃이 성공함<br>취약: 롤아웃이 실패하거나 지연됨 | 롤아웃 실패 시 새 버전 배포가 안 되어 버그가 지속되며, 애플리케이션 업데이트가 지연됨 | Deployment 스펙을 검토하고, 이미지 태그나 리소스를 수정하여 롤아웃을 재시도함 | * 설정방법<br>kubectl rollout restart deployment <dep-name><br>* References<br>- Deployments: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ |
| StatefulSet 파티션 오류 확인 | kubectl get statefulset <sts-name> -o yaml \| grep partitions | 정상: 파티션이 0임<br>취약: 파티션이 증가하거나 오류 발생함 | 파티션 오류 시 StatefulSet 스케일링이 실패하여 데이터 일관성이 깨지며, 장애가 발생함 | StatefulSet 파티션을 0으로 설정하고, Pod를 재배포하여 상태를 복구함 | * 설정방법<br>kubectl patch statefulset <sts-name> -p '{"spec":{"updateStrategy":{"rollingUpdate":{"partition":0}}}'<br>* References<br>- StatefulSets: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/ |
| CronJob 실패 로그 확인 | kubectl logs job/<job-name> | 정상: Job 로그에 오류가 없음<br>취약: Job 실행 실패 오류가 있음 | CronJob 실패 시 스케줄 작업이 실행되지 않아 백업이나 배치 처리가 중단되며, 운영 효율이 저하됨 | CronJob 스펙을 수정하고, 컨테이너 명령어를 디버깅하여 Job을 재실행함 | * 설정방법<br>kubectl create cronjob <cron-name> --schedule="*/5 * * * *" --image=<image><br>* References<br>- CronJobs: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/ |
| Node NotReady 상태 확인 | kubectl get nodes \| grep -v Ready | 정상: 모든 노드가 Ready 상태임<br>취약: NotReady 노드가 있음 | NotReady 노드 시 워크로드가 스케줄되지 않아 클러스터 용량이 감소하며, 가용성이 저하됨 | 노드 로그를 확인하고, 하드웨어/네트워크 문제를 해결한 후 노드를 재활성화함 | * 설정방법<br>kubectl uncordon <node-name><br>* References<br>- Nodes: https://kubernetes.io/docs/concepts/architecture/nodes/ |
| Etcd 오류 로그 확인 | kubectl logs -n kube-system -l component=etcd \| grep -i error | 정상: Etcd 로그에 오류가 없음<br>취약: 클러스터 상태 오류(예: "leader changes")가 발생함 | Etcd 오류 시 클러스터 메타데이터가 손상되어 전체 제어가 불가능해지며, 데이터 손실이 발생함 | Etcd 백업을 복구하고, 클러스터를 재구성하여 안정성을 회복함 | * 설정방법<br>etcdctl snapshot restore <backup-file><br>* References<br>- Operating etcd clusters: https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/ |
| CNI 플러그인 오류 확인 | kubectl logs -n kube-system -l name=flannel \| grep -i error | 정상: CNI 로그에 오류가 없음<br>취약: IP 할당 실패 오류가 있음 | CNI 오류 시 Pod IP가 할당되지 않아 네트워크 통신이 불가능해지며, 클러스터가 마비됨 | CNI 설정 파일을 검토하고, 플러그인을 재설치하여 네트워크를 재초기화함 | * 설정방법<br>kubectl apply -f flannel.yaml<br>* References<br>- Cluster Networking: https://kubernetes.io/docs/concepts/cluster-administration/networking/ |
| Admission webhook 실패 확인 | kubectl get validatingwebhookconfigurations \| grep -i failed | 정상: Webhook 상태가 정상임<br>취약: Webhook 호출 실패가 있음 | Webhook 실패 시 정책 적용이 안 되어 보안 취약점이 노출되며, 클러스터가 위험해짐 | Webhook 서버를 확인하고, 인증서를 갱신하여 webhook을 재활성화함 | * 설정방법<br>kubectl apply -f webhook.yaml<br>* References<br>- Dynamic Admission Control: https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/ |
| Scheduler 오류 로그 확인 | kubectl logs -n kube-system -l component=scheduler \| grep -i error | 정상: Scheduler 로그에 오류가 없음<br>취약: 스케줄링 실패 오류가 발생함 | Scheduler 오류 시 Pod가 노드에 배정되지 않아 워크로드가 지연되며, 리소스 낭비가 발생함 | Scheduler 설정을 최적화하고, 노드 선호도를 수정하여 스케줄링을 개선함 | * 설정방법<br>kubectl edit configmap kube-scheduler-config -n kube-system<br>* References<br>- kube-scheduler: https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/ |
| Controller manager 오류 확인 | kubectl logs -n kube-system -l component=controller-manager \| grep -i error | 정상: Controller 로그에 오류가 없음<br>취약: 컨트롤 루프 실패 오류가 있음 | Controller 오류 시 리소스 조정이 실패하여 클러스터 상태가 불안정해지며, 자동 복구가 안 됨 | Controller 매니저 플래그를 조정하고, Pod를 재시작하여 컨트롤 루프를 복구함 | * 설정방법<br>kubectl edit deployment kube-controller-manager -n kube-system<br>* References<br>- kube-controller-manager: https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/ |
| Audit 로그 오류 이벤트 확인 | kubectl logs -n kube-system -l component=apiserver \| grep -i audit | 정상: Audit 로그가 정상 기록됨<br>취약: Audit 실패 이벤트가 있음 | Audit 오류 시 보안 이벤트가 기록되지 않아 침해 추적이 불가능해지며, 규정 준수가 위반됨 | Audit 정책 파일을 설정하고, 로그 볼륨을 증설하여 감사 로그를 안정적으로 기록함 | * 설정방법<br>API Server Flag: --audit-policy-file=/etc/kubernetes/audit-policy.yaml<br>* References<br>- Auditing: https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/ |
| 메트릭 수집 오류 확인 | kubectl logs -n monitoring -l app=prometheus \| grep -i error | 정상: Prometheus 로그에 오류가 없음<br>취약: 스크랩 실패 오류가 발생함 | 메트릭 오류 시 모니터링이 안 되어 장애를 사전에 감지하지 못하며, 성능 관리가 어려움 | Prometheus Config를 수정하고, 타겟 엔드포인트를 확인하여 메트릭 수집을 재구성함 | * 설정방법<br>kubectl edit configmap prometheus-config -n monitoring<br>* References<br>- Monitoring Kubernetes: https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/ |
| 백업 실패 로그 확인 | velero backup logs <backup-name> \| grep -i error | 정상: 백업 로그에 오류가 없음<br>취약: 백업 실패 오류(예: "partial failure")가 있음 | 백업 실패 시 데이터 복구가 불가능해지며, 장애 발생 시 비즈니스 연속성이 깨짐 | Velero 설정을 검토하고, 스토리지 버킷 권한을 확인하여 백업을 재실행함 | * 설정방법<br>velero backup create <backup-name> --include-namespaces=all<br>* References<br>- Velero Documentation: https://velero.io/docs/ |
| 업그레이드 실패 로그 확인 | kubectl get events -A \| grep -i "upgrade failed" | 정상: 업그레이드 이벤트가 성공함<br>취약: 업그레이드 실패 이벤트가 있음 | 업그레이드 실패 시 클러스터 버전이 불안정해지며, 보안 패치가 적용되지 않아 취약점이 노출됨 | 업그레이드 계획을 재수립하고, 호환성을 확인하여 클러스터를 안전하게 업그레이드함 | * 설정방법<br>SKE 콘솔에서 클러스터 업그레이드 선택<br>* References<br>- Upgrading kubeadm clusters: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/ |

## 가용성 

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|----------------|----------|------|
| 클러스터 멀티 AZ 배포 | SCP 콘솔에서 클러스터 세부 정보 확인 또는 kubectl get nodes -o wide | 정상: 노드가 2개 이상의 가용 영역(AZ)에 분산 배포됨<br>취약: 모든 노드가 단일 AZ에 배포됨 | 단일 AZ 배포 시 해당 AZ 장애 발생으로 클러스터 전체 다운이 발생하며, 서비스 중단 시간이 길어져 비즈니스 연속성이 저하됨 | SKE 클러스터 생성 시 멀티 AZ 옵션을 선택하고 노드풀을 각 AZ에 분산 배포하여 장애 내성을 강화함 | * 설정방법<br>SCP 콘솔에서 클러스터 생성 시 Availability Zones 선택 후 여러 AZ 지정<br>* References<br>- High Availability in Kubernetes: https://kubernetes.io/docs/setup/best-practices/multiple-zones/ |
| 노드 autoscaling 활성화 | kubectl get clusterautoscaler | 정상: ClusterAutoscaler가 배포되어 있고 autoscaling 그룹이 활성화됨<br>취약: ClusterAutoscaler가 비활성화되거나 설정되지 않음 | autoscaling 미활성화 시 워크로드 증가로 노드 부족이 발생하여 Pod 스케줄링 실패가 일어나며, 애플리케이션 가용성이 저하됨 | SKE에서 ClusterAutoscaler를 설치하고 노드풀 autoscaling을 활성화하여 동적 노드 확장을 구현함 | * 설정방법<br>SCP 콘솔 Node Pool 설정에서 Autoscaling On 선택<br>* References<br>- Cluster Autoscaler: https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler |
| Pod Disruption Budget 설정 | kubectl get pdb -A | 정상: 주요 워크로드에 PDB가 설정되어 최소 가용 Pod 수가 보장됨<br>취약: PDB가 없거나 가용 Pod 수가 0으로 설정됨 | PDB 미설정 시 노드 드레인이나 업그레이드 중 모든 Pod가 동시에 종료되어 서비스 중단이 발생하며, 가용성 저하가 초래됨 | SKE에서 PodDisruptionBudget 객체를 생성하여 최소 가용 Pod 수를 지정하고 워크로드에 적용함 | * 설정방법<br>kubectl apply -f pdb.yaml (minAvailable: 1)<br>* References<br>- Pod Disruption Budgets: https://kubernetes.io/docs/tasks/run-application/configure-pdb/ |
| Replica 수 설정 | kubectl get deployments -A -o yaml \| grep replicas | 정상: StatefulSet/Deployment에 replicas가 2 이상 설정됨<br>취약: replicas가 1로 설정됨 | 단일 replica 시 Pod 실패로 서비스 전체가 중단되며, 복구 시간이 길어져 사용자 요청이 실패함 | SKE Deployment/StatefulSet 스펙에서 replicas를 3 이상으로 증가시켜 고가용성을 확보함 | * 설정방법<br>kubectl scale deployment <dep-name> --replicas=3<br>* References<br>- Replicas in Kubernetes: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/ |
| Liveness/Readiness Probes 설정 | kubectl describe deployments -A \| grep Probes | 정상: 모든 Pod에 livenessProbe와 readinessProbe가 정의됨<br>취약: Probes가 없거나 잘못 설정됨 | Probes 미설정 시 비정상 Pod가 트래픽을 수신하여 서비스 불안정성이 증가하며, 장애 확산이 발생함 | SKE Pod 스펙에 HTTP/TCP/Exec 기반 probes를 추가하여 Pod 건강 상태를 모니터링함 | * 설정방법<br>Pod YAML: livenessProbe: httpGet: path: /healthz, port: 8080<br>* References<br>- Configure Liveness, Readiness Probes: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/ |
| Anti-affinity 규칙 적용 | kubectl get pods -A -o yaml \| grep affinity | 정상: Pod에 node/pod anti-affinity가 설정되어 분산 배포됨<br>취약: affinity 규칙이 없음 | anti-affinity 미적용 시 Pod가 단일 노드에 집중되어 노드 장애로 다중 Pod 실패가 발생하며, 가용성이 저하됨 | SKE Pod 스펙에 preferredDuringSchedulingIgnoredDuringExecution anti-affinity를 추가하여 분산을 강제함 | * 설정방법<br>Pod YAML: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution...<br>* References<br>- Affinity and Anti-Affinity: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity |
| Topology Spread Constraints 설정 | kubectl get deployments -A -o yaml \| grep topologySpreadConstraints | 정상: Deployment에 topologySpreadConstraints가 정의됨<br>취약: topologySpreadConstraints가 없음 | topology 미설정 시 Pod가 특정 토폴로지(예: AZ)에 편중되어 해당 영역 장애로 서비스 중단이 발생함 | SKE Deployment 스펙에 maxSkew를 설정한 topologySpreadConstraints를 추가하여 균형 배포를 구현함 | * 설정방법<br>Deployment YAML: topologySpreadConstraints: - maxSkew: 1, topologyKey: topology.kubernetes.io/zone<br>* References<br>- Topology Spread Constraints: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/ |
| Master 노드 HA 구성 | kubectl get nodes -l node-role.kubernetes.io/master | 정상: Master 노드가 3개 이상으로 HA 구성됨<br>취약: Master 노드가 단일임 | 단일 Master 시 Master 장애로 API 서버 다운이 발생하며, 클러스터 제어가 불가능해짐 | SKE 클러스터 생성 시 HA Master 옵션을 선택하여 다중 Master 노드를 배포함 | * 설정방법<br>SCP 콘솔에서 High Availability Master 선택<br>* References<br>- High Availability Kubernetes Clusters: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/ |
| Etcd HA 클러스터 | kubectl get etcd -n kube-system | 정상: Etcd가 3개 이상의 멤버로 클러스터링됨<br>취약: Etcd가 단일 인스턴스임 | 단일 Etcd 시 Etcd 장애로 클러스터 상태 손실이 발생하며, 전체 클러스터 복구가 어려움 | SKE에서 Etcd를 스택된 또는 외부 클러스터로 HA 구성하여 데이터 복제를 활성화함 | * 설정방법<br>Etcd 클러스터 설정: etcdctl member list<br>* References<br>- Operating etcd clusters for Kubernetes: https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/ |
| Load Balancer HA 설정 | SCP 콘솔에서 LB 세부 정보 확인 | 정상: LB가 Active-Standby 또는 Active-Active HA 모드로 구성됨<br>취약: LB가 단일 인스턴스임 | 단일 LB 시 LB 장애로 외부 트래픽 차단이 발생하며, 서비스 접근이 불가능해짐 | SCP LB 생성 시 HA 옵션을 선택하고 다중 AZ에 배포하여 failover를 구현함 | * 설정방법<br>SCP 콘솔 LB 설정에서 High Availability On<br>* References<br>- Load Balancer High Availability: https://cloud.google.com/load-balancing/docs/high-availability (유사 클라우드 예시, SCP 문서 참조) |
| Persistent Volume HA | kubectl get pv -A | 정상: PV가 Multi-AZ 스토리지 또는 replicated 스토리지 사용됨<br>취약: PV가 단일 AZ 스토리지임 | 단일 AZ PV 시 AZ 장애로 데이터 접근 불가 상태가 발생하며, Stateful 앱 가용성이 저하됨 | SKE에서 replicated 스토리지 클래스(예: Ceph)를 사용하거나 Multi-AZ 볼륨을 프로비전함 | * 설정방법<br>StorageClass YAML: provisioner: ceph.com/rbd<br>* References<br>- Persistent Volumes: https://kubernetes.io/docs/concepts/storage/persistent-volumes/ |
| 백업 및 복구 정책 | kubectl get cronjobs -A \| grep backup | 정상: Velero 또는 유사 툴로 정기 백업 CronJob이 설정됨<br>취약: 백업 정책이 없음 | 백업 미설정 시 장애 발생으로 데이터 손실이 영구화되며, 복구 시간이 길어짐 | SKE에 Velero를 설치하고 BackupSchedule을 생성하여 정기 백업을 구현함 | * 설정방법<br>velero schedule create daily --schedule="@every 24h"<br>* References<br>- Velero Documentation: https://velero.io/docs/ |
| 모니터링 및 경고 설정 | kubectl get deployments -n monitoring \| grep prometheus | 정상: Prometheus와 Alertmanager가 배포되어 가용성 메트릭 경고 설정됨<br>취약: 모니터링 시스템이 없음 | 모니터링 미설정 시 장애를 사전 감지하지 못하여 다운타임이 증가하며, 대응 지연이 발생함 | SKE에 Prometheus Operator를 설치하고 가용성 관련 규칙(예: PodDown)을 추가함 | * 설정방법<br>kubectl apply -f prometheus-operator.yaml<br>* References<br>- Monitoring Kubernetes: https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/ |
| 리소스 요청/제한 설정 | kubectl get pods -A -o yaml \| grep resources | 정상: 모든 Pod에 requests/limits가 정의됨<br>취약: resources가 미정의됨 | resources 미설정 시 리소스 경쟁으로 Pod eviction이 발생하며, 서비스 불안정성이 증가함 | SKE Pod 스펙에 cpu/memory requests/limits를 추가하여 안정적 할당을 보장함 | * 설정방법<br>Pod YAML: resources: requests: cpu: 100m, memory: 128Mi<br>* References<br>- Manage Resources for Containers: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/ |
| Horizontal Pod Autoscaler 설정 | kubectl get hpa -A | 정상: 주요 워크로드에 HPA가 설정되어 CPU/Memory 기반 스케일링됨<br>취약: HPA가 없음 | HPA 미설정 시 트래픽 증가로 과부하가 발생하며, 응답 지연과 다운이 초래됨 | SKE Deployment에 HPA를 생성하고 minReplicas를 2 이상으로 설정함 | * 설정방법<br>kubectl autoscale deployment <dep-name> --cpu-percent=50 --min=2 --max=10<br>* References<br>- Horizontal Pod Autoscaler: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ |
| Vertical Pod Autoscaler 설정 | kubectl get vpa -A | 정상: VPA가 배포되어 Pod 리소스 자동 조정됨<br>취약: VPA가 없음 | VPA 미설정 시 리소스 과/부족으로 Pod 불안정성이 발생하며, 가용성 저하가 일어남 | SKE에 VPA를 설치하고 recommender 모드로 Pod 리소스를 최적화함 | * 설정방법<br>kubectl apply -f vpa.yaml (updateMode: "Auto")<br>* References<br>- Vertical Pod Autoscaler: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler |
| 노드 드레인/언코드 절차 | kubectl get nodes \| grep SchedulingDisabled | 정상: 드레인된 노드가 없고, 유지보수 시 PDB 준수됨<br>취약: 무작위 드레인으로 Pod 중단됨 | 무절차 드레인 시 서비스 중단이 발생하며, 복구 프로세스가 혼란스러움 | SKE 운영 시 kubectl drain --ignore-daemonsets를 사용하고 PDB를 준수하여 안전 드레인을 구현함 | * 설정방법<br>kubectl drain <node-name> --pod-selector=<selector><br>* References<br>- Safely Drain a Node: https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/ |
| 업그레이드 전략 설정 | kubectl get deployments -A -o yaml \| grep strategy | 정상: Deployment에 RollingUpdate strategy가 maxUnavailable: 0으로 설정됨<br>취약: Recreate strategy 또는 maxUnavailable 높음 | 취약 전략 시 업그레이드 중 다운타임이 발생하며, 서비스 가용성이 저하됨 | SKE Deployment 스펙에 rollingUpdate: maxUnavailable: 0, maxSurge: 25%를 설정함 | * 설정방법<br>Deployment YAML: strategy: type: RollingUpdate<br>* References<br>- Performing a Rolling Update: https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/ |
| 네트워크 중복성 | SCP 콘솔에서 VPC/Subnets 확인 | 정상: 다중 Subnet과 VPC Peering으로 중복 경로 구성됨<br>취약: 단일 Subnet 사용됨 | 단일 네트워크 시 네트워크 장애로 Pod 통신이 차단되며, 클러스터 가용성이 저하됨 | SCP VPC에서 다중 Subnet을 생성하고 SKE 클러스터를 배포하여 중복성을 확보함 | * 설정방법<br>SCP 콘솔 VPC 설정에서 Subnet 추가<br>* References<br>- Kubernetes Networking: https://kubernetes.io/docs/concepts/cluster-administration/networking/ |
| 방화벽 중복성 | SCP 콘솔에서 Firewall Rules 확인 | 정상: 방화벽 규칙이 다중 그룹으로 HA 구성됨<br>취약: 단일 방화벽 그룹임 | 단일 방화벽 시 규칙 업데이트 실패로 트래픽 차단이 발생하며, 서비스 중단이 일어남 | SCP Firewall에서 태그 기반 규칙을 다중 적용하고 자동 failover를 설정함 | * 설정방법<br>SCP 콘솔 Firewall Rule 복제 및 적용<br>* References<br>- Firewall Rules Overview: https://cloud.google.com/vpc/docs/firewalls (유사 클라우드 예시) |
| DNS 중복성 | kubectl get svc kube-dns -n kube-system | 정상: CoreDNS가 다중 replicas로 배포됨<br>취약: CoreDNS replicas가 1임 | 단일 DNS 시 DNS Pod 실패로 이름 해석이 불가능해지며, 서비스 디스커버리 장애가 발생함 | SKE kube-system에서 CoreDNS Deployment replicas를 3으로 증가시킴 | * 설정방법<br>kubectl scale deployment coredns -n kube-system --replicas=3<br>* References<br>- DNS for Services and Pods: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/ |
| Service health checks | kubectl describe svc -A \| grep healthCheck | 정상: LoadBalancer Service에 healthCheckNodePort가 설정됨<br>취약: healthCheck가 없음 | healthCheck 미설정 시 비정상 노드가 트래픽을 수신하여 응답 실패가 발생하며, 가용성 저하됨 | SKE Service 스펙에 healthCheckNodePort를 추가하고 probes와 연동함 | * 설정방법<br>Service YAML: type: LoadBalancer, healthCheckNodePort: 30000<br>* References<br>- LoadBalancer Services: https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer |
| Ingress replicas 설정 | kubectl get deployments -n ingress-nginx | 정상: Ingress 컨트롤러 Deployment replicas가 2 이상임<br>취약: replicas가 1임 | 단일 Ingress 시 컨트롤러 실패로 외부 라우팅이 중단되며, 서비스 접근 불가 상태가 발생함 | SKE ingress-nginx Deployment를 scale하여 다중 replicas를 배포함 | * 설정방법<br>kubectl scale deployment ingress-nginx-controller -n ingress-nginx --replicas=3<br>* References<br>- Ingress Controllers: https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/ |
| Failover 메커니즘 | SCP 콘솔에서 LB Failover 확인 | 정상: LB에 failover 그룹이 설정됨<br>취약: failover가 없음 | failover 미설정 시 Primary 실패로 트래픽 손실이 발생하며, 다운타임이 증가함 | SCP LB 설정에서 Failover Group을 생성하고 백업 인스턴스를 지정함 | * 설정방법<br>SCP 콘솔 LB Failover 옵션 활성화<br>* References<br>- Failover Configuration: https://aws.amazon.com/elasticloadbalancing/features/ (유사 클라우드 예시) |
| 노드 헬스 체크 | kubectl get nodes -o yaml \| grep conditions | 정상: 모든 노드 조건이 Ready=True임<br>취약: NotReady 노드가 있음 | NotReady 노드 시 워크로드가 재배포되지 않아 가용 Pod 수가 감소하며, 서비스 불안정성이 발생함 | SKE 노드 헬스 체크를 강화하고 자동 복구 스크립트를 구현함 | * 설정방법<br>kubectl describe node <node-name>으로 확인 후 uncordon<br>* References<br>- Node Conditions: https://kubernetes.io/docs/concepts/architecture/nodes/#condition |

## 성능 및 용량

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|----------------|----------|------|
| CPU 사용률 모니터링 | kubectl top nodes \| kubectl top pods -A | 정상: 노드/Pod CPU 사용률이 70% 미만임<br>취약: 노드/Pod CPU 사용률이 70% 초과함 | CPU 과부하 시 Pod 응답 지연이 발생하며, 스케줄링 실패로 새로운 워크로드 배포가 불가능해져 전체 클러스터 성능이 저하됨 | Prometheus와 Grafana를 설치하여 CPU 메트릭을 모니터링하고, HPA를 설정하여 자동 스케일링을 통해 CPU 부하를 분산함 | * 설정방법<br>kubectl apply -f prometheus.yaml 후 Grafana 대시보드에서 CPU 쿼리 추가<br>* References<br>- Monitoring Kubernetes Cluster Resources: https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-usage-monitoring/ |
| 메모리 사용률 모니터링 | kubectl top nodes \| kubectl top pods -A | 정상: 노드/Pod 메모리 사용률이 80% 미만임<br>취약: 노드/Pod 메모리 사용률이 80% 초과함 | 메모리 부족 시 OOMKilled 이벤트가 빈번하게 발생하여 Pod가 반복 종료되며, 애플리케이션 안정성과 성능이 저하됨 | VPA를 활성화하여 Pod 메모리 요청을 자동 조정하고, ResourceQuota를 네임스페이스에 적용하여 메모리 과사용을 제한함 | * 설정방법<br>kubectl apply -f vpa.yaml (targetRef: kind: Deployment)<br>* References<br>- Vertical Pod Autoscaler: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler |
| 디스크 I/O 성능 | kubectl exec -it <pod-name> -- iostat -x 1 5 | 정상: 디스크 I/O 대기 시간이 10ms 미만임<br>취약: 디스크 I/O 대기 시간이 10ms 초과함 | 디스크 I/O 병목 시 데이터 읽기/쓰기 지연이 발생하여 Stateful 애플리케이션의 응답 시간이 증가하며, 전체 시스템 성능이 저하됨 | 고성능 스토리지 클래스(예: SSD 기반)를 사용하고, PV 크기를 증설하여 I/O 부하를 분산함 | * 설정방법<br>StorageClass YAML: provisioner: kubernetes.io/aws-ebs, parameters: type: gp3<br>* References<br>- Storage Classes: https://kubernetes.io/docs/concepts/storage/storage-classes/ |
| 네트워크 throughput | kubectl exec -it <pod-name> -- iperf -c <target-ip> | 정상: 네트워크 throughput이 1Gbps 이상임<br>취약: 네트워크 throughput이 1Gbps 미만임 | 네트워크 병목 시 Pod 간 통신 지연이 발생하여 마이크로 서비스 응답 시간이 증가하며, 데이터 전송 효율이 저하됨 | CNI 플러그인(예: Calico)을 최적화하고, SCP 네트워크 대역폭을 업그레이드하여 throughput을 향상함 | * 설정방법<br>kubectl apply -f calico.yaml (with MTU tuning)<br>* References<br>- Network Plugins: https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/ |
| Pod 리소스 요청/제한 설정 | kubectl get pods -A -o yaml \| grep resources | 정상: 모든 Pod에 requests/limits가 적절히 정의됨<br>취약: requests/limits가 미정의 또는 과도함 | 리소스 미설정 시 과도한 자원 소비로 노드 불안정성이 발생하며, 다른 Pod의 성능이 저하됨 | LimitRange를 네임스페이스에 적용하여 기본 requests/limits를 설정하고, Pod 스펙을 검토하여 최적화함 | * 설정방법<br>kubectl create limitrange <name> --min=cpu=100m --max=cpu=1<br>* References<br>- Limit Ranges: https://kubernetes.io/docs/concepts/policy/limit-range/ |
| Horizontal Pod Autoscaler 설정 | kubectl get hpa -A | 정상: 주요 워크로드에 HPA가 CPU/Memory 기반으로 설정됨<br>취약: HPA가 없거나 잘못 설정됨 | HPA 미설정 시 부하 증가로 응답 지연이 발생하며, 수동 스케일링으로 운영 효율이 저하됨 | HPA를 생성하여 minReplicas 2 이상, targetCPUUtilizationPercentage 50%로 설정함 | * 설정방법<br>kubectl autoscale deployment <name> --cpu-percent=50 --min=2 --max=10<br>* References<br>- Horizontal Pod Autoscaler: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ |
| Vertical Pod Autoscaler 설정 | kubectl get vpa -A | 정상: VPA가 recommender/update 모드로 활성화됨<br>취약: VPA가 비활성화됨 | VPA 미설정 시 Pod 리소스 과/부족으로 eviction이 발생하며, 성능 불안정성이 증가함 | VPA를 설치하고 Auto updateMode로 Pod 리소스를 동적 조정함 | * 설정방법<br>kubectl apply -f vpa-recommender.yaml<br>* References<br>- Vertical Pod Autoscaler: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler |
| 노드 용량 계획 | kubectl describe nodes \| grep Allocatable | 정상: 노드 CPU/Memory allocatable이 워크로드 요구량의 1.5배 이상임<br>취약: allocatable이 요구량 미만임 | 노드 용량 부족 시 Pod 스케줄링 실패가 발생하며, 클러스터 확장 지연으로 성능 저하가 초래됨 | ClusterAutoscaler를 활성화하고 노드 타입을 업그레이드하여 용량을 증설함 | * 설정방법<br>SCP 콘솔 Node Pool에서 Instance Type 변경<br>* References<br>- Cluster Autoscaler: https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler |
| Resource Quotas 설정 | kubectl get resourcequotas -A | 정상: 네임스페이스별 quotas가 CPU/Memory 상한 설정됨<br>취약: quotas가 없거나 무제한임 | quotas 미설정 시 단일 네임스페이스가 자원 독점으로 다른 워크로드 성능이 저하됨 | ResourceQuota 객체를 생성하여 네임스페이스별 hard limits를 적용함 | * 설정방법<br>kubectl create quota <name> --hard=cpu=10,memory=20Gi<br>* References<br>- Resource Quotas: https://kubernetes.io/docs/concepts/policy/resource-quotas/ |
| Overcommitment 비율 | kubectl describe nodes \| grep -E 'cpu\|memory' | 정상: overcommit 비율이 1.2 이하임<br>취약: overcommit 비율이 1.2 초과함 | 과도한 overcommit 시 실제 부하 시 eviction이 빈번하게 발생하며, 전체 클러스터 성능이 불안정해짐 | Kubelet --cpu-manager-policy=static으로 설정하고 overcommit을 조정함 | * 설정방법<br>Kubelet Config: cpuManagerPolicy: static<br>* References<br>- CPU Management Policies: https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/ |
| Affinity 규칙 최적화 | kubectl get pods -A -o yaml \| grep affinity | 정상: performance-critical Pod에 node affinity 설정됨<br>취약: affinity가 없거나 잘못됨 | affinity 미설정 시 Pod가 저성능 노드에 배포되어 latency가 증가하며, 성능 저하가 발생함 | Pod 스펙에 requiredDuringSchedulingIgnoredDuringExecution node affinity를 추가함 | * 설정방법<br>Pod YAML: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution...<br>* References<br>- Assign Pods to Nodes: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/ |
| Topology Spread Constraints | kubectl get deployments -A -o yaml \| grep topologySpreadConstraints | 정상: 워크로드에 maxSkew 1로 topology 설정됨<br>취약: constraints가 없음 | topology 미설정 시 Pod 편중으로 로드 불균형이 발생하며, 특정 영역 성능이 저하됨 | Deployment 스펙에 topologyKey: topology.kubernetes.io/zone 추가함 | * 설정방법<br>Deployment YAML: topologySpreadConstraints: - maxSkew: 1<br>* References<br>- Topology Spread Constraints: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/ |
| Container Runtime Tuning | kubectl get nodes -o jsonpath='{.items[*].status.nodeInfo.containerRuntimeVersion}' | 정상: containerd에 --cpu-shares 등의 tuning 적용됨<br>취약: 기본 runtime 설정임 | runtime 미튜닝 시 CPU/Memory 할당 불균형으로 컨테이너 성능이 저하됨 | Containerd config.toml에서 cpu cfs quota를 활성화함 | * 설정방법<br>/etc/containerd/config.toml: [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options] SystemdCgroup = true<br>* References<br>- Container Runtimes: https://kubernetes.io/docs/setup/production-environment/container-runtimes/ |
| Kubelet Garbage Collection | kubectl describe nodes \| grep garbage | 정상: --image-gc-high-threshold=85 --image-gc-low-threshold=80 설정됨<br>취약: 기본 threshold임 | GC 미최적화 시 디스크 용량 부족으로 Pod eviction이 발생하며, 노드 성능이 저하됨 | Kubelet 플래그를 수정하여 GC threshold를 조정함 | * 설정방법<br>Kubelet Flag: --image-gc-high-threshold=70<br>* References<br>- Configure Out of Resource Handling: https://kubernetes.io/docs/concepts/architecture/nodes/#out-of-resource |
| API Server Throughput | kubectl get --raw /metrics \| grep apiserver_request_duration_seconds | 정상: API 요청 latency가 100ms 미만임<br>취약: latency가 100ms 초과함 | API throughput 저하 시 배포/스케일링 지연이 발생하며, 클러스터 응답성이 저하됨 | API 서버 replicas를 증가하고 --max-requests-inflight를 tuning함 | * 설정방법<br>API Server Flag: --max-requests-inflight=400<br>* References<br>- kube-apiserver: https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/ |
| Etcd Performance | etcdctl check perf | 정상: Etcd write latency가 10ms 미만임<br>취약: latency가 10ms 초과함 | Etcd 성능 저하 시 클러스터 상태 업데이트 지연으로 전체 운영 성능이 저하됨 | Etcd를 SSD에 배포하고 --quota-backend-bytes를 증가함 | * 설정방법<br>Etcd Flag: --quota-backend-bytes=8589934592<br>* References<br>- Operating etcd clusters: https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/ |
| CNI Plugin 성능 | kubectl logs -n kube-system -l k8s-app=calico-node \| grep latency | 정상: CNI latency가 5ms 미만임<br>취약: latency가 5ms 초과함 | CNI 성능 저하 시 Pod 네트워크 설정 지연으로 배포 시간이 증가하며, throughput이 저하됨 | Calico BPF 모드를 활성화하여 네이티브 성능을 향상함 | * 설정방법<br>Calico YAML: bpf: enabled: true<br>* References<br>- Calico Documentation: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.BPF |
| Ingress Controller 성능 | kubectl logs -n ingress-nginx -l app=ingress-nginx \| grep request_time | 정상: Ingress request time이 50ms 미만임<br>취약: time이 50ms 초과함 | Ingress 성능 저하 시 외부 트래픽 처리 지연으로 사용자 응답 시간이 증가함 | NGINX Ingress replicas를 증가하고 worker_processes를 tuning함 | * 설정방법<br>Ingress ConfigMap: worker-processes: "4"<br>* References<br>- NGINX Ingress Controller: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/ |
| Service Mesh 성능 (Istio 등) | istioctl proxy-status | 정상: Envoy latency가 10ms 미만임<br>취약: latency가 10ms 초과함 | Mesh 성능 저하 시 서비스 간 호출 지연으로 전체 애플리케이션 성능이 저하됨 | Istio sidecar 리소스를 최적화하고 mTLS를 selective로 설정함 | * 설정방법<br>Istio YAML: trafficManagement: components: proxy: resources: requests: cpu: 100m<br>* References<br>- Istio Performance and Scalability: https://istio.io/latest/docs/ops/deployment/performance-and-scalability/ |
| Monitoring Metrics 수집 주기 | kubectl get configmap -n monitoring prometheus-config | 정상: scrape_interval이 15s 이하임<br>취약: interval이 15s 초과함 | metrics 수집 지연 시 성능 이상을 늦게 감지하여 대응 지연이 발생하며, 용량 계획이 부정확해짐 | Prometheus config에서 scrape_interval을 10s로 조정함 | * 설정방법<br>ConfigMap YAML: scrape_interval: 10s<br>* References<br>- Prometheus Configuration: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ |
| Scheduling Bottlenecks | kubectl logs -n kube-system -l component=scheduler \| grep queue | 정상: Pending queue가 10 미만임<br>취약: queue가 10 초과함 | 스케줄링 병목 시 Pod 대기 시간이 증가하며, 워크로드 배포 성능이 저하됨 | Scheduler profile을 high-throughput으로 설정하고 plugins를 최적화함 | * 설정방법<br>Scheduler Config: kind: KubeSchedulerConfiguration, profiles: - schedulerName: default-scheduler<br>* References<br>- kube-scheduler: https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/ |
| Eviction Thresholds | kubectl describe nodes \| grep eviction | 정상: --eviction-hard=memory.available<10% 설정됨<br>취약: 기본 threshold임 | eviction threshold 미최적화 시 불필요한 Pod eviction으로 성능 불안정성이 발생함 | Kubelet --eviction-hard를 조정하여 예방 eviction을 구현함 | * 설정방법<br>Kubelet Flag: --eviction-hard=memory.available<5%<br>* References<br>- Node-pressure Eviction: https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/ |
| Huge Pages 사용 | kubectl get nodes -o yaml \| grep hugepages | 정상: 메모리 집약적 Pod에 hugepages 할당됨<br>취약: hugepages 미사용임 | hugepages 미사용 시 TLB miss 증가로 메모리 액세스 latency가 높아지며, 성능 저하됨 | 노드에 hugepages를 예약하고 Pod에 hugepages requests를 추가함 | * 설정방법<br>Pod YAML: resources: requests: hugepages-2Mi: 100Mi<br>* References<br>- Huge Pages: https://kubernetes.io/docs/tasks/manage-hugepages/scheduling-hugepages/ |
| CPU Manager Policy | kubectl get kubeletconfigs | 정상: --cpu-manager-policy=static 설정됨<br>취약: 기본 policy임 | static 미설정 시 CPU pinning 부족으로 latency-sensitive 앱 성능이 저하됨 | Kubelet config에서 cpuManagerPolicy를 static으로 변경함 | * 설정방법<br>KubeletConfig YAML: cpuManagerPolicy: static<br>* References<br>- CPU Management Policies: https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/ |
| Network Policy Overhead | kubectl get networkpolicies -A \| kubectl describe pods -A \| grep policy | 정상: NetworkPolicy가 최소화되어 오버헤드 적음<br>취약: 과도한 policy로 latency 증가함 | policy 오버헤드 시 패킷 처리 지연으로 네트워크 성능이 저하됨 | Calico NetworkPolicy를 selective로 최적화하고 eBPF를 사용함 | * 설정방법<br>NetworkPolicy YAML: egress: - to: - podSelector: matchLabels: role: db<br>* References<br>- Network Policies: https://kubernetes.io/docs/concepts/services-networking/network-policies/ |

## 운영

| 점검내용 | 점검방법 | 점검기준 | 취약시 문제점 | 개선방안 | 참고 |
|----------|----------|----------|----------------|----------|------|
| 감사 로그 활성화 | kubectl get configmap -n kube-system kube-apiserver -o yaml \| grep audit | 정상: --audit-policy-file이 설정되고 로그 볼륨이 마운트됨<br>취약: 감사 로그 설정이 없음 | 감사 로그 미활성화 시 클러스터 활동 추적이 불가능하며, 보안 사건 발생 시 원인 분석이 어려워져 규정 준수 위반과 침해 대응 지연이 발생함 | SKE API 서버에 Audit Policy를 적용하고 로그를 외부 시스템(예: ELK)으로 전송하여 장기 보관함 | * 설정방법<br>API Server Flag: --audit-policy-file=/etc/kubernetes/audit-policy.yaml, --audit-log-path=/var/log/audit.log<br>* References<br>- Auditing: https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/ |
| 클러스터 업그레이드 정책 | SCP 콘솔에서 클러스터 버전 히스토리 확인 또는 kubectl get cm -n kube-system kubeadm-config | 정상: 정기 업그레이드 스케줄이 설정되고 최근 3개월 내 업그레이드 이력 있음<br>취약: 업그레이드 이력이 6개월 이상 없음 | 오래된 버전 사용 시 알려진 버그와 취약점이 노출되어 안정성 저하와 보안 침해 위험이 증가하며, 새로운 기능 미지원으로 운영 효율이 떨어짐 | SKE 콘솔에서 자동 업그레이드 옵션을 활성화하고 매 분기 클러스터를 최신 안정 버전으로 업그레이드함 | * 설정방법<br>SCP 콘솔 클러스터 업그레이드 메뉴에서 Schedule 설정<br>* References<br>- Upgrading kubeadm clusters: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/ |
| 백업 및 복구 절차 | kubectl get cronjobs -A \| grep backup 또는 velero get backups | 정상: Velero 등으로 일일 백업 CronJob이 실행 중임<br>취약: 백업 Job이 없거나 실패 이력 있음 | 백업 미설정 시 데이터 손실 발생으로 복구가 불가능하며, 장애 시 비즈니스 중단 시간이 길어져 비용 증가함 | SKE에 Velero를 설치하고 Restic을 사용한 PV 백업 스케줄을 설정하며 정기 복구 테스트를 수행함 | * 설정방법<br>velero install --provider aws --bucket <bucket> --backup-location-config region=ap-northeast-2<br>* References<br>- Velero Documentation: https://velero.io/docs/ |
| 모니터링 시스템 배포 | kubectl get deployments -n monitoring \| grep prometheus | 정상: Prometheus와 Grafana가 배포되어 메트릭 수집 중임<br>취약: 모니터링 네임스페이스나 Deployment가 없음 | 모니터링 미설정 시 리소스 사용 이상을 감지하지 못하여 장애 예방이 어려우며, 용량 계획 오류로 비용 낭비가 발생함 | SKE에 Prometheus Operator를 Helm으로 설치하고 Node Exporter, Kube State Metrics를 추가하여 종합 모니터링을 구현함 | * 설정방법<br>helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring<br>* References<br>- Prometheus Kubernetes Monitoring: https://prometheus.io/docs/prometheus/latest/federation/ |
| 알림 및 경고 설정 | kubectl get prometheusrules -n monitoring | 정상: Alertmanager가 배포되어 이메일/Slack 알림 규칙이 설정됨<br>취약: Alert 규칙이 없거나 비활성화됨 | 알림 미설정 시 장애 발생을 즉시 인지하지 못하여 대응 지연이 발생하며, SLA 위반과 사용자 불만이 증가함 | PrometheusRule 객체를 생성하여 CPUHigh, MemoryLow 등의 알림을 설정하고 Alertmanager config에 receiver를 추가함 | * 설정방법<br>Alertmanager YAML: route: receiver: email<br>* References<br>- Alerting: https://prometheus.io/docs/alerting/latest/overview/ |
| 사용자 접근 로그 관리 | kubectl logs -n kube-system -l component=apiserver \| grep user | 정상: API 호출 로그에 사용자 식별자가 기록됨<br>취약: 사용자 로그가 익명 또는 누락됨 | 접근 로그 미관리 시 무단 접근 추적이 불가능하며, 감사 요구사항 미충족으로 컴플라이언스 문제가 발생함 | RBAC와 함께 Webhook 인증을 활성화하고 Fluentd로 로그를 중앙 수집하여 사용자별 액세스 기록을 보관함 | * 설정방법<br>Fluentd DaemonSet: kubectl apply -f fluentd.yaml<br>* References<br>- Access Control Overview: https://kubernetes.io/docs/reference/access-authn-authz/ |
| 인증서 만료 관리 | kubectl get secrets -n kube-system \| grep cert | 정상: 모든 인증서 만료일이 6개월 이상 남음<br>취약: 인증서 만료일이 1개월 이내임 | 인증서 만료 시 API 서버 접근 불가로 클러스터 다운이 발생하며, 복구 과정에서 운영 중단이 길어짐 | Cert-manager를 설치하고 자동 갱신 Issuer를 설정하여 Let's Encrypt 등으로 인증서를 관리함 | * 설정방법<br>helm install cert-manager jetstack/cert-manager --set installCRDs=true<br>* References<br>- Certificate Rotation: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/ |
| 이미지 청소 정책 | kubectl describe nodes \| grep image-gc | 정상: --image-gc-high-threshold=80 --image-gc-low-threshold=70 설정됨<br>취약: 기본 threshold 또는 미설정임 | 이미지 청소 미설정 시 디스크 용량 부족으로 Pod eviction이 발생하며, 노드 불안정성과 운영 비용 증가함 | Kubelet config에서 image GC threshold를 조정하고 cronjob으로 정기 이미지 prune을 실행함 | * 설정방법<br>kubectl create cronjob image-prune --schedule="0 0 * * *" --image=busybox --command="crictl rmi --prune"<br>* References<br>- Image Garbage Collection: https://kubernetes.io/docs/concepts/architecture/garbage-collection/#container-image-garbage-collection |
| 노드 유지보수 스케줄 | SCP 콘솔에서 노드 히스토리 확인 또는 kubectl get events -A \| grep maintenance | 정상: 월간 노드 드레인 및 패치 스케줄이 설정됨<br>취약: 유지보수 이벤트 이력이 없음 | 유지보수 미실시 시 누적된 패치 미적용으로 보안 취약점이 노출되며, 노드 장애 빈도가 증가함 | SKE 노드풀에 자동 패치 옵션을 활성화하고 PDB를 준수한 드레인 스크립트를 cron으로 실행함 | * 설정방법<br>kubectl drain <node> --ignore-daemonsets --delete-emptydir-data<br>* References<br>- Safely Drain a Node: https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/ |
| 네임스페이스 할당 관리 | kubectl get namespaces \| wc -l | 정상: 네임스페이스 수가 워크로드 수에 비례하여 50개 미만임<br>취약: 네임스페이스 수가 100개 초과함 | 과도한 네임스페이스 시 관리 복잡도가 증가하며, 리소스 분산으로 성능 모니터링이 어려워짐 | 네임스페이스 생성 정책을 정의하고 Admission Webhook으로 제한하며, 불필요 네임스페이스를 정기 삭제함 | * 설정방법<br>kubectl delete ns <ns-name> --force<br>* References<br>- Namespaces: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/ |
| 헬름 차트 버전 관리 | helm ls -A \| grep VERSION | 정상: 모든 차트가 최신 버전으로 업데이트됨<br>취약: deprecated 차트 사용 중임 | 오래된 차트 사용 시 버그 노출과 호환성 문제로 배포 실패가 발생하며, 운영 효율이 저하됨 | Helm repo를 업데이트하고 helm upgrade --install로 최신 버전을 적용하며, values.yaml을 버전 관리함 | * 설정방법<br>helm repo update; helm upgrade <release> <chart><br>* References<br>- Helm Charts: https://helm.sh/docs/topics/charts/ |
| 보안 스캔 정기 실행 | kubectl get cronjobs -A \| grep scan | 정상: Trivy 또는 Clair로 주간 이미지 스캔 Job이 실행 중임<br>취약: 스캔 Job이 없음 | 보안 스캔 미실시 시 취약 이미지 배포로 런타임 공격이 발생하며, 컴플라이언스 위반이 초래됨 | Trivy Operator를 설치하고 CronJob으로 이미지 레지스트리를 스캔하며, 고위험 취약점 시 배포 차단함 | * 설정방법<br>kubectl apply -f trivy-operator.yaml<br>* References<br>- Trivy Documentation: https://aquasecurity.github.io/trivy/latest/ |
| 비용 모니터링 설정 | kubectl get deployments -n monitoring \| grep kubecost | 정상: Kubecost 또는 유사 툴이 배포되어 비용 메트릭 수집 중임<br>취약: 비용 모니터링이 없음 | 비용 미모니터링 시 과도한 리소스 사용으로 청구액 증가하며, 예산 초과로 운영 제한이 발생함 | Kubecost를 Helm으로 설치하고 Grafana 대시보드에 비용 알림을 설정함 | * 설정방법<br>helm install kubecost cost-analyzer --repo https://kubecost.github.io/cost-analyzer/<br>* References<br>- Kubecost Documentation: https://www.kubecost.com/kubernetes-cost-monitoring/ |
| 스케줄링 정책 관리 | kubectl get configmap -n kube-system scheduler-config | 정상: Custom scheduler profile이 설정되어 priorityClass 사용됨<br>취약: 기본 scheduler만 사용됨 | 스케줄링 미관리 시 우선순위 낮은 Pod가 지연되며, critical 워크로드 성능이 저하됨 | Kube-scheduler config에 plugins를 추가하고 PriorityClass를 워크로드에 할당함 | * 설정방법<br>kubectl edit cm kube-scheduler-config -n kube-system<br>* References<br>- Scheduling Framework: https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/ |
| 네트워크 정책 업데이트 | kubectl get networkpolicies -A \| grep updated | 정상: 정책에 최근 업데이트 타임스탬프 있음<br>취약: 정책 변경 이력이 3개월 이상 없음 | 정책 미업데이트 시 새로운 워크로드에 맞지 않아 통신 오류가 발생하며, 보안 홀이 노출됨 | GitOps(ArgoCD)로 네트워크 정책을 관리하고 변경 시 자동 적용함 | * 설정방법<br>kubectl apply -f netpol.yaml<br>* References<br>- Network Policies: https://kubernetes.io/docs/concepts/services-networking/network-policies/ |
| 스토리지 용량 모니터링 | kubectl get pv -A \| grep capacity | 정상: PV 사용률이 80% 미만임<br>취약: PV 사용률이 80% 초과함 | 스토리지 부족 시 Pod 마운트 실패로 애플리케이션 다운이 발생하며, 데이터 손실 위험이 증가함 | StorageClass에 자동 프로비저닝을 설정하고 Prometheus로 용량 알림을 구현함 | * 설정방법<br>StorageClass YAML: allowVolumeExpansion: true<br>* References<br>- Dynamic Volume Provisioning: https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/ |
| API 서버 성능 튜닝 | kubectl describe pod -n kube-system kube-apiserver \| grep flags | 정상: --max-requests-inflight=400 등 튜닝됨<br>취약: 기본 플래그만 사용됨 | API 튜닝 미적용 시 고부하 시 요청 지연으로 운영 명령어가 실패하며, 클러스터 응답성이 저하됨 | API 서버 플래그를 수정하고 리소스 limits를 증가시켜 throughput을 최적화함 | * 설정방법<br>API Server YAML: --max-mutating-requests-inflight=200<br>* References<br>- kube-apiserver: https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/ |
| Etcd 백업 관리 | etcdctl snapshot status /backup.db | 정상: 주간 Etcd 스냅샷이 생성되고 유효함<br>취약: 스냅샷이 없거나 손상됨 | Etcd 백업 미관리 시 클러스터 메타데이터 손실로 전체 복구가 불가능하며, 재구성 비용이 증가함 | CronJob으로 etcdctl snapshot save를 실행하고 S3에 저장하며 정기 restore 테스트함 | * 설정방법<br>etcdctl snapshot save /backup.db --endpoints=https://127.0.0.1:2379<br>* References<br>- Backing up an etcd cluster: https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster |
| 클러스터 스케일링 정책 | kubectl get clusterautoscaler/status | 정상: Autoscaler가 활성화되어 scale-up/down 이벤트 있음<br>취약: 스케일링 이벤트 이력 없음 | 스케일링 미설정 시 피크 타임 과부하로 성능 저하가 발생하며, 아이들 타임 자원 낭비함 | ClusterAutoscaler config에 min/max 노드를 설정하고 metrics-server와 연동함 | * 설정방법<br>kubectl apply -f cluster-autoscaler.yaml<br>* References<br>- Cluster Autoscaler FAQ: https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md |
| 이벤트 로그 보관 기간 | kubectl get events -A --sort-by=.metadata.creationTimestamp | 정상: 이벤트가 1시간 이상 보관됨 (evicted 이벤트 없음)<br>취약: 이벤트가 1시간 미만으로 evicted됨 | 이벤트 미보관 시 과거 장애 분석이 어려우며, 트러블슈팅 효율이 저하됨 | API 서버 --event-ttl=24h로 설정하고 외부 로그 시스템으로 export함 | * 설정방법<br>API Server Flag: --event-ttl=1h0m0s<br>* References<br>- Events: https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/event-v1/ |
| 커스텀 메트릭스 수집 | kubectl get apiservices \| grep metrics | 정상: custom.metrics.k8s.io가 등록됨<br>취약: 커스텀 메트릭스 API가 없음 | 커스텀 메트릭스 미수집 시 애플리케이션 특정 지표 기반 스케일링이 불가능하며, 성능 최적화가 제한됨 | Prometheus Adapter를 설치하고 HPA에 customMetrics를 추가함 | * 설정방법<br>kubectl apply -f prometheus-adapter.yaml<br>* References<br>- Custom Metrics: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics |
| 롤링 업데이트 전략 관리 | kubectl get deployments -A -o yaml \| grep strategy | 정상: maxUnavailable=0으로 zero-downtime 설정됨<br>취약: Recreate 전략 사용됨 | 취약 전략 시 업데이트 중 다운타임 발생으로 서비스 중단이 일어나며, 사용자 영향이 큼 | Deployment 스펙에 rollingUpdate를 설정하고 canary 배포를 도입함 | * 설정방법<br>Deployment YAML: strategy: rollingUpdate: maxUnavailable: 0<br>* References<br>- Rolling Update Deployment: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-update-deployment |
| 다운타임 최소화 계획 | kubectl get pdb -A | 정상: 모든 critical 워크로드에 PDB 설정됨<br>취약: PDB가 없음 | PDB 미설정 시 유지보수 중 서비스 중단이 발생하며, HA가 깨짐 | PodDisruptionBudget을 생성하고 minAvailable을 50%로 설정함 | * 설정방법<br>kubectl create pdb <name> --selector=app=foo --min-available=1<br>* References<br>- Disruptions: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/ |
| 재해 복구(DR) 계획 | SCP 콘솔에서 DR 설정 확인 또는 velero get restores | 정상: Multi-region 백업과 restore 테스트 이력 있음<br>취약: DR 계획이 없음 | DR 미준비 시 지역 장애로 전체 클러스터 손실이 발생하며, 복구 시간이 길어 비즈니스 손실이 큼 | Velero로 cross-region 백업을 설정하고 정기 DR 드릴을 수행함 | * 설정방법<br>velero backup-location create dr --provider aws --bucket <dr-bucket> --config region=us-west-2<br>* References<br>- Disaster Recovery: https://velero.io/docs/v1.6/disaster-case/ |
| 운영 문서화 및 지식 공유 | Git repo 또는 Confluence에서 SKE 문서 확인 | 정상: SOP(Standard Operating Procedure) 문서가 업데이트됨<br>취약: 문서가 없거나 오래됨 | 문서 미관리 시 팀원 간 지식 불균형으로 운영 오류가 증가하며, 신규 멤버 온보딩이 지연됨 | Markdown 또는 Wiki로 운영 매뉴얼을 작성하고 Git으로 버전 관리하며, 정기 리뷰를 실시함 | * 설정방법<br>Git repo에 README.md 작성 및 push<br>* References<br>- Kubernetes Documentation Style Guide: https://kubernetes.io/docs/contribute/style/style-guide/ |
