---
title: "Broadcast UDP 패킷 수신과 net.ipv4.conf.all.rp_filter 값의 상관관계"
date: 2025-08-27
tags: [broadcast, udp, rp_filter, network, linux, cloud]
categories: [Issues, Network]
---

### 문제 원인 분석

사용자의 시나리오를 요약하면: L2B BMEdge를 우회하기 위해 VM에 추가 vNIC(virtual Network Interface Card)을 생성하여 증권 시세 정보를 브로드캐스트(UDP 기반)로 직접 수신하려 했으나, 처음에는 데이터가 수신되지 않았습니다. 이를 해결하기 위해 `net.ipv4.conf.all.rp_filter=0`으로 변경한 후 수신이 시작되었지만, 이전의 유실률(0.05% 수준)이 0.2~0.3%로 증가했습니다. 이는 네트워크 스택의 동작 변화로 인한 부작용으로 보입니다. 아래에서 사실 기반으로 자세히 설명하겠습니다. (내 분석은 Linux 커널 문서와 관련 포럼/스택오버플로우 등의 신뢰할 수 있는 소스를 기반으로 검증했습니다.)

#### **rp_filter의 역할과 값 설명**
`net.ipv4.conf.all.rp_filter`는 Linux 커널의 Reverse Path Filtering(RPF) 설정으로, 들어오는 패킷의 소스 IP 주소가 올바른 인터페이스(라우팅 테이블 기준)로부터 왔는지 검사합니다. 이는 IP 스푸핑(IP 주소 위조) 공격을 방지하기 위한 보안 기능입니다. 값은 다음과 같습니다:

- **0 (비활성화)**: 소스 검증을 전혀 하지 않습니다. 모든 패킷을 받아들이므로, 비대칭 라우팅(asymmetric routing, 패킷이 들어온 경로와 나가는 경로가 다른 경우) 환경에서 유용합니다. 하지만 불필요하거나 위조된 패킷까지 받아들여 시스템 부하를 증가시킬 수 있습니다.
- **1 (Strict 모드)**: 들어온 인터페이스가 소스 IP의 최적 reverse path(역경로)가 아니면 패킷을 드롭합니다. RFC3704 Strict Reverse Path에 기반하며, 엄격한 환경(예: 단일 NIC)에서 보안을 강화하지만, 멀티 NIC나 브로드캐스트 환경에서 패킷 드롭이 발생할 수 있습니다.
- **2 (Loose 모드)**: 소스 IP가 시스템의 어떤 인터페이스에서도 도달 가능하지 않으면 드롭합니다. Strict보다 유연하지만 여전히 일부 검증을 합니다.

기본값은 0이지만, 많은 Linux 배포본(Ubuntu 등)에서 보안 이유로 1로 설정됩니다. 사용자의 경우, 초기 상태(아마 1 또는 2)에서 브로드캐스트 패킷이 드롭되어 수신되지 않았고, 0으로 변경 후 수신이 시작된 것은 이 기능 때문입니다. 특히 UDP 브로드캐스트/멀티캐스트는 소스 IP가 브로드캐스트 주소(예: 255.255.255.255)라서 RPF 검사에서 자주 실패합니다.

#### **rp_filter=0 변경 후 유실률 증가 원인**
이 변경으로 유실률이 증가한 이유는 다음과 같습니다. (Linux 커널 문서와 서버포럼 사례를 기반으로 한 사실입니다.)

1. **불필요한 패킷 증가로 인한 시스템 부하**:
   - rp_filter=0은 모든 패킷을 무조건 받아들이므로, 원래 드롭되었을 위조/중복/루프 패킷(예: 네트워크 루프나 다른 NIC에서 유입된 패킷)이 VM 내부로 들어옵니다.
   - 특히 multi-NIC 환경(추가 vNIC 생성)에서, 브로드캐스트 패킷이 여러 인터페이스로 중복 수신될 수 있습니다. 이는 UDP 수신 큐(queue)에 과부하를 주고, 버퍼 오버플로우를 유발합니다.
   - 결과: UDP 패킷 처리 지연이나 드롭이 증가. 이전 분석에서 봤듯이 UdpRcvbufErrors(UDP receive buffer errors)가 주요 유실 원인이었는데, 이 설정으로 오류가 더 많아질 수 있습니다.
   - 검증 사례: Linux 커널 문서와 Stack Overflow에서, rp_filter=0은 asymmetric routing에서 수신을 돕지만, multi-NIC에서 "unexpected traffic"으로 인해 패킷 손실이 증가할 수 있다고 언급됩니다. (예: 멀티캐스트 패킷이 인터페이스 간 충돌.)

2. **보안 취약점과 간접적 영향**:
   - 0 설정은 IP 스푸핑을 허용하므로, DDoS나 스푸핑 공격에 취약해집니다. 하지만 유실률 증가와 직접 관련은 적고, 오히려 트래픽 양 증가가 문제입니다.
   - UDP 브로드캐스트처럼 대량 트래픽(증권 시세 정보)에서, 추가 패킷이 CPU/메모리 리소스를 소모하여 애플리케이션 처리 속도가 느려집니다. 이전 데이터에서 애플리케이션 단 유실(0.2% 수준)이 버퍼 오류와 연관되었듯이, 이 변화가 버퍼 압박을 키웁니다.

3. **multi-NIC VM 환경의 특성**:
   - VM에 vNIC을 추가하면 라우팅 테이블이 복잡해집니다. rp_filter=1/2라면 잘못된 인터페이스의 패킷을 드롭해 깨끗한 트래픽을 유지하지만, 0으로는 모든 인터페이스가 "잡음"을 받아들입니다.
   - ESXi 하이퍼바이저 환경에서 vNIC 간 트래픽 분산이 불균형해지면, 하나의 vNIC이 과부하되어 유실이 증가합니다.
   - 이전 유실률 0.05% (L2B BMEdge 경유 시)는 필터링 덕분에 깨끗한 트래픽이었을 가능성이 큽니다.

요약: rp_filter=0은 수신을 가능하게 했지만, "더러운" 트래픽 증가로 UDP 버퍼/CPU 부하가 높아져 유실률이 0.2~0.3%로 악화되었습니다. 이는 보안-성능 트레이드오프의 전형적 예입니다.

#### **대안 제안**
- **rp_filter=2 (Loose 모드)로 변경**: Strict(1)보다 유연하며, 브로드캐스트 수신을 유지하면서 불필요 패킷을 일부 필터링합니다. 명령어: `sysctl -w net.ipv4.conf.all.rp_filter=2`. 각 인터페이스별로도 설정 가능(예: `net.ipv4.conf.eth0.rp_filter=2`).
- **라우팅 테이블 최적화**: 추가 vNIC의 default gateway를 확인하고, 브로드캐스트 트래픽을 전용 vNIC으로만 라우팅하세요. (ip route show 확인)
- **버퍼 크기 재조정**: 이전에 32MB로 늘렸으나, 트래픽 증가로 64MB 이상 시도. (net.core.rmem_max=67108864)
- **테스트**: 변경 후 07:55~09:55 구간 유실률 측정.

#### **VM 단에서 수집해야 할 데이터**
유실 원인을 더 정확히 파악하려면, 변경 전/후 비교를 위해 아래 데이터를 수집하세요. (이전 문서처럼 netstat, ethtool 등 활용) 이해 쉽게 단계별로 설명합니다.

1. **rp_filter 설정 확인** (변경 영향 검증):
   - 명령어: `sysctl -a | grep rp_filter` 또는 `cat /proc/sys/net/ipv4/conf/all/rp_filter`
   - 왜? 각 인터페이스(기존/추가 vNIC)의 값이 0인지, all이 오버라이드하는지 확인. multi-NIC에서 인터페이스별 차이 분석.

2. **네트워크 통계 (UDP 오류/드롭)**:
   - 명령어: `netstat -s | grep Udp` 또는 `cat /proc/net/snmp | grep Udp`
   - 수집 항목: UdpInDatagrams (수신 패킷), UdpInErrors (오류), UdpRcvbufErrors (버퍼 오버플로우), UdpNoPorts (포트 없음 드롭).
   - 왜? rp_filter=0 후 UdpInErrors나 UdpRcvbufErrors 증가 여부 확인. 이전 데이터처럼 버퍼 오류가 주요 원인일 수 있음.

3. **NIC 수준 통계 (드라이버 드롭)**:
   - 명령어: `ethtool -S ethX` (ethX는 추가 vNIC 이름, 예: eth1)
   - 수집 항목: rx_packets (수신 패킷), rx_errors, rx_dropped, rx_over_errors (버퍼 오버플로우), rx_broadcast_packets (브로드캐스트 수신).
   - 왜? vNIC별 드롭이 증가했는지, 브로드캐스트 패킷 양이 폭증했는지 분석. multi-NIC에서 중복 수신 확인.

4. **시스템 리소스 사용률 (CPU/메모리 부하)**:
   - 명령어: `sar -u 1 10` (CPU), `sar -n DEV 1 10` (네트워크 I/O), `vmstat 1 10` (메모리/스왑), `top` 또는 `mpstat -P ALL` (vCore별 CPU).
   - 수집 항목: %user/%system (네트워크 처리 CPU), rxpck/s (수신 패킷 속도), drop/s (드롭 속도).
   - 왜? rp_filter=0으로 패킷 양 증가 시 CPU가 병목이 될 수 있음. vCore 24개지만, 트래픽 피크 시 특정 코어 과부하.

5. **라우팅 및 인터페이스 정보**:
   - 명령어: `ip route show`, `ip addr show`, `ip maddr show` (멀티캐스트 주소).
   - 왜? 추가 vNIC의 IP/게이트웨이가 올바른지, 브로드캐스트가 어떤 인터페이스로 유입되는지 확인. 루프나 중복 라우트 분석.

6. **로그 및 커널 오류**:
   - 명령어: `dmesg | grep -i net` 또는 `journalctl -u networking` (systemd 로그).
   - 왜? 커널에서 rp_filter 관련 드롭 로그나 버퍼 오류가 기록될 수 있음.

**수집 팁**: 
- cronjob으로 매 1분마다 위 명령어 실행 결과를 로그 파일에 저장 (예: `/var/log/net-stats.log`).
- 변경 전/후 delta 계산: `watch -n 60 netstat -s`처럼 실시간 모니터링.
- 도구: sar (sysstat 패키지), nstat (net-tools) 설치 필요.

---
### rp_filter 설정이 브로드캐스트 수신에 미치는 영향

사용자의 질문은, Linux 시스템에서 `net.ipv4.conf.all.rp_filter`를 0으로 변경해야만 브로드캐스트 패킷 수신이 가능해진 이유에 관한 것입니다. 이는 Linux 커널의 네트워크 보안 기능인 Reverse Path Filtering(RPF)의 동작 원리에 기인합니다. 아래에서 사실 기반으로 자세히 설명하겠습니다. 설명은 Linux 커널 공식 문서와 관련 커뮤니티 사례(Stack Exchange, Reddit 등)를 바탕으로 검증했습니다. 이해를 돕기 위해 단계적으로 풀어서 설명하겠습니다.

#### 1. **rp_filter의 기본 역할**
rp_filter는 Linux 커널의 sysctl 설정으로, 들어오는 IP 패킷의 소스 주소(source IP)가 올바른 경로로 들어왔는지 검증하는 기능입니다. 이는 IP 스푸핑(spoofing, IP 주소 위조) 공격을 방지하기 위한 보안 메커니즘으로, RFC3704 문서에 기반합니다. 간단히 말해, 패킷이 도착한 인터페이스(NIC)가 해당 소스 IP로 패킷을 되돌려 보낼 수 있는 "최적의 역경로(reverse path)"인지 확인합니다.

- **왜 이런 검사가 필요한가?** 네트워크 공격자가 가짜 IP로 패킷을 보내 DDoS나 다른 공격을 시도할 수 있습니다. rp_filter는 이런 패킷을 미리 드롭(drop)하여 시스템을 보호합니다.
- **값에 따른 동작** (Linux 커널 문서에 따라):
  - **0**: 소스 검증을 완전히 비활성화합니다. 모든 패킷을 받아들입니다. 보안이 약해지지만, 특수한 네트워크 환경에서 유용합니다.
  - **1 (Strict 모드)**: 엄격한 검사. 패킷이 도착한 인터페이스가 FIB(Forwarding Information Base, 라우팅 테이블)에서 소스 IP의 "최적 역경로"가 아니면 드롭합니다. 대부분의 배포본에서 기본값입니다.
  - **2 (Loose 모드)**: 느슨한 검사. 소스 IP가 시스템의 "어떤 인터페이스"에서도 도달 가능하지 않으면 드롭합니다. Strict보다 유연합니다.

기본적으로 많은 Linux 시스템(예: Ubuntu, RHEL)에서 rp_filter가 1 또는 2로 설정되어 있어, 보안이 강화된 상태입니다.

#### 2. **브로드캐스트 패킷이 rp_filter에 의해 드롭되는 이유**
브로드캐스트 패킷(예: UDP 브로드캐스트)은 네트워크상 모든 호스트에 보내는 특수 패킷으로, 소스 IP가 일반적인 유니캐스트 패킷과 다릅니다. 예를 들어:
- 소스 IP가 종종 0.0.0.0(알 수 없음) 또는 255.255.255.255(브로드캐스트 주소)처럼 특이합니다.
- 목적지 IP도 브로드캐스트 주소(예: 192.168.255.255)입니다.

rp_filter가 1(Strict) 또는 2(Loose)로 설정되어 있으면:
- **Strict 모드(1)에서**: 패킷의 소스 IP가 도착한 인터페이스의 "최적 역경로"가 아니라고 판단되면 드롭합니다. 브로드캐스트 패킷의 소스 IP(0.0.0.0 등)는 라우팅 테이블에서 "정상적인" 경로로 보이지 않아 검사에 실패합니다. 이는 asymmetric routing(들어오는 경로와 나가는 경로가 다른 경우)에서 특히 발생합니다.
- **Loose 모드(2)에서**: 소스 IP가 시스템의 "어떤 인터페이스"에서도 도달 가능하지 않으면 드롭합니다. 브로드캐스트 소스 IP가 "도달 불가능"으로 간주되면 마찬가지로 드롭될 수 있습니다.
- 결과: 사용자가 추가 vNIC을 생성하고 브로드캐스트를 수신하려 할 때, rp_filter가 활성화되어 있으면 패킷이 도착해도 커널에서 드롭되어 애플리케이션이 받지 못합니다. 이는 "갑자기" 수신이 안 되는 듯 보이지만, 실제로는 보안 기능 때문입니다.

멀티캐스트 패킷(브로드캐스트와 유사)에서도 비슷한 문제가 발생하며, 커뮤니티 사례에서 rp_filter를 0으로 설정해야 수신이 된다고 보고됩니다. 예를 들어, 임베디드 장치나 가상 네트워크(VM)에서 소스 IP가 다른 서브넷에 속하면 드롭됩니다.

#### 3. **왜 rp_filter=0으로 변경하면 수신이 가능해지는가?**
- rp_filter를 0으로 설정하면 소스 검증을 완전히 끄기 때문에, 브로드캐스트 패킷의 특이한 소스 IP를 무시하고 모든 패킷을 받아들입니다.
- 이는 특히 multi-NIC 환경(추가 vNIC 생성)이나 가상화(ESXi VM)에서 유용합니다. 하지만 부작용으로 불필요한 패킷(위조나 중복)이 유입되어 시스템 부하가 증가할 수 있습니다. 이전 대화에서 언급된 유실률 증가(0.05% → 0.2~0.3%)도 이 때문에 발생할 가능성이 큽니다 – 더 많은 "잡음" 패킷이 UDP 버퍼를 압박합니다.

#### 4. **주의점과 대안**
- **보안 위험**: rp_filter=0은 IP 스푸핑 취약점을 열어두므로, 프로덕션 환경에서 피하세요. 대신 Loose 모드(2)를 시도해보세요 – Strict만큼 엄격하지 않으면서 브로드캐스트를 허용할 수 있습니다.
- **설정 방법**: `sysctl -w net.ipv4.conf.all.rp_filter=0`으로 변경. 인터페이스별로도 가능(예: `net.ipv4.conf.eth1.rp_filter=0`).
- **검증 팁**: `tcpdump`나 `netstat -s`로 패킷 드롭을 확인하세요. 만약 asymmetric routing이 원인이라면, 라우팅 테이블(`ip route show`)을 조정하는 게 근본 해결입니다.

---
### 1. **L2B BMEdge 제거가 브로드캐스트 수신에 미치는 영향**
- **L2B BMEdge의 역할**: L2B BMEdge(Layer 2 Bridge Bare Metal Edge)는 네트워크 브리지나 에지 장치로, 패킷을 필터링하거나 라우팅 없이 직접 전달하는 역할을 합니다. 이전 구성에서 이 장치는 브로드캐스트 패킷(예: 증권 시세 정보)을 VM으로 안전하게 전달하는 "중개자" 역할을 했을 수 있습니다. 이를 제거하면 패킷 경로가 직접적이 되지만, 네트워크 토폴로지가 바뀌어 asymmetric routing(패킷이 들어오는 경로와 나가는 경로가 다른 상황)이 발생할 수 있습니다.
- **가능한 문제**: 
  - 브로드캐스트 패킷의 소스 IP(예: 0.0.0.0 또는 255.255.255.255)는 "비정상적"으로 보일 수 있어, VM의 Linux 커널이 이를 검증 과정에서 드롭합니다. L2B BMEdge가 있었을 때는 이 장치가 패킷을 "정상화"하거나 필터링 없이 전달해 문제가 없었지만, 제거 후 직접 수신 시 커널의 보안 기능(rp_filter)이 작동해 패킷이 버려질 수 있습니다.
  - ESXi 하이퍼바이저 환경에서 vSwitch(virtual switch)가 브로드캐스트를 처리하지만, L2B 제거로 인해 서브넷 간 또는 외부 네트워크로부터의 패킷이 예상치 못한 경로로 도착하면 드롭될 위험이 있습니다. 실제 사례에서 다중 인터페이스 환경에서 멀티캐스트/브로드캐스트 패킷이 이런 이유로 손실된다고 보고됩니다.

결과적으로, L2B BMEdge 제거는 브로드캐스트 패킷이 VM에 도달하더라도 "유효하지 않다"고 판단되어 수신되지 않을 가능성을 높입니다.

### 2. **VM에 vNIC 추가가 브로드캐스트 수신에 미치는 영향**
- **multi-NIC 환경의 문제**: VM에 vNIC을 추가하면 이제 VM이 다중 네트워크 인터페이스(기존 NIC + 추가 vNIC)를 가지게 됩니다. 이는 라우팅 테이블(ip route show로 확인 가능)이 복잡해지게 하고, 패킷 검증 과정에서 충돌을 일으킬 수 있습니다. 브로드캐스트 패킷은 모든 인터페이스로 퍼지지만, 추가 vNIC이 "전용"으로 설정되었더라도 커널이 소스 IP를 검사할 때 "이 패킷이 이 인터페이스로 와야 하는가?"를 확인합니다.
- **rp_filter의 개입**: Linux 커널의 rp_filter(Reverse Path Filter)는 들어오는 패킷의 소스 IP가 올바른 경로로 왔는지 검사합니다. 기본값(보통 1 또는 2)에서 브로드캐스트 패킷의 소스 IP가 "도달 불가능"으로 보이면 드롭합니다. multi-NIC 환경에서 이는 더 빈번히 발생합니다. 예를 들어:
  - rp_filter=1(Strict 모드): 패킷이 도착한 인터페이스가 최적 역경로가 아니면 드롭. 추가 vNIC으로 인해 경로가 불일치할 수 있습니다.
  - rp_filter=2(Loose 모드): 소스 IP가 어떤 인터페이스에서도 도달 가능하지 않으면 드롭. 브로드캐스트의 특수 IP 때문에 실패할 수 있습니다.
- **왜 수신이 안 될 수 있는가?**: 추가 vNIC으로 브로드캐스트를 받으려 할 때, 패킷이 "잘못된 인터페이스"로 도착했다고 판단되어 드롭됩니다. 실제로 Oracle Linux나 임베디드 장치 사례에서 다중 NIC 환경에서 rp_filter=1로 하면 연결 문제가 발생한다고 합니다. VM(가상화) 환경에서는 ESXi의 vNIC 설정이 호스트의 물리적 NIC과 연동되어 더 복잡해집니다.

### 3. **그래서 rp_filter를 0으로 바꿔야 했는가?**
- **네, 그럴 가능성이 큽니다**: rp_filter를 0으로 변경하면 소스 IP 검증을 완전히 끄기 때문에, 브로드캐스트 패킷이 무조건 수신됩니다. 이는 L2B 제거와 vNIC 추가로 인한 경로 불일치 문제를 우회하는 방법입니다. 하지만 이는 보안 위험(스푸핑 공격 취약)을 초래하고, 이전에 언급된 대로 유실률 증가(불필요 패킷 유입으로 버퍼 오버플로우)를 유발할 수 있습니다.
- **대안**: rp_filter=0 대신 2(Loose 모드)로 설정해 보세요. 이는 브로드캐스트를 허용하면서 최소한의 검증을 유지합니다. 명령어: `sysctl -w net.ipv4.conf.all.rp_filter=2`. 또는 추가 vNIC에만 적용: `sysctl -w net.ipv4.conf.[인터페이스 이름].rp_filter=2`. 만약 asymmetric routing이 원인이라면, 라우팅 테이블을 조정하거나 iptables로 패킷을 필터링하는 게 더 나은 해결책입니다.

### 요약과 추천
- **가능성**: 네, L2B BMEdge 제거와 vNIC 추가는 asymmetric routing과 multi-NIC 문제를 일으켜 브로드캐스트가 드롭될 수 있습니다. rp_filter가 이 과정에서 주요 원인입니다.
- **검증 방법**: VM에서 `netstat -s | grep Udp`로 UDP 오류 확인, `tcpdump -i [vNIC 이름] broadcast`로 패킷 캡처해 드롭 여부 관찰하세요. 로그(dmesg | grep net)도 유용합니다.
- **개선**: rp_filter=2 시도 후 유실률 모니터링. 만약 여전히 문제라면 네트워크 전문가와 ESXi vSwitch 설정을 재검토하세요.

이 설명은 실제 사례와 문서를 기반으로 하며, 필요 시 더 구체적인 로그를 공유해 주세요!
