TIMESTMAP	DEV	tps	rkB/s	wkB/s	dkB/s	areq-sz	aqu-sz	await	%util
2025-10-25 AM 00:10	dm-3	133.75	0	25064.46	0	187.39	0.08	0.59	9.8
2025-10-25 AM 00:20	dm-3	162.64	0	30640.05	0	188.39	0.09	0.53	10.49
2025-10-25 AM 00:30	dm-3	127.69	0	24327.33	0	190.52	0.07	0.58	9.44
2025-10-25 AM 00:40	dm-3	80.92	0	15273.17	0	188.74	0.05	0.57	6.14
2025-10-25 AM 00:50	dm-3	122.62	0	23432.33	0	191.1	0.08	0.63	9.29
2025-10-25 AM 01:00	dm-3	110.45	0	21002.13	0	190.15	0.07	0.61	8.56
2025-10-25 AM 01:10	dm-3	135.27	0	21542.16	0	159.26	0.07	0.53	10.96
2025-10-25 AM 01:20	dm-3	115.59	0	22077.28	0	190.99	0.07	0.6	8.78
2025-10-25 AM 01:30	dm-3	104.65	0	19594.94	0	187.25	0.06	0.6	7.98
2025-10-25 AM 01:40	dm-3	108.23	0	20319.97	0	187.74	0.06	0.57	8.01
2025-10-25 AM 01:50	dm-3	106.57	0	19992.43	0	187.59	0.06	0.57	8
2025-10-25 AM 02:00	dm-3	114.26	0	21475.83	0	187.96	0.07	0.57	8.47

2025-10-24 AM 00:10	dm-3	502.19	0	87035.88	0	173.31	0.18	0.35	14.11
2025-10-24 AM 00:20	dm-3	527.6	0	91510.24	0	173.45	0.14	0.26	14.69
2025-10-24 AM 00:30	dm-3	542.49	0	94069.64	0	173.4	0.34	0.62	16.05
2025-10-24 AM 00:40	dm-3	536.23	0	93314.99	0	174.02	0.79	1.47	17.92
2025-10-24 AM 00:50	dm-3	538.18	0	93393.99	0	173.54	0.38	0.71	16
2025-10-24 AM 01:00	dm-3	540.31	0	93655.75	0	173.34	0.33	0.62	15.72
2025-10-24 AM 01:10	dm-3	562.3	0	93411.98	0	166.13	0.24	0.42	15.66
2025-10-24 AM 01:20	dm-3	510.38	0	88465.11	0	173.33	0.21	0.41	14.45
2025-10-24 AM 01:30	dm-3	532.21	0	92409.98	0	173.63	0.24	0.44	15.04
2025-10-24 AM 01:40	dm-3	537.96	0	93447.8	0	173.71	0.17	0.32	15.03
2025-10-24 AM 01:50	dm-3	554.92	0	96461.41	0	173.83	0.15	0.28	15.46
2025-10-24 AM 02:00	dm-3	563.55	0	97902.6	0	173.72	0.22	0.38	15.82

2025-10-24 PM 01:00	dm-3	550.79	0	102850.82	0	186.73	0.75	1.36	18.69
2025-10-24 PM 01:10	dm-3	591.04	0	111322.29	0	188.35	4.67	7.9	29.5
2025-10-24 PM 01:20	dm-3	610.97	0	114695.42	0	187.73	2.55	4.17	24.24
2025-10-24 PM 01:30	dm-3	652.76	0.21	124051.31	0	190.04	1.19	1.82	23.04
2025-10-24 PM 01:40	dm-3	659.84	0	123551.28	0	187.24	2.58	3.92	25.96
2025-10-24 PM 01:50	dm-3	716.89	0.43	139068.45	0	193.99	1.23	1.72	28.29
2025-10-24 PM 02:00	dm-3	737.44	0.11	138826.4	0	188.25	2.82	3.82	29.41
2025-10-24 PM 02:10	dm-3	763.26	0	143904.35	0	188.54	1.77	2.32	26.6
2025-10-24 PM 02:20	dm-3	768.35	0.21	147662.04	0	192.18	3.6	4.68	32.36
2025-10-24 PM 02:30	dm-3	769.84	0.11	145887.42	0	189.5	1.15	1.49	24.91
2025-10-24 PM 02:40	dm-3	758.93	0	144689.03	0	190.65	5.27	6.95	35.37
2025-10-24 PM 02:50	dm-3	447.56	0	84628.56	0	189.09	0.94	2.1	17.6
2025-10-24 PM 03:00	dm-3	111.39	0	20970.77	0	188.27	0.06	0.51	8.25
2025-10-24 PM 03:10	dm-3	119.08	0	22248.98	0	186.84	0.06	0.53	8.66
2025-10-24 PM 03:20	dm-3	172.97	0	32117.47	0	185.69	0.08	0.46	10.36
2025-10-24 PM 03:30	dm-3	130.03	0	23947.31	0	184.17	0.06	0.48	9.05
2025-10-24 PM 03:40	dm-3	102.84	0	18780.81	0	182.61	0.05	0.49	7.34
2025-10-24 PM 03:50	dm-3	152.89	0	27598.71	0	180.52	0.07	0.47	9.68
2025-10-24 PM 04:00	dm-3	138.7	0	25410.19	0	183.21	0.08	0.56	10


https://support.scc.suse.com/s/kb/TSC-Clocksource-Switching-to-HPET-During-High-I-O-Load?language=en_US


### 문제 요약 및 분석 개요

사용자님의 서버(Lenovo SR950, RHEL 9.4, 224 Core CPU, 12TB RAM, 7.5TB SATA SSD 5개 RAID-6 구성, dm-3 디바이스)에서 SSD 쓰기 성능이 2025-10-24 오후 2:50~3:00경부터 급격히 저하되었습니다. sar -d 데이터(ps.txt)에서 wkB/s가 PM 02:40의 144k에서 PM 03:00의 20k로 떨어지며, tps도 758에서 111로 감소했습니다. 이는 정상 상태(2.6GB/s) 대비 현재 0.8GB/s 수준으로, 약 70% 저하입니다. /var/log/messages(x.txt 및 m.txt) 로그를 검토한 결과, 이 시점(14:45:09)에 kernel clocksource가 TSC(Time Stamp Counter)에서 HPET(High Precision Event Timer)으로 전환된 것이 주요 원인으로 보입니다. 재부팅 후(10/25 17시 이후) /sys/devices/system/clocksource/clocksource0/current_clocksource가 TSC로 복귀된 것은 불안정 감지가 일시적이었음을 시사하지만, 근본 원인을 해결하지 않으면 재발 가능합니다.

분석은 제공된 sar 데이터와 로그를 기반으로 하며, 외부 출처(커널 문서, Red Hat/SUSE KB, 엔지니어링 블로그)를 통해 사실 검증했습니다. 아래에서 단계적으로 설명하겠습니다.

#### 1. sar -d 데이터 재분석 (ps.txt)
- **정상 시기 (PM 01:00~02:40)**: tps 550~769, wkB/s 102k~147k (약 100~140 MB/s), %util 18~35%, aqu-sz 0.75~5.27, await 1~7ms. 고부하지만 지연 없이 처리. RAID-6의 쓰기 패널티(패리티 계산)에도 불구하고 안정적.
- **저하 시작 (PM 02:50~03:00)**: tps 447→111, wkB/s 84k→20k. 부하 감소에도 throughput 급감. %util 17.6→8.25로 낮아졌으나, areq-sz(평균 요청 크기)는 189KB 유지 → 처리 속도 자체가 느려짐.
- **저하 지속 (PM 03:10~04:00 및 다음 날 AM)**: tps 102~172, wkB/s 18k~32k. 사용자 테스트(1M block 20GB dd 명령)와 일치: 정상 2.6GB/s vs. 현재 0.8GB/s.
- **검증 포인트**: 저하 시점이 로그의 clocksource 전환(14:45:09)과 맞물림. I/O가 쓰기 중심(rkB/s 거의 0)으로, 타이밍 의존적인 RAID 작업에서 영향 큼.

#### 2. /var/log/messages 분석 (x.txt 및 m.txt)
- **clocksource 관련 경고 반복**: 13:11~14:39까지 여러 CPU(예: CPU348,133,302 등)에서 "timekeeping watchdog on CPUxx: hpet wd-wd read-back delay of xxx ns"와 "wd-tsc-wd read-back delay of xxx ns, clock-skew test skipped!" 발생. 이는 kernel의 clocksource watchdog가 TSC와 HPET 간 클럭 스큐(skew)를 감지한 신호.
- **전환 이벤트 (14:45:09)**: 
  - "clocksource: timekeeping watchdog on CPU392: wd-tsc-wd read-back delay of 113640ns, attempt 3, marking unstable"
  - "tsc: Marking TSC unstable due to clocksource watchdog"
  - "TSC found unstable after boot, most likely due to broken BIOS. Use 'tsc=unstable'."
  - "clocksource: Switched to clocksource hpet"
  이는 watchdog가 TSC 불안정을 3회 시도 후 확인하고 HPET으로 전환한 것입니다. m.txt에서 추가로 03:08, 05:23 등 더 이른 시기부터 유사 경고가 보이지만, 실제 전환은 14:45에 발생.
- **기타 이벤트**:
  - corosync (클러스터링) link down/up (13:10): 네트워크 불안정, 하지만 I/O 직접 영향 적음.
  - auditd rotating log files 반복: 로그 로테이션으로 약간의 I/O 부하, 하지만 미미.
  - perf interrupt too long (13:44): kernel.perf_event_max_sample_rate 낮춤 → CPU 오버헤드 증가, clock skew 유발 가능.
  - SAP SLD Registration (14:10): HTTP 전송 성공, 일시적 네트워크/I/O 부하.
  - NMI handler too long (03:08 등): Non-Maskable Interrupt 지연, 하드웨어/BIOS 문제 시사.
- **multipath 출력 (m.txt 상단)**: dm-3은 언급되지 않음 (NETAPP LUN 관련 dm-14~18만 보임). dm-3은 internal SSD RAID로 별도, 데그레이드 없음으로 보임.
- **재부팅 후 TSC 복귀**: 재부팅 시 kernel이 TSC를 다시 안정으로 판단. 이는 skew가 부팅 시 초기화되거나, 워크로드 의존적임을 의미. 하지만 "broken BIOS" 로그로 BIOS 결함 가능성 높음.

#### 3. 주요 원인: Clocksource TSC → HPET 전환
TSC는 CPU 내장 고정밀 타이머(CPU 클럭 기반, ns 단위 해상도)로, I/O나 실시간 작업에 최적. HPET은 하드웨어 타이머(10~100MHz, μs 단위)로 대체지만, 호출 비용(오버헤드)이 TSC보다 10~100배 높음. 대형 서버(224 Core)에서 CPU 간 클럭 동기화 실패 시 watchdog가 TSC를 unstable로 마킹하고 HPET으로 전환.

이 전환으로 I/O 성능 저하 이유:
- **타이밍 오버헤드 증가**: I/O 작업(예: dd, RAID 쓰기)은 gettimeofday()나 sched_clock() 같은 타이밍 함수를 빈번히 호출. TSC는 레지스터 읽기(빠름)지만, HPET은 I/O 포트 접근(느림) → 각 I/O 요청 처리 지연 누적.
- **throughput 저하**: 고부하 쓰기에서 초당 수천 요청 시, 오버헤드가 쌓여 wkB/s 감소. 사용자 경우처럼 sequential write(1M block)에서 두드러짐.
- **검증 근거 및 출처**:
  - SUSE KB: High I/O load 중 TSC unstable로 HPET 전환 시 성능 영향. "A clocksource watchdog failure will result in the current clocksource being marked as unstable, forcing a switch to an alternative clocksource." (URL: https://support.scc.suse.com/s/kb/TSC-Clocksource-Switching-to-HPET-During-High-I-O-Load)
  - Vinted Engineering 블로그: 동일 서버에서 TSC vs. HPET 시 "high-throughput workloads" 성능 저하. HPET 오버헤드로 인해 시스템 성능 drop. (URL: https://vinted.engineering/2025/07/15/clocksource-performance/)
  - DeeperF 블로그: TSC 대신 HPET 사용 시 "low performance" 발생, 특히 최신 Intel CPU에서. (URL: https://deeperf.com/2019/04/30/tsc-clock-missing-caused-performance-issues/)
  - Red Hat KB: RHEL 8/9에서 TSC unstable 마킹 시, CPU 온라인 추가나 skew로 발생. I/O 영향 암시. (URL: https://access.redhat.com/solutions/6989115)
  - 추가: Reddit/Nvidia 포럼에서 HPET 시 게임/시스템 FPS 70% 저하 사례, 유사 메커니즘. 이는 kernel 문서(Documentation/timers/timekeeping.txt)와 일치: HPET은 "slower but more reliable"로, 성능 트레이드오프.

Lenovo SR950(멀티소켓 Intel Xeon)에서 BIOS 결함("broken BIOS" 로그)으로 skew 발생 빈번. 재부팅 후 TSC 복귀로 성능 회복 예상되지만, BIOS 업데이트 필요.

#### 4. 정확한 원인 분석을 위한 추가 확인 방법
- **Clocksource 상태**: `cat /sys/devices/system/clocksource/clocksource0/current_clocksource` (이미 TSC 확인). `cat /sys/devices/system/clocksource/clocksource0/available_clocksource`로 대안 목록.
- **TSC 안정성 테스트**: 부팅 시 GRUB에 `clocksource=tsc tsc=reliable` 추가 (GRUB_CMDLINE_LINUX_DEFAULT 수정 후 `grub2-mkconfig -o /boot/grub2/grub.cfg` 및 재부팅). 또는 `tsc=unstable`로 강제 테스트.
- **BIOS 확인**: Lenovo Vantage나 웹 콘솔로 BIOS 버전 확인. TSC 관련 패치 다운로드 (Lenovo 지원: https://pcsupport.lenovo.com/us/en/products/servers/thinksystem/sr950/downloads).
- **I/O 및 하드웨어 확인**:
  - RAID 상태: `cat /proc/mdstat` 또는 컨트롤러 툴(`storcli /c0 show` if LSI).
  - SSD 건강: `smartctl -a /dev/sdX` (X=a~e, wear level/error 확인).
  - 실시간 모니터: `iostat -x -d dm-3 1` (await/%util 관찰), `fio --name=write --rw=write --bs=1M --size=20G --direct=1 --filename=/testfile` (쓰기 벤치마크).
- **로그 상세**: `dmesg | grep -i clocksource` 또는 `journalctl -k --since "2025-10-24 14:00" | grep tsc`.
- **워크로드**: SAP 로그(`/usr/sap/S4P/*/trace/`)나 `iotop -o`로 I/O 소비 프로세스 확인.
- **권장 조치**: BIOS 업데이트 후 모니터링. 재발 시 Red Hat 지원 티켓 (skew가 kernel stall 측면 효과일 수 있음).

추가 데이터 공유 시 더 구체적 조언 드리겠습니다.
