---
title: "네트워크 데이터 유실률 분석 #1"
date: 2025-06-16
tags: [netstat, ethtool, drop, network]
categories: [Network, Analysis]
---

# 네트워크 데이터 유실률 분석 - 06/16 07:55 ~ 09:55 

## Delta 값 

| VM | Udp packets received | Udp packet receive errors | IpExt InBcastPkts | UdpRcvbufErrors | Ip InDiscards | Udp InErrors | drv dropped rx total | rx buf alloc fail | pkts rx err | bcast pkts rx |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| mca5102 | 118726547 | 9880 | 118735732 | 9880 | 0 | 9880 | 0 | 0 | 0 | 118740740 |
| mca5204 | 118765978 | 2195 | 118768269 | 2195 | 0 | 2195 | 0 | 0 | 0 | 118772997 |
| mca5304 | 118814026 | 8548 | 118821440 | 8548 | 0 | 8548 | 0 | 0 | 0 | 118826683 |

| ESXi 서버 | broadcast pkts rx ok | droppedRx | pktsRxBroadcast |
|----------|----------------------|-----------|-----------------|
| mca5101  | 118710306            | 0         | 118710666       |
| mca5203  | 118714965            | 0         | 118715197       |
| mca5303  | 118776751            | 0         | 118777002       |

아래는 07:55 ~ 09:55 동안의 VM 및 ESXi 서버 통계값의 델타 값을 바탕으로 유실률과 관련된 데이터를 분석한 결과입니다. 

---

## **데이터 분석**

### **1. VM 통계 분석**
VM 통계에서 패킷 유실과 관련된 주요 지표는 다음과 같습니다:
- `Udp packet receive errors`: UDP 패킷 수신 오류 수
- `UdpRcvbufErrors`: UDP 수신 버퍼 오류 수
- `Udp InErrors`: UDP 입력 오류 수
- `Ip InDiscards`, `drv dropped rx total`, `rx buf alloc fail`, `pkts rx err`: 기타 패킷 드롭 또는 오류 지표

**관찰:**
- 모든 VM에서 `Ip InDiscards`, `drv dropped rx total`, `rx buf alloc fail`, `pkts rx err` 값이 `0`입니다. 이는 드라이버나 하드웨어 수준에서 패킷 유실이 발생하지 않았음을 의미합니다.
- 그러나 `Udp packet receive errors`, `UdpRcvbufErrors`, `Udp InErrors`는 모두 동일한 비제로 값을 가집니다:
  - `mca5102`: 9,880
  - `mca5204`: 2,195
  - `mca5304`: 8,548
- 이 세 지표가 동일하다는 것은 패킷 유실이 주로 **UDP 수신 버퍼 오버플로우**로 인해 발생했음을 나타냅니다. 즉, VM이 수신한 UDP 패킷을 처리할 수 있는 속도가 충분하지 않아 버퍼가 넘친 경우입니다.

### **2. ESXi 서버 통계 분석**
ESXi 서버 통계에서 유실률과 관련된 주요 지표는 `droppedRx`입니다:
- 모든 ESXi 서버(`mca5101`, `mca5203`, `mca5303`)에서 `droppedRx` 값이 `0`입니다.
- 이는 하이퍼바이저 수준에서 패킷 드롭이 발생하지 않았음을 의미하며, 유실 문제는 VM 내부에서 발생하고 있음을 확인할 수 있습니다.

### **3. UDP 패킷 유실률 계산**
UDP 패킷 유실률은 다음과 같은 식으로 계산할 수 있습니다:
\[
\text{UDP 유실률} = \frac{\text{Udp packet receive errors}}{\text{Udp packets received} + \text{Udp packet receive errors}} \times 100\%
\]
여기서 `Udp packets received`는 성공적으로 수신된 패킷 수를 의미하고, `Udp packet receive errors`를 더해 총 시도된 패킷 수를 구합니다.

- **mca5102**:
  \[
  \text{UDP 유실률} = \frac{9,880}{118,726,547 + 9,880} \approx \frac{9,880}{118,736,427} \approx 0.00832\%
  \]
- **mca5204**:
  \[
  \text{UDP 유실률} = \frac{2,195}{118,765,978 + 2,195} \approx \frac{2,195}{118,768,173} \approx 0.00185\%
  \]
- **mca5304**:
  \[
  \text{UDP 유실률} = \frac{8,548}{118,814,026 + 8,548} \approx \frac{8,548}{118,822,574} \approx 0.00719\%
  \]

유실률은 0.00185%에서 0.00832%로 매우 낮은 수준이지만, 애플리케이션의 요구 사항에 따라 이 값이 성능에 영향을 줄 수 있습니다.

### **4. 브로드캐스트 패킷 관련 통찰**
- VM의 `bcast pkts rx`(드라이버 수준)와 ESXi의 `pktsRxBroadcast`를 비교하면 불일치가 관찰됩니다:
  - `mca5102`: `bcast pkts rx` = 118,740,740
  - `mca5101`: `pktsRxBroadcast` = 118,710,666
- VM의 값이 ESXi의 값보다 크다는 점은 직관적으로 예상과 다릅니다. 일반적으로 VM의 패킷 수는 호스트 서버의 패킷 수 이하여야 합니다.
- 이 차이는 다음과 같은 이유로 발생할 수 있습니다:
  - VM의 가상 NIC와 ESXi의 물리 NIC 간 패킷 카운팅 방식의 차이
  - 다중 rx 큐(multiple receive queues) 또는 내부 패킷 처리 메커니즘
  - 데이터 수집 또는 델타 계산 오류 가능성

---

## **주요 통찰**
1. **패킷 유실의 원인**:
   - 패킷 유실은 VM 내부에서 발생하며, 주로 **UDP 수신 버퍼 오버플로우**로 인해 나타납니다. 이는 높은 패킷 수신률(예: `mca5102`의 경우 초당 약 16,490 UDP 패킷)과 버퍼 크기 또는 애플리케이션 처리 속도의 불균형에서 기인합니다.

2. **ESXi와 VM 간 역할**:
   - ESXi 서버는 패킷 드롭이 없으므로 네트워크 인프라 자체는 안정적입니다. 문제는 VM의 네트워크 스택에 국한됩니다.

3. **브로드캐스트 패킷 불일치**:
   - VM과 ESXi 간 브로드캐스트 패킷 수의 불일치는 가상화 환경에서의 패킷 전달 또는 카운팅 방식에 대한 추가 조사가 필요함을 시사합니다.

---

## **권장 사항**
1. **UDP 수신 버퍼 크기 증가**:
   - VM 운영체제에서 UDP 수신 버퍼 크기를 조정하여 더 많은 패킷을 처리할 수 있도록 합니다. 예: `sysctl` 명령어로 `net.core.rmem_max` 값을 늘릴 수 있습니다.
   
2. **애플리케이션 최적화**:
   - 패킷을 처리하는 애플리케이션이 높은 처리량을 감당할 수 있도록 최적화하거나, 멀티스레딩을 도입하여 병렬 처리를 강화합니다.

3. **부하 분산**:
   - 가능하다면 트래픽을 여러 VM에 분산시켜 개별 VM의 부담을 줄입니다.

4. **브로드캐스트 패킷 불일치 조사**:
   - VM과 ESXi 간 브로드캐스트 패킷 수의 차이를 명확히 이해하기 위해 네트워크 설정, rx 큐 설정, 또는 데이터 수집 프로세스를 점검합니다.

---

## **결론**
분석 결과, 07:55 ~ 09:55 동안의 패킷 유실은 VM 내 UDP 수신 버퍼 오버플로우로 인해 발생하며, 유실률은 약 0.00185% ~ 0.00832%로 낮은 편입니다. ESXi 서버는 패킷 드롭이 없어 네트워크 인프라가 안정적임을 알 수 있습니다. 그러나 UDP 버퍼 문제 해결을 위해 버퍼 크기 조정 및 애플리케이션 최적화가 필요하며, 브로드캐스트 패킷 수의 불일치는 추가적인 조사가 요구됩니다. 이러한 조치를 통해 유실률을 최소화하고 시스템 성능을 향상시킬 수 있을 것입니다.

---

## 1. ESXi 서버 (mca5101) 통계 분석

ESXi 서버는 VM으로 전달되는 패킷 흐름을 관리하며, 하이퍼바이저 레벨에서의 패킷 유실 여부를 확인할 수 있습니다. 아래는 07:55 (UTC 22:55)와 09:55 (UTC 00:55) 간 주요 통계 변화입니다.

### ESXi 통계 변화 표
| 항목                    | 07:55 (UTC 22:55) | 09:55 (UTC 00:55) | 델타 (차이)   |
|-------------------------|-------------------|-------------------|---------------|
| broadcast pkthey rx ok   | 4,755,499,577     | 4,874,209,883     | 118,710,306   |
| pktsRxBroadcast         | 4,755,499,578     | 4,874,210,244     | 118,710,666   |
| droppedRx               | 16                | 16                | 0             |

**분석:**
- **broadcast pkts rx ok**: 정상 수신된 브로드캐스트 패킷 수가 약 1억 1,871만 개 증가.
- **pktsRxBroadcast**: VM으로 전달된 브로드캐스트 패킷 수가 약 1억 1,871만 개 증가.
- **droppedRx**: 드롭된 수신 패킷 수는 16개로 변화 없음.

**결론:**  
`broadcast pkts rx ok`와 `pktsRxBroadcast`의 증가량이 거의 동일하며, `droppedRx`가 변하지 않았습니다. 이는 ESXi 서버에서 VM으로의 패킷 전달 과정에서 하이퍼바이저 레벨의 유실이 발생하지 않았음을 의미합니다.

---

## 2. VM (mca5102) 통계 분석

VM 통계는 네트워크 스택과 애플리케이션 레벨에서의 패킷 처리 상태를 보여줍니다. 아래는 07:55와 09:55 간 주요 통계 변화입니다.

### VM 통계 변화 표
| 항목                    | 07:55             | 09:55             | 델타 (차이)   |
|-------------------------|-------------------|-------------------|---------------|
| Udp packets received    | 4,754,874,123     | 4,873,600,670     | 118,726,547   |
| Udp packet receive errors| 875,563           | 885,443           | 9,880         |
| IpExt InBcastPkts       | 4,755,479,591     | 4,874,215,323     | 118,735,732   |
| bcast pkts rx (ethtool) | 4,755,499,595     | 4,874,240,335     | 118,740,740   |

**분석:**
- **bcast pkts rx (ethtool)**: NIC에서 수신한 브로드캐스트 패킷 수는 1억 1,874만 개 증가.
- **IpExt InBcastPkts**: OS 네트워크 스택에서 처리된 브로드캐스트 패킷 수는 1억 1,873만 개 증가. NIC 대비 5,008개 적음.
- **Udp packets received**: 애플리케이션에 전달된 UDP 패킷 수는 1억 1,872만 개 증가. `IpExt InBcastPkts`보다 적음.
- **Udp packet receive errors**: 수신 오류가 9,880개 증가. 이는 `receive buffer errors`와 동일.

**결론:**  
NIC에서 수신한 패킷(`bcast pkts rx`)이 네트워크 스택(`IpExt InBcastPkts`)과 애플리케이션(`Udp packets received`)으로 전달되는 과정에서 감소하며, `Udp packet receive errors` 증가와 연관이 있습니다. 이는 VM 내부에서 패킷 유실이 발생했음을 시사합니다.

---

## 3. 애플리케이션 유실률 분석

애플리케이션에서 보고된 유실률 0.159%는 Baremetal 서버 수신 패킷(115,989,899) 대비 VM 수신 패킷(115,805,978)으로 계산됩니다.

\[
\text{유실률} = \left(1 - \frac{115,805,978}{115,989,899}\right) \times 100\% \approx 0.159\%
\]

**분석:**  
- VM에서 수신한 패킷 수가 Baremetal보다 183,921개 적음.
- VM 통계의 `Udp packet receive errors` 증가(9,880개)는 전체 유실의 일부를 설명하지만, 나머지 유실(약 174,041개)은 별도 원인일 가능성 있음.

---

## 4. 패킷 유실 원인 분석

VM에서 발생한 패킷 유실의 주요 원인을 분석합니다.

- **수신 버퍼 오버플로우**: `Udp packet receive errors`와 `receive buffer errors`가 9,880개로 동일. 애플리케이션 처리 속도가 느려 버퍼가 가득 찼을 가능성 높음.
- **체크섬 오류**: 데이터에 명시적 증거 없음.
- **포트 오류**: `packets to unknown port received`는 55개 증가(12,251 → 12,306)로 영향 미미.

**결론:**  
주요 원인은 **수신 버퍼 오버플로우**로, `net.core.rmem_max` (32MB)가 패킷 수신률 대비 부족했을 가능성이 있습니다.

---

## 5. 버퍼 및 큐 설정 분석

- **rx ring buffer**: `ethtool -g <DEV>`로 확인한 최대 크기는 4096. `drv dropped rx total`이 0이므로 하드웨어 레벨 드롭은 없음.
- **net.core.rmem_max**: 33,554,432(32MB). UDP 수신 버퍼 크기로, 트래픽 부하 대비 적절성 검토 필요.

---

## 6. 개선 방안

패킷 유실을 줄이기 위한 상세한 개선 방안을 제안합니다.

### 1. 애플리케이션 최적화
- **멀티스레딩 도입**: 패킷 처리 속도를 높이기 위해 병렬 처리 구현.
- **비동기 I/O 사용**: 블로킹 작업을 줄여 처리 효율성 향상.

### 2. UDP 수신 버퍼 크기 증가
- 현재 32MB인 `net.core.rmem_max`를 64MB로 증가:
```
sysctl -w net.core.rmem_max=67108864
sysctl -w net.core.rmem_default=67108864
```
- 변경 후 `/proc/sys/net/core/rmem_max`로 확인.

### 3. 네트워크 설정 조정
- **인터럽트 병합**: CPU 부하 감소를 위해 활성화:
```
ethtool -C <DEV> adaptive-rx on
```
- **rx ring buffer**: 현재 최대값(4096)으로 설정됨. 추가 증가 불가.

### 4. 시스템 자원 모니터링
- **CPU/메모리 확인**: `top` 또는 `vmstat`으로 자원 병목 여부 점검.
- **자원 할당 증가**: 필요 시 VM에 CPU/메모리 추가 할당.

---

## 7. 특정 Rx Queue 사용 분석 및 확장 가능성

VM의 `ethtool` 통계에서 Rx Queue별 패킷 분산을 확인했습니다:
- **Rx Queue #1**: 브로드캐스트 패킷 대부분 처리 (약 4,747만 개).
- **Rx Queue #6**: 일부 브로드캐스트 처리 (약 1,266만 개).
- 나머지 Queue: 유니캐스트 위주.

**분석:**  
특정 Queue(예: #1)에 부하가 집중됨. 이는 RSS (Receive Side Scaling) 설정으로 조정 가능합니다.

**확장 방안:**
- **RSS 최적화**: `ethtool -x <DEV>`로 Queue별 분배 확인 후, 균등 분산 조정:
  ```bash
  ethtool -X <DEV> equal
  ```
- **Queue 수 증가**: VM의 vNIC 설정에서 Rx Queue 수를 늘리려면 ESXi에서 VM의 네트워크 어댑터를 재구성해야 함 (관리자 권한 필요).
- **제한**: 하드웨어(NIC)와 VMXNET3 드라이버의 Queue 최대 수에 의존.

---

## 결론

mca5102에서 발생한 패킷 유실은 주로 **UDP 수신 버퍼 오버플로우**로 인해 발생했습니다. 애플리케이션 처리 속도 개선, `net.core.rmem_max` 증가, 네트워크 설정 최적화(RSS, 인터럽트 병합), 자원 모니터링을 통해 유실률을 줄일 수 있습니다. Rx Queue는 현재 분산 사용 중이나, 부하 집중을 줄이기 위해 RSS 조정 또는 Queue 수 증가를 고려할 수 있습니다. 이러한 조치로 애플리케이션 성능을 향상시키고 유실률 0.159%를 감소시킬 수 있습니다.
