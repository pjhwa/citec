네이버페이 서비스 장애 분석 보고서
 

1. 개요
2026년 2월 19일 발생한 네이버페이(Naver Pay) 장애는 마이크로서비스 아키텍처(MSA)의 복잡성과 분산 트랜잭션 관리의 어려움을 잘 보여준 사례이다. 인터넷에 공개된 자료를 바탕으로 장애의 전개 과정과 기술적 원인을 통해 기술적 시사점을 정리하였다.


2. 장애발생 타임라인 (진행경과)
장애는 2026년 2월 19일 정오경 시작되어 약 4시간 동안 지속되었으며, 장애 원인으로 알려진 DB서비스 복구와 대기열 해소라는 두 단계의 과정을 거쳐 정상화되었다.

시간

주요 진행 상황 및 조치 내용

 12:00 ~ 12:07

 포인트 조회 실패 및 결제 오류 발생. (장애 인지 시점) 

 12:38

 과기정통부 신고 및 대외 공식 공지 게시: 주문서 내 포인트 조회 및 결제 실패 안내. 

 14:20

 1차 긴급 복구: 포인트 서비스 내부 로직 오류 및 DB 장애 해결. 

 14:20 ~ 15:30

 적체된 Kafka 메시지 처리를 위한 대기열(Throttling) 조치 시행. 

 15:30

 결제 대기열 및 과부하 전면 해소. 전 서비스 실질적 정상화. 

 16:35

 최종 서비스 정상화 공식 발표 및 사과문 게시. 



3. 기술적 원인분석 (RCA)

이번 장애는 포인트 서비스의 원본 DB 쓰기 실패가 시스템 전반으로 전파된 '연쇄 실패(Cascading Failure)'의 전형적인 사례이다.


3.1. 네이버페이 기술 아키텍처 및 장애 전파 경로
인터넷에 공개된 아키텍처와 공식 발표한 원인을 바탕으로 재구성한 장애 전파 경로는 다음과 같습니다.


3.2. 컴포넌트별 장애 요인 상세 분석

Persistence Layer (MySQL/nBase-T): 포인트 서비스의 원본 DB인 MySQL(nBase-T 분산 DB)에서 내부 로직 오류로 인한 쓰기(Update) 장애가 발생했다. 이는 샤딩 로직의 결함이나 복식부기 원장 기록 시의 데드락 가능성을 포함한다.

Saga Orchestrator: 포인트 DB 업데이트 실패로 응답이 지연되자, Saga 패턴에 의해 이미 완료된 주문을 취소하기 위한 보상 트랜잭션(Compensation Transaction)이 대량으로 발생하여 시스템 부하를 가중시켰다.

Kafka (Event Bus): 쏟아지는 실패, 취소 이벤트를 처리하는 과정에서 컨슈머 랙(Consumer Lag)이 수백만 건 발생했다. 이를 해결하기 위해 복구 후에도 초당 처리량을 제한하는 스로틀링(Throttling) 전략이 사용되었으며, 이로 인해 완전 정상화까지 추가 시간이 소요되었다.

Ergate (CDC): 원본 DB의 지연으로 인해 CDC(Change Data Capture) 복제 시스템의 지연 임계치가 초과되었다. 시스템은 데이터 부정합을 방지하기 위해 읽기 전용 복제본에 대한 접근을 차단했으며, 이것이 사용자가 겪은 '포인트 조회 실패'의 직접적인 원인이 되었다.


4. 장애로 인한 영향

기능적 마비: 주문서 내 포인트 조회 및 결제 실패, 현장 결제 포인트, 머니 사용 불능, 페이머니카드 결제 승인 실패 등의 문제가 광범위하게 발생했다.

서비스 확산: 네이버 쇼핑 외에도 네이버 예약, 웹툰, 배달의민족 등 네이버페이 결제 모듈을 사용하는 연동 서비스 전반이 마비되었다.

경제적 손실: 결제 수단 선택 자체가 차단되면서 가맹점(SME)들은 매출 기회를 상실했고, 고객센터 접속 대기자가 수만 명에 달하는 등 CS 부하가 극심했다.



5. 조치경과 및 공식 발표

원인 확정: 네이버페이는 조사를 통해 "외부 해킹이 아닌 내부 로직 오류에 의한 DB 시스템 장애"임을 공식 발표했다.

복구 전략: 긴급 패치를 통해 논리적 오류를 해결한 후, 대기열 조치를 병행하여 시스템을 안정화했다.

정부 대응: 과학기술정보통신부와 금융감독원에 사고 경위를 보고하였으며, 금감원은 소비자 보호 조치 및 재발 방지 대책을 강하게 요구했다.
