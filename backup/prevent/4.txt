SCP Compute개발그룹(SCP개발)
SCP 통합로그 관리 및 이상로그 Alert 자동화를 통한 Storage 상품 패턴기반 모니터링 - 운영 안정성 확보 및 장애 최소화 사례

1. 추진 배경 및 문제 정의
- SCP Storage 상품 구조: PP/PS/PG 등 다양한 오퍼링 제공, 리전별  Storage 인프라와 프로비저닝 애플리케이션이 역할별로 나누어져 있음.
- 역할 분리: 개발/기술/아키텍처/운영 부서로 역할이 구분되어 이슈 발생 시 원인 파악에 시간이 소요됨.
- 문제 발생 가능성: 개발/검증 환경에서는 발생하지 않았던 예상치 못한 에러가 애플리케이션의 다층적 구조로 인해 발생할 수 있음.
- 로그 분석의 중요성: 화면 기능이 아닌 애플리케이션 Log로만 문제의 원인을 확인할 수 있는 경우가 많아 분석이 필수적임.
- Pain Point:
  . 인프라와 프로비저닝 애플리케이션이 역할별 분리되어 문제 발생 시 원인 파악이 어려움.
  . 다양한 오퍼링으로 인해 로그 데이터가 분산되어 로그 분석 및 문제 파악이 비효율적임.
  . Storage 장비의 특성 등 사전에 문제를 예방하기 어려운 구조적 한계가 존재함.

2. 개선 활동 내용 
- 1차 :  Storage Log Monitoring 및 batch 시스템 개발  (2024.1 ~ 2024.9)
  . 목적: 스토리지 파트에서 개발한 Application(모듈)의 운영 로그를 점검하여 에러 로그를 필터링하고, 필요 시 이슈 대응 및 소스 개선에 반영.
  . 현황:
    - 매일 또는 주간 단위로 각 오퍼링별 로그 점검 수행.
    - (구) Kibana → (현) Opensearch Dashboard 를 통해 에러 로그 필터링.
    - 반복 작업으로 인해 확인자의 부담 및 피로감 증가.
  . 자동화 방안 검토 및 적용:
    - Log level 정의 및 로그 정제 작업 진행.
    - 개별 오퍼링에서 수집되던 Opensearch 로그를 Shared MB(PP)에서 통합 Opensearch로 통합.
    - 통합 Datasource에서 불필요한 에러 로그 필터링 및 지정된 기간 내 에러 로그를 Excel 파일로 추출하는 소스 개발.
    - Excel 파일에 에러 로그(첫 번째 탭) 및 각 에러별 발생 빈도(두 번째 탭) 추출.
    - 자주 발생하는 에러 로그 파악 및 위험 확인이 필요한 에러 분류, 리포팅 방안 검토.

- 2차 : Opensearch Alert을 활용한 패턴기반 모니터링 자동화 (2024.9 ~ 계속)
  . 목적: Opensearch Alert 기능을 활용하여 패턴 기반 모니터링 자동화를 구현하고, 에러 로그를 효율적으로 관리 및 리포팅.
  . Opensearch Alert 설정:
    - Data Source: Alerting 메뉴에서 대상이 되는 데이터 지정.
    - Query(DQL): 데이터 중 조회를 원하는 검색 조건 설정.
    - Triggers: 조회된 데이터 중 조건(Threshold)을 충족하고 실행할 동작 정의.
    - Action: Webhook을 통해 Channel API 호출, Messenger 및 이메일로 알림 전송 구성.
  . 패턴 기반 모니터링 자동화 적용
    - 패턴 정의: 자주 발생하는 에러 로그 패턴을 식별하고, 이를 기반으로 모니터링 규칙 설정.
    - 자동화 적용: 정의된 패턴을 기반으로 실시간 로그 모니터링 및 Alert 트리거링.

3. 동작 방식 및 기술 아키텍처
- 쿼리 및 임계치 설정을 통해 다수의 로그 데이터를 통합 모니터링하며, OpenSearch를 활용하여 로그 데이터를 수집, 저장, 시각화함.
- Alert 모니터링 설정 및 WebHook 방식을 통해 사용자에게 메일/메신저 알림을 보내고, 신속한 대응이 가능하도록 설계됨
- OpenSearch를 활용한 로그 통합 및 패턴화
- OpenSearch 기반 Log 수집 자동화 개발
- Log Alert 모니터링 설정 및 메일/Messenger/SMS 알림

4. 적용 사례 및 효과
- 시스템을 적용한 이후, File Storage와 Object Storage에서 발생하던 오류 사전 감지 및 장애 예방
- 주말 및 야간과 같이 확인 공백이 발생할 수 있는 시간대에도 Alert 메일이 자동화되어 신속하게 문제를 파악할 수 있었음
- 사전 인지 후 조치 실제 사례(일부)
  . 사례1) 주말(에러 발생 시 대응 취약 시점)에 개인 일정을 보던 중 Knox Messenger를 통하여 Alert 알림을 수신
    - File Storage 상품과 연계하는 서비스인 SO(Storage Orchestrator)의 API 호출에 대한 대량의 timeout 발생 확인
    - 대량의 timeout 발생에 대한 에러 내용을 확인하고, 부서장에게 보고
    - 유관 부서에 해당 내용 공유하여 이슈 확인 및 필요 시 조치 요청
  . 사례2) File Storage 상품과 연계하는 서비스인 SO(Storage Orchestrator)의 API 호출에 대하여 특정 장비에서 대량의 timeout 발생 확인
    - API 호출 시 특정 Storage 장비에서 timeout이 많이 발생됨을 확인
    - 해당 장비에 대한 문제점에 대하여 유관 부서에서 인지하고, 사전 조치 방안에 대하여 검토 수립
    - 관련 Alert 사례 발생 시 유관 부서 인력도 포함하여 리포팅 될 수 있도록 요청 받음
  . 사례3) File Storage 상품과 연계하는 서비스인 SO(Storage Orchestrator)의 API 호출에 대하여 몇 개의 장비에서 대량의 timeout 발생 확인
    - 유관 부서에서 해당 내용 전달 하여, SO와 Storage 장비 사이에 있는 SO proxy server가 다운됨을 확인
    - 이로 인하여 해당 SO proxy server를 통하는 모든 Storage 장비로의 API 호출이 수행되지 않아 조치 진행 됨
- 효과
  . 장애 사전 예방 및 운영 안정성 확보
  . VoC 예측 및 유관 부서 전달을 통한 이상 현상 지속 방지 및 즉시 대응
  . 문제 발생의 원인 파악을 위한 노력 감소로 개발 업무 생산성 향상

5. 향후 계획 (개선 및 횡전개) 
- AI 적용: 생성형 AI를 활용하여 패턴을 설정하고, 예측 정확도를 높이고, 특정 빈도와 발생 시간대를 예측하여 선제적으로 대응할 수 있는 방안을 마련하고자 함
- 횡전개:  
  . SCP의 모든 상품, 서비스로 확대 적용 (VM, BM, DB 상품 등) 
  . 특정 장비에 대한 부분으로 확대 가능 (Object Storage 장비, DNS 장비, LB 장비 등) 
  . 패턴화된 로그 분석과 통합 모니터링 시스템을 다양한 서비스/시스템으로 확대 가능
